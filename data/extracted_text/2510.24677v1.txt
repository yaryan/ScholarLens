--- Page 1 --- Dissecting Role Cognition in Medical LLMs via Neuronal Ablation Xun Liang1,+, Huayi Lai1,+, Hanyu Wang1, Wentao Zhang2, Linfeng Zhang3, Yanfang Chen4,*, Feiyu Xiong5,6, and Zhiyu Li5,6,* 1SchoolofInformation,RenminUniversityofChina,Beijing,China 2CenterofMachineLearningResearch,PekingUniversity,Beijing,China 3SchoolofArtificialIntelligence,ShanghaiJiaotongUniversity,Shanghai,China 4HealthInformaticsCommitteeoftheChinaSocietyforScientificandTechnicalInformation,RenminUniversityof China,Beijing,China 5InstituteforAdvancedAlgorithmsResearch(IAAR),Shanghai,China 6MemtensorResearchCenter,Shanghai,China  +Theycontributeequallytothiswork ABSTRACT Large language models (LLMs) have gained significant traction in medical decision support systems, particularly in the contextofmedicalquestionansweringandrole-playingsimulations. Acommonpractice,Prompt-BasedRolePlaying(PBRP), instructsmodelstoadoptdifferentclinicalroles(e.g.,medicalstudents,residents,attendingphysicians)tosimulatevaried professionalbehaviors. However, theimpactofsuchrolepromptsonmodelreasoningcapabilitiesremainsunclear. This studyintroducestheRP-Neuron-ActivatedEvaluationFramework(RPNA)toevaluatewhetherrolepromptsinducedistinct, role-specific cognitive processes in LLMs or merely modify linguistic style. We test this framework on three medical QA datasets,employingneuronablationandrepresentationanalysistechniquestoassesschangesinreasoningpathways. Our resultsdemonstratethatrolepromptsdonotsignificantlyenhancethemedicalreasoningabilitiesofLLMs. Instead, they primarilyaffectsurface-levellinguisticfeatures,withnoevidenceofdistinctreasoningpathwaysorcognitivedifferentiation acrossclinicalroles. Despitesuperficialstylisticchanges,thecoredecision-makingmechanismsofLLMsremainuniform across roles, indicating that current PBRP methods fail to replicate the cognitive complexity found in real-world medical practice. Thishighlightsthelimitationsofrole-playinginmedicalAIandemphasizestheneedformodelsthatsimulategenuine cognitive processes rather than linguistic imitation.We have released the related code in the following repository:https: //github.com/IAAR-Shanghai/RolePlay_LLMDoctor 1 Introduction Driven by the rapid advancement of large language models(LLMs)1–4, LLMs are increasingly used for medical question answeringandclinicaldecisionsupport5–8. MainstreamarchitecturesincludeautoregressivegeneratorssuchastheGPTseries9 andencoder–decodermodelssuchastheT5family10,11. ThesemodelsperformwellonmedicalQA12,casesummarization13, andpatient-facingdialogue14. AprevalentpracticeintheseapplicationsisPrompt-BasedRolePlaying(PBRP)15,16,which instructsamodeltorespond“as”aparticularclinician(e.g.,intern,resident,attending,orspecialist)withthegoalofincreasing realism and credibility of generated outputs. Building on PBRP, recent systems adopt multi-agent designs where prompt- conditionedagentscoordinateviatooluseanddeliberationtoimprovedecisions17,18. Despitetheirappeal,thevalidityof theseagentconfigurations(roleprompts,divisionoflabor,andinteractionprotocols)andtheiractualcontributiontoreasoning qualityremaininsufficientlytested. WeintroducetheRP-Neuron-ActivatedEvaluationFramework(RPNA)totestwhetherrole promptsinducecomplementary,role-specificcomputationormerelystylisticmodulation. Inclinicalmedicine,rolestratificationismorethananallocationofauthorityorlabor;itencodesgradedexpertisewith heterogeneouscognitivemechanisms,reasoningstrategies,andknowledgestructuresacrosslevels19,20. Fromnoviceinternsto frontlineattendingsandseniorspecialists,cliniciansdeploydifferentdiagnosticheuristics,evidence-integrationroutines,and risk-calibrationpolicieswhenfacingthesamecase. Empiricalworkincognitivepsychologyandstatisticaldecisiontheory hasdocumentedsystematicdifferencesinneuralactivationandinformation-processingpoliciesacrossexpertiselevelsduring historytaking,symptominterpretation,andtheconstructionofdiagnostic–therapeuticpathways21–24. Thisstratifiedcognition underpinsmedicaleducation’sroleprogressionandenablesmulti-level,collaborativedecisionmakinginpractice. Therefore,if LLMs“play”clinicalroles,atestableexpectationisrole-dependentdifferencesinlatentcomputationandbehavior,beyond 5202 tcO 82 ]LC.sc[ 1v77642.0152:viXra --- Page 2 --- Figure1. OverviewoftheRPNAevaluationframework. surfacestyle. Acentral,under-testedquestioniswhetherprompt-basedroleplayingactuallyinducesrole-specificreasoninginLLMsor merelyproducesstylisticshiftswhileleavinglatentcomputationslargelyunchanged. WeaddressthiswiththeRP-Neuron- ActivatedEvaluationFramework(RPNA)(AsshowninFigure1). Weidentifyrole-salientunitsusinganactivation/gradient- basedsaliencescoreundereachroleprompt,thenablatethetop-r%unitsinthetop-Klayersduringinference. Ifroleprompts instantiate distinct circuits, within-role masking should degrade performance more than cross-role masking; symmetry or uniformlysmalldropsarguesagainstrole-specificpathways. Aroundthisprobe,RPRFbenchmarkspre/post-promptaccuracy, assessesrepresentationstructure(CKA/PCAandclustering),andprofileslayer-wisedivergenceviaJSDacrossdepth. WeapplyRPNAon3medicalQAdatasetson3kindsofopen-sourceLLMswithdifferentmodelsize. Todisentanglestyle fromcomputation,wefixdecoding,computepairedaccuracydeltaswith95%confidenceintervals,andsweepmaskingratios. RPRFthenasksfourtestablequestions: Dorolepromptsyieldconsistentaccuracygains? Doroleeffectspersistindeeplayers ratherthanfadingwithdepth? Doroleconditionsformseparableclustersinrepresentationspace(CKA/PCAandclustering)? andiswithin-roleneuronmaskingmoredamagingthancross-rolemasking? Failureontheseindicatesthatrolepromptsmainly coordinatelanguagestyleratherthanreconfigurereasoning. Ourfindingsindicatethatrolepromptsdonotinducesignificantchangesinlatentreasoningpathwaysacrossclinicalroles, andanyobservedaccuracyimprovementsareunstable. Neuronmaskingforaspecificroleresultsinperformancedegradation comparabletothatobservedforotherroles,andcross-rolemaskingproduceseffectssimilartowithin-rolemasking,providing noevidencefortheexistenceofrole-specificcircuits. Theseresultssuggestsubstantialhomogeneityinlatentcomputation acrossclinicalrolesunderPBRP,withpromptsprimarilyinfluencingsurfacelanguageratherthaninducingdistinctreasoning pathways. Activationdifferencesareconcentratedinearlytomiddlelayersandattenuatewithdepth;highCKAvaluesand overlappingPCAclustersindicateconvergentdeeprepresentations. Collectively,thesefindingshighlightthatroleplaying in PBRP mainly tunes linguistic style rather than contributing to genuine improvements in reasoning. Consequently, the Role-PromptedNeuron-ActivatedEvaluationFramework(RPNA)providesaclearandpracticalfoundationforassessingwhen role-playingagentpipelinesarelikelytodelivertrueadvancementsinclinicaldecisionsupport,asopposedtomerelyenhancing stylisticrealism. AsshowninthepipelineinFigure1,steps1to5outlinetheworkflowoftheRPNAframework. InStep1,PBRPintegrates LLMswithspecificbehavioralguidelinesandcareerbackgroundstosimulatereasoningprocessesacrossclinicalroles. Step2 evaluatesthemodel’sperformancethroughmultiple-choiceQAtests,posingquestionsandreasoningoverdifferentoptions. InStep3,alightweight,model-agnosticneuron-maskingablationmethodisappliedtoidentifyrole-salientneuralunitsand comparetheeffectsofwithin-roleversuscross-rolemasking,revealingnoevidenceofrole-specificcircuits. Thissuggeststhat 2/15 --- Page 3 --- Figure2. Thefigureshowstheoverallprocessofconstructingrole-playingprompts(RolePrompts)intheQ&Atask.FigureA showsthestepofcreatingastandardpromptforaMedicalStudent,FigureBsimulatesthereasoningbehaviorofrealmedical professionalsunderdifferentknowledgebackgroundsandthinkingstyles. rolepromptsmainlytunelinguisticstyleratherthanalterreasoningpaths. InStep4,representationstructuresareexamined usingCKA/PCAanalysisandclustering,revealingconvergentdeeprepresentationsacrossrolesratherthanformingseparable, hierarchy-alignedgroups. Finally,Step5profilesdepth-wisedivergenceusinglayer-wiseJensen-ShannonDivergence(JSD), showing that any role effects are concentrated in early to middle layers and attenuate with depth. These results provide actionableguidancefordeterminingwhensingle-ormulti-agentrole-playingpipelinesoffergenuineimprovementsinclinical decisionsupport,asopposedtomerelyenhancingstylisticrealism. Methods 1.1 DatasetSelection Tocomprehensivelyassessthecognitivemodelingcapabilitiesoflargelanguagemodels(LLMs)inmedicalrole-playing,we selectedthreerepresentativeandcomplementarymedicalquestion-answeringdatasets,coveringbasicknowledge,clinical reasoning,andinterdisciplinaryscenarios. Thisselectionensuresabalancedassessmentoftasksintermsofhierarchyand cognitivecomplexity,ascategorizedusingBloom’sTaxonomy(AsshowninFigure3.B).Thedatasetsspanarangeofcognitive levels,fromfundamentalrecall-basedtaskstomorecomplexclinicalreasoningandinterdisciplinaryintegration(Asshownin Figure3.A). • MedQA25:ThisdatasetisderivedfromexaminationpapersofthemedicalboardsintheUnitedStates,mainlandChina, andTaiwan. Itisdesignedtoassessdoctors’professionalknowledgeandclinicaldecision-makingabilities. Thedataset containsnumerousreal-worldclinicalquestionsacrossfieldssuchasinternalmedicine,surgery,pediatrics,gynecology, andradiology. Thequestiondesignemphasizesmulti-stepreasoningandknowledgeintegration,makingitcrucialfor evaluating the model’s higher-order reasoning capabilities. From MedQA, we selected the USMLE sub-dataset for testing,containing1,273multiple-choicequestionsinthetestset. AsshowninFigure3,themajorityofthequestionsin MedQAarecategorizedunder"Remembering"and"Understanding"inBloom’sTaxonomy,withasmallerproportion requiringhighercognitivelevelssuchas"Evaluating"and"Creating". • MedMCQA26:DerivedfromtheIndianNEETandAIIMSmedicalexamquestionbanks,thisdatasetfocusesonbasic medicalcoursessuchasanatomy,physiology,andbiochemistry. Thequestionsarestructuredinaclear,standardformat, makingitsuitablefortestingthemodel’sabilitytounderstandmedicalterminologyandtextbook-levelknowledge. We usedthetestsetofthisdataset,whichcontains4,183multiple-choicequestions. AsdepictedinFigure3,MedMCQA questionspredominantlyfallunder"Remembering"and"Understanding",withonlyafewquestionsinthe"Applying" and"Analyzing"categories,reflectingthefocusonfoundationalknowledge. • MMLU-Med27:Focusedoninterdisciplinaryknowledgeintegration,MMLU-Medtestsmodelsoncommon-sensefusion and conceptual reasoning abilities. We selected the medical-related sub-datasets from MMLU, covering topics like anatomy,clinicalknowledge,professionalmedicine,medicalgenetics,collegemedicine,andcollegebiology,totaling 1,083multiple-choicequestions. Thesesub-datasetsincludeawiderangeofcognitivelevels,withasignificantproportion ofquestionsinthehigher-ordercategoriesof"Analyzing","Evaluating",and"Creating",asshowninFigure3,aligning withtheneedformorecomplexreasoningininterdisciplinarymedicalcontexts. 3/15 --- Page 4 --- Figure3. Taskclassificationofthreemedicalquestion-answeringdatasets(basedonGPT-4o). FigureAshowsthe classificationresultsbasedonBloom’staxonomy,andFigureBshowsthesixlevelsofBloom’staxonomyfromhightolow. MedQA and MMLU-Med use the standard four-option multiple-choice question format, while MedMCQA utilizes a five-optionformat. Weselectedthetestsetportionfromeachdatasettoensuretheperformanceresultsareasaccurateand consistentaspossible. ThedistributionofquestionsacrossdifferentlevelsofBloom’sTaxonomyensuresthatthedatasets provideacomprehensivechallengeforassessingLLMs’cognitivereasoninginmedicalcontexts. 1.2 PromptConfiguration TosystematicallyevaluatetheimpactofdifferentdoctorrolesettingsonthebehaviorandinternalrepresentationsofLLMs, as shown in Figure2, we constructed a prompt set containing multiple role contexts, divided into three major categories: Role-PlayingGroup,BaselineGroup,andControlGroup. TheQAexampleofusingtheroleplayingpromptcanbeseeninthe coderepository. Role-PlayingGroup(Role-PlayingPrompts) Role-playingpromptssimulatethedifferencesinknowledge,experience,and decision-makingstylesacrossmedicalprofessionals. Thesepromptsaredesignedtotestifthemodelcanreflectrole-specific reasoning.Wecreatedtenrepresentativedoctorrolesbasedonmedicaleducationandclinicalroledivisionstandards,generating thepromptsusingGPT4o(Figure2.A).Thepromptsinclude“[Background/BehavioralGuidance+RoleName]+Please answerthequestion,”guidingthemodeltoanswerasaspecificrole. Figure2.Bshowshowtherolepromptiscombinedwith theclinicalQ&Ataskandoutputconstraintstoguidethemodel’sreasoning. BaselineGroup(BaselinePrompts) Toestablishabaseline,weusedaunifiedprompt: “Pleaseprovidethemostappropriate answertothefollowingmedicalquestion.”Thispromptlacksrole-specificinformation,allowingthemodeltorespondbased onitsdefaultknowledge. ControlGroup(RandomPrompts) Totestthemodel’ssensitivitytomedicalcontexts,weincludedrandom,non-medical prompts(e.g.,“Thisisasentence.”). Thesepromptsarenotrelatedtothetaskandareexpectedtohavenoimpactonthe model’sanswers,servingasameasureofthemodel’srobustnessandtheselectivityoftheinductionmechanism. 1.3 ModelSelectionandSetup Tosystematicallyevaluatetheresponsebehaviorandinternalmechanismchangesoflargelanguagemodels(LLMs)under differentpromptsettingsinmedicaltasks,weselectedtheQwenseriesofLLMsasthebackboneforourexperiments,covering variousparameterscales. Specifically,wedeployedfourversionsofinstruction-tunedmodelslocally: Qwen2.5-7B-Instruct, Qwen2.5-14B-Instruct,Qwen2.5-32B-Instruct,andQwen2.5-72B-Instruct,representingtheperformanceboundariesofmedium, large,andextra-largemodelswithinthecurrentopenarchitecture. Additionally,weselectedGPT-4o9andDeepseek-R128,two closed-sourcemodelsbasedonreasoning-centricarchitecturesthathaveachievedstate-of-the-art(SOTA)resultsinmultiple evaluationlists. Thesemodelswereusedtofurtherexploretheimpactofdifferentmodelarchitecturesonrole-playingreasoning paths. ThebasemodelsusedinthisstudyaretheQwenseriesofLLMs(Qwen2.5-7B/14B/32B/72B-Instruct), developedby AlibabaDAMOAcademy. Qwen29,asoneoftheleadingChineseopen-sourcemodelswiththehighestglobaldownloadrate, hassubstantialinternationalinfluenceontheHuggingFaceplatformandiswidelyusedbybothdomesticandinternational researchteamsinmedicalquestionansweringsystems,virtualdoctorassistants,andotherscenarios30–32. Ithasbecomea corefoundationalmodelinthemedicalLLMecosystem. TheQwenseriesisknownforitsstrongmulti-turnconversation capabilities,instruction-followingability,andperformanceincomplexcontextualunderstandingandreasoninginmedical scenarios33,makingitasuitableresearchplatformforrole-playingtasks. 4/15 --- Page 5 --- Figure4. Themethodsofneuronsselectionandablation. ItshowstheCharacterNeuronlayerselectionMethod(Step1), NeuronablationMethod(Step2)andBaselineAblationMethod(baselinemethod). GPT-4o9, aclosed-sourcemultimodalmodeldevelopedbyOpenAI,integratesvision, audio, andtextwithinaunified architecture. Althoughonlyitstextcapabilitieswereevaluatedinthisstudy,itsadvancedalignmenttechniquesandefficient memorymanagementcontributetoitsstronginstruction-followingperformance,makingitareliablebenchmarkforcommercial models. Deepseek-R128, built on a reasoning-centric architecture with Mixture-of-Experts (MoE), is optimized for retrieval- augmentedgenerationandlong-contextprocessing. ItshybriddesignreflectsthelatesttrendsinscalableLLMs,focusingon high-efficiencyreasoningtasks. To ensure the reproducibility of the experiments and consistency in computational resources, all open-source model evaluationswereconductedonhigh-performanceGPUserversofthesametype. Toenhancethedeterminismoftheexperiments and repeatability of the analysis, all model inferences were performed with the random sampling mechanism turned off (do_sample=False) and using greedy decoding. This setup ensures that the same input generates stable and comparable outputsunderdifferentexperimentalconditions,providingamoreaccuratereflectionofinternalrepresentationandbehavioral differencesundervariouspromptsorneuralinterventions. Formodelswithextremelylargeparameters(GPT-4oandDeepseek- R1),weutilizedAPIcallstoextractthemodels’answerstoquestionsandanalyzedtheirperformance. ThemodelinvocationinterfacewasbuiltbasedonHuggingFaceTransformersandalocalCUDAaccelerationframework, and all experiments were completed in the Ubuntu Linux environment to ensure controlled inference response times and efficient resource scheduling. By maintaining a unified model configuration, we further ensured that comparisons across prompts,roles,andexperimentaltasksarescientificallyrigorousandcontrollable. 1.4 NeuronAblationMethods Toexploretheregulatoryinfluenceofdifferentrole-playingpromptsonthemodel’sinternalrepresentationpathways, we designedacontrolledablationexperimentframeworkbasedonneuronselectionandmasking. Thisframeworkaimstoquantify whetherrolepromptsactivatespecificneuronscriticaltothedecision-makingprocess. Theexperimentconsistsofthreekey components: Role-SpecificNeuronSelection,Role-SpecificNeuronAblation,andBaselineAblationMethods. Role-SpecificNeuronSelection Toidentifyneuronsactivatedbyrole-playingprompts, wedevelopedanunsupervised neuronselectionmethodthatmeasurescross-conditionactivationdifferences. Thismethodquantifiestheimpactofroleprompts onthemodel’sinternalrepresentationsbycomparingthehiddenstateactivationsunderrole-playingconditions(withtherole 5/15 --- Page 6 --- prompt)andneutralconditions(withouttheroleprompt). Let the hidden state outputs under the role-playing condition be denoted as Hrole ={hrole}L and under the baseline l l=1 conditionasHbase={hbase}L ,wherel indexesthelayersofthemodel,andh ∈R1×T×d representsthehiddenstateofthe l l=1 l l-thlayerwithtokensequencelengthT anddimensionalityd. Theabsoluteactivationdifferenceateachlayerafteraveraging overtokensiscalculatedas: (cid:12) (cid:12) ∆ =(cid:12)mean (hrole)−mean (hbase)(cid:12)∈Rd (1) l (cid:12) T l T l (cid:12) Next,wedefinetherolesensitivityscoreforeachlayerlas: 1 d s = ∑∆[i] (2) l l d i=1 Wethenrankthelayersbasedons andselectthetopK layers(withK defaultingto4). Withineachselectedlayer,we l furtheridentifythetopr%(e.g.,5%)ofneurons,formingthecross-layerrole-sensitiveneuronsetN . Thismethodallowsus role topreciselyidentifytherole-specificneuronsactivatedbytherole-playingprompts,settingthestageforsubsequentneuron ablation. Role-Specific Neuron Ablation To investigate whether the selected role-sensitive neurons are essential for the model’s reasoningprocess,weperformneuronablationbysettingtheoutputactivationsoftheseneuronstozero. Thissimulatesthe "functionalremoval"oftheseneuronsandallowsustoobservethecausalimpactonthemodel’sbehavior. Formally, let N represent the setof role-specific neurons identified inthe l-th layer. Wemodify the activation tensor l h(l)∈RT×d (whereT isthetokensequencelengthandd isthehiddenspacedimensionality)bysettingtheactivationsof neuronsinN tozero,asfollows: l (cid:40) 0, i∈N h˜(l) = l ∀t∈[1,T] (3) t,i h(l) , otherwise t,i ThisablationmethodisapplieddynamicallyateachtargetlayeroftheTransformerblock. Ithastwomainadvantages: first, itallowspreciseidentificationandmanipulationofneuralpathswithoutinterferingwiththeoverallcontextdistribution;second, itishighlyadaptableandcross-modelcompatible,makingitapplicabletodifferentarchitecturesandmodelsizes. Intheexperiments,weusedafixedmaskingratio(e.g.,1%)toensureconsistentinterventionintensityacrossdifferentroles. Wethencomparedtheaccuracydifferencebetweentheoriginalandmaskedmodels. Asignificantdropinaccuracyindicates that the ablated neurons play a crucial role in the reasoning process under specific roles, revealing their “role-scheduling causality.” Additionally,inthecross-roletransferexperiment,wetestedthe"cross-masking"setting,wheretheneuronssensitiveto oneroleareusedtomaskthereasoningpathsofanotherrole. Thiscomparisonhelpsevaluatethegeneralityandselectivityof theseneuralpathwaysacrossdifferentroles. BaselineAblationMethods Tovalidatetheeffectivenessoftheneuronselectionmechanism,wedesignedbaselineablation schemes. Intheseschemes,werandomlyselectedthesameproportionofneuronswithinthesamelayerrangeformasking, ensuringthattheobservedaccuracydropisnotsolelyduetothenumberofneuronsmasked,butrathertothespecificrole- sensitive representation dimensions. By comparing the performance of role-specific ablation with the baseline method, a significantlylargeraccuracydropintheformerwouldfurthersupportthehypothesisthattheselectedneuronsfunctionasa "behavioralschedulingcenter"inspecificroles. 1.5 EvaluationMethods To comprehensively and rigorously assess the impact of role-playing on the medical reasoning ability of large language models, we designed various quantitative metrics for both behavioral and internal representation layers, supplemented by statistical significance tests and confidence interval analyses to ensure the reliability and repeatability of the results. All opensourceexperimentswereconductedonthreemodelswithdifferentscales(Qwen2.5-7B-Instruct,Qwen2.5-14B-Instruct, Qwen2.5-32B-Instruct). Accuracy Thecoreevaluationmetricforthemodel’sbehavioristheansweraccuracy. Wecalculatewhetherthemodel’s selectiontendencyingeneratinganswersacrossdifferentdatasetsundereachrolepromptalignswiththecorrectansweroption, definedas: NumberofCorrectPredictions Accuracy= (4) TotalNumberofQuestions Bycomparingtheaccuracywithrolepromptstothebaselinegroup(noprompt),weextracttheoptionsfromthemodel’s outputusingregularexpressionsandobservewhetherrole-playingleadstoperformanceimprovementorinterference. 6/15 --- Page 7 --- Jensen-ShannonDivergence Tomeasuretheextentofchangesinthemodel’sinternalrepresentationsbeforeandafter role-playing,weuseJSD34toquantifythedifferenceinthehiddenstatevectorsintermsofprobabilitydistributions. JSDisa symmetric,smoothedvariantoftheKullback-Leibler(KL)divergence,definedas: 1 1 1 JSD(P∥Q)= D (P∥M)+ D (Q∥M), M= (P+Q) (5) KL KL 2 2 2 WherePandQrepresentthehiddenstatevectorsgeneratedbythemodelunder"noroleprompt(baseline)"and"withrole prompt"conditions,normalizedtoprobabilitydistributions;Mistheiraveragedistribution;andD istheKullback-Leibler KL divergencedefinedas: P(i) D (P∥Q)=∑P(i)log (6) KL Q(i) i Inthespecificimplementation,themodelgeneratestwoversionsofhiddenlayeroutputsforthesamequestion(i.e.,witha standardpromptvs. withaspecificroleprompt). Wefirstperformmeanpoolingforthehiddenvectorsofeachlayer,then normalizethemtoformpseudo-probabilitydistributions. WethencalculatetheJSDvalueofthehiddenstatedistributionof eachlayerunderthetwoconditions,asaquantitativemeasureoftherepresentationchangeinthatlayer. WecalculatetheJSDforeachsampleandrolepromptwithrespecttothebaselineforeachlayer,andthenaveragethe JSDresultsforallsamples,plottingahierarchicalcurvetoanalyzetheimpactrangeandintensityofdifferentrolesonthe representationspace. Thismetricisusednotonlytovisuallyassesswhetherthemodelhassignificantlyadjusteditsstructure fordifferentroles,butalsotoprovideabasisforsensitivelayerselectioninsubsequentneuralactivationpruningexperiments (e.g.,role-sensitiveneuronablation). PrincipalComponentAnalysis(PCA) Tovisualizethedifferencesinthemodel’shiddenstatesunderdifferentroleprompts, weperformPrincipalComponentAnalysis(PCA)onthehiddenstatesofeachrole. LetX ∈Rn×d bethematrixofhidden statevectorsundertheroleprompts,andPCAisusedtoobtainthefirsttwoprincipalcomponentsthroughSingularValue Decomposition(SVD),embeddingthemina2Dspacetoconstructascatterplot. Thisplotisusedtoanalyzewhetherdifferent rolesexhibitdistinctrepresentationclustersorstructuralboundaries. SilhouetteCoefficient AfterperformingK-meansdimensionalityreduction,wefurthercalculatethesilhouettecoefficientfor eachroletoquantifytheclarityofroleclustering. Foranydatapointiofarole,itssilhouettecoefficientisdefinedas: b(i)−a(i) s(i)= (7) max{a(i),b(i)} Wherea(i)istheaveragedistancefromitootherpointsinitsowncluster,andb(i)istheaveragedistancefromitothenearest othercluster. s(i)∈[−1,1],withahighervalueindicatingclearerclustering. WeuseK-meanstoclustertherolesandreportthe averagesilhouettecoefficientforallpointsasameasureofoverallsemanticdistinguishability. CenteredKernelAlignment(CKA) Tomeasurethestructuralsimilarityofhiddenstates,weintroducetheCKAanalysis method. CKAisarobustneuralrepresentationsimilarityevaluationtool35,definedas: HSIC(K,L) CKA(K,L)= (8) (cid:112) HSIC(K,K)·HSIC(L,L) WhereK andLaretheGrammatricesoftworepresentationmatrices,andHSICistheHilbert-SchmidtIndependence Criterionkernelnorm. WecalculatetheCKAvaluesforthehiddenstatesofdifferentrolesandconstructheatmapstodisplay thedegreeofroleisomorphismintherepresentationspace. Results 1.6 Result 1: Role-Playing Does Not Enhance the Medical Reasoning Capabilities of Large Language Models Webeganbyvalidatingacorehypothesis: ifrole-playingpromptscantrulyenhancethemedicalreasoningcapabilitiesof LLMs,themodel’sansweraccuracyshouldsignificantlyimproveundersuchguidance. Toinvestigatethis,wedesigneda systematiccomparativeexperimenttoanalyzetheQAaccuracyofthetest. Wetestedtheansweraccuracyofdifferentmodelscales(Qwen2.5-7B/14B/32B/72B-Instruct,GPT-4o,andDeepseek-R1) onthesamesetofmedicalmultiple-choicequestions,underthreetypesofPromptgroups: 1. Role-PlayGroup(RP):7different doctoridentitydescriptionsforrole-playing. 2. BaselineGroup(No-RP):Directmodelguidancewithoutrole-playingprompts. 3. RandomGroup: Randomlygeneratedstatementsreplacingtherole-playingprompts. 7/15 --- Page 8 --- Figure5. QAaccuracyof6kindsofLLMon3kindsofmedicalQAdatasets Table1. QAperformancecomparisonof3kindsofmodelswithdifferentarchitectureonMedQAdataset Model Model Medical Expert American China Emergency Resident Surgeon Name Architecture Student Doctor Doctor Doctor Doctor Qwen2.5-72B Reasoningbase(Dense) 0.7227 0.7054 0.7069 0.714 0.7046 0.7046 0.7014 GPT-4o ClosedSource 0.802 0.7824 0.7824 0.8114 0.8067 0.7824 0.7941 Deepseek-R1 Reasoningbase(MoE) 0.8939 0.8900 0.8982 0.8955 0.8884 0.8892 0.8884 As shown in Figure 6. The accuracy evaluation using 7 different doctor role-playing prompts on 6 types of LLMs demonstratesthatrole-playing(RP)didnotsignificantlyimprovethemodel’sansweraccuracy. IntheMedMCQAandMedQA datasets,accuracydifferencesbetweenRPandRandomorNo-RPwerenegligible,withavariationoflessthan±2%. Inthe MMLU-Meddataset,theperformanceofthedoctorrole-playinggroupshowedalmostnodifference,indicatingthatadopting aclinician’sperspectivedidnotsignificantlyaffectthemodel’smedicalreasoningcapabilities.WeusedCochran’sQtestto furthervalidatetheaccuracydifferencesbetweentheRPgroupandthebaselinegroup(No-RP).Theresultsshowedthatin mostcases(p>0.05),thedifferenceswerenotstatisticallysignificant,indicatingthatrolepromptsdidnotsignificantlyenhance themodel’smedicalreasoningcapabilities." Tofurtherexplorewhetherspecificdoctorrolescouldenhancereasoningeffects,wedisplaytheaccuracydistributionsof3 open-sourcemodels(Qwen2.5-7B/14B/32B-Instruct)underthe7doctorroleprompts(Figure6). Significancetestanalysis, usingCochran’sQtest(indicatedbydashedlines),revealednosignificantdifferencesbetweenthemajorityoftherolegroups (p>0.05). ForthosegroupswithsignificantCochran’sQtestresults,pairwiseMcNemartests(afterHolmcorrection)showed nostatisticalsignificanceinmostcases(p>0.05). Furthermore,whenexaminingtheimpactofmodelarchitectureandreasoningmethodsonrole-playing,weobservedno significantaccuracydifferencesbetweenmodels,regardlessofwhetherthemodelwasrole-playingasa"medicalstudent"or an"expertdoctor"(Table1). Thisconsistenttrendacrossdifferenttaskssuggeststhatlargelanguagemodelsdonotdevelop distinctreasoningresponsepatternsbasedondifferentrolesettings. Theseresultsconcludethatrole-playingpromptsdonotactivateorenhancethemodel’smedicalreasoningcapabilities. Instead,theyappeartoprimarilyalterlinguisticstyle,ratherthaninfluencingtheinternaldecision-makingprocessofthemodel. 1.7 Result2: Role-PlayingDoctorsFollowHighlySimilarCognitivePathways Inclinicalpractice,doctorsatdifferentlevels(e.g.,interns,residents,attendingphysicians)exhibitdistinctcognitivepathways andtaskstrategies. However,currentLLMsshowhighlyconsistentreasoningpathways,regardlessofthedoctorroletheyare 8/15 --- Page 9 --- Figure6. QAaccuracyof9rolesplayresultstestedon3kindsofmedicaldatasetsbasedonQwen2.5-14B-Instruct AblationLayers AblationPercentageperlayer MedQA MedMCQA MMLU-Med 3% 0.457 0.496 0.624 Top-4layers 5% 0.460 0.502 0.653 10% 0.493 0.543 0.704 3% 0.427 0.489 0.599 Top-6layers 5% 0.436 0.493 0.626 10% 0.518 0.559 0.731 3% 0.512 0.546 0.703 Top-8layers 5% 0.528 0.563 0.744 10% 0.547 0.574 0.757 Table2. Accuracydropatdifferentablationstrengthsandper-layerpercentagesonMedQA,MedMCQA,andMMLU-Med. simulating. ToinvestigatewhetherLLMsexhibitrole-specificreasoningpathways,wedesignedaneuronmaskingintervention. We firstconductedaparametersensitivityanalysistovalidatethegeneraleffectivenessofthisintervention,withresultsdetailed inTable2. Thisanalysisconfirmsacleardose-responserelationship: increasingtheablationstrength—eitherbytargeting morelayers(fromTop-4toTop-8)orincreasingthemaskingpercentage(from3%to10%)—consistentlyresultsinamore significantaccuracydropacrossallthreedatasets. Forinstance,ontheMedQAdataset,theaccuracydropforTop-8layersat 10%(0.547)isnotablylargerthanthatforTop-4layersat3%(0.457). Havingestablishedtheintervention’sefficacy,weselectedamoderateandrepresentativeparametersetforourprimary role-specificexperiments: maskingthetop5%mostsignificantlyactivatedneuronsfromthetop4hiddenlayers. Wetested thisexperimentonthreedifferentmodelsizes(Qwen2.5-7B-Instruct,Qwen2.5-14B-Instruct,andQwen2.5-32B-Instruct). AsshowninFigures7.A-F,theaccuracydropaftermaskingwasconsistentacrossallroles. Forexample,intheQwen2.5- 32B-InstructmodelontheMedQAdataset,theaccuracydropsfortherolesof"Resident,""MedicalStudent,"and"China Doctor"were0.051,0.060,and0.046,respectively. Themaximumdifferenceinaccuracydropwasonly1.4%,andthesame pattern was observed across different datasets (MedQA, MedMCQA, MMLU-Med). We also conducted McNemar’s test andobservednosignificantdifferencesinaccuracydropsbetweenroles(p>0.05). Thisindicatesthattheimpactofneuron ablationonperformancewasconsistentacrossdifferentroles. Furthercross-roleneuronmaskingexperiments(Figures7.G-I)showedthattheperformancedropsbetweenroleswere almost identical, with no significant differences in accuracy. For example, the cross-masking of "Medical Student" and "Resident"rolesledtonegligibleperformancedifferences(Qwen2.5-14B: p=0.317;32B: p=0.362,McNemartest). TheseresultssuggestthatLLMsdonotconstructdifferentiatedcognitivepathwayswhensimulatingdifferentdoctorroles. Instead,theyrelyonsimilarunderlyingactivationstructures,regardlessoftherole. Thishighoverlapincognitivepathways suggeststhatcurrentLLMscannotsimulatedistinctthinkingpatternsfordifferentroles,andtheirresponsesareprimarily controlledbylinguisticstyleratherthancognitivedifferentiation. 9/15 --- Page 10 --- Figure7. AccuracydropbetweenRPLLMandNo-RPLLM(A-F),figureG-Ishowstheaccuracybetweencrossablation experiments."role_diff"meanstheaccuracydropbyRPbasedablationmethod,"random"meanstheaccuracydropbyrandom ablationmethod 1.8 Result3: Role-PlayingDoctorsLacktheAbilitytoModelHierarchicalStructuresinMedicalProfessional Levels Table3. SilhouettescoresfordifferentrolesinQwen2.5-14BmodelinMedQAbenchmark. Role SilhouetteScore MedicalStudent 0.12 Resident 0.13 AttendingPhysician 0.13 ChiefPhysician 0.13 AssociateChiefPhysician 0.13 MedicalExpert 0.13 SeniorMedicalExpert 0.14 Baseline 0.11 Random 0.11 Inclinicalpractice,doctorsatdifferentlevelsofexpertiseusedifferentcognitivestrategiesbasedontheirprofessional ranking.However,wefoundthatLLMs,whengivenrole-playingpromptsfordifferentdoctorlevels,failtoformdistinguishable professionalcognitivestructures. Theiractivationpatternsremainhighlysimilaracrossroles. We used the CKA metric to measure the similarity of hidden layer representations induced by different doctor role prompts. AsshowninFigure8.A,thesimilaritybetweendifferentroleswasconsistentlyhigh(0.96–1.00),indicatingthatthe representationspacefordifferentrolesoverlapssignificantly. Therewasnocleargradientinactivationstructuresalongthe professionalhierarchy. Further, Principal Component Analysis (PCA) of the final hidden layer representations (Figure 8.B) showed that the samplesfordifferentrolesheavilyoverlappedintheprojectionspace,exhibitingalmostnovisibleclusteringboundaries. The role-specificclusteringresultsbasedonK-means,withsimilarsilhouettescoresforallroles(asshowninTable.3),confirmed thatthemodelfailedtodifferentiatebetweenrolesbasedontheprofessionalhierarchy. ThisanalysisindicatesthatLLMsdonotgeneratedistinctcognitivestructuresfordifferentmedicalroles. Instead,the 10/15 --- Page 11 --- Figure8. TheCKAanalysisandPCAanalysisofroleplayinseniorityincreasescanario. SubfigureAshowstheCKA similarityheatmapofactivationsbetweendifferentdoctorroles,displayingtheaveragehiddenlayersimilarityof Qwen2.5-14B-Instructmodelunderdifferentmedicalrolepromptinputs. SubfigureBshowsthePCAvisualizationofthefinal hiddenlayeroutputfordifferentrolesinMedQAdataset. role-playingpromptsonlyinfluencesurface-levellanguagefeatures,failingtotriggerdeeperstructuraldifferentiation. This highlights a significant limitation in current LLM-based role-playing: while the models can mimic the linguistic style of differentroles,theydonotreproducethehierarchicalcognitivedifferentiationexpectedofhumandoctors. 1.9 Result4: Role-PlayingDoctorsDoNotSimulateSpecificCognitivePathwaysofRealDoctors Toevaluatewhetherrole-playingpromptstriggerstructuralchangesinthereasoningpathwaysofLLMs,weusedJSDasan indicatortosystematicallyquantifythedeviationofhiddenstaterepresentationsinTransformerlayersacrossdifferentrole conditions. WeconductedthisexperimentontheMedMCQAdataset,usingthreesizesofQwen2.5seriesmodels(7B-Instruct, 14B-Instruct,32B-Instruct). Figures9.A–CshowthatthesignificantdifferencesinJSDbetweentheRPgroupandthecontrolgroups(Baselineand Random)wereconcentratedinthemodel’sshallow-to-midlayers(e.g.,layers1–25inFigure9.C).Thissuggeststhatrole promptsaffecttheearlylanguagemodelingandsemanticencodingprocessesofthemodel. However,astheTransformerlayers deepen,therepresentationdifferencesdiminishandconverge(afterlayer35inFigure9.C).Thisindicatesthatrolepromptsdo nothavelastingeffectsonthedeeperlayersofthemodel. This suggests that while role settings can influence the model’s initial reasoning or language expression, they do not significantlyalterthecorereasoningpathways. Thispatternholdsforallroles,indicatingthatLLMsdonotexhibitdistinct cognitivestrategieswhenplayingdifferentdoctorroles,andtheirreasoningpathsremainlargelysimilar. TheseresultsdemonstratethatLLMsdonotreplicatereal-worldhumandoctors’cognitiveprocessesbutmerelysimulate languagestyles. Ithighlightsthelimitationsofusingrole-playingpromptstoinducerealcognitivedifferentiationinmedicalAI. Discussion This study systematically evaluated the impact of role-playing prompts on the reasoning capabilities of LLMs in medical question answering tasks. Our results reveal that while role-playing prompts significantly alter the language style of the models, they do not induce meaningful differences in the cognitive reasoning pathways expected from different medical professionals. Specifically,despiterole-playingpromptssimulatingvariousdoctorroles,suchasmedicalstudent,resident, andattendingphysician,themodel’sunderlyingdecision-makingprocessesremainedstrikinglysimilaracrossallroles. This findingchallengesthecommonassumptionthat"languageequalscognition,"particularlyinthecontextofmedicalAI,where thecognitivedifferencesbetweenmedicalprofessionalsarecrucialforaccuratediagnosisandtreatment. 11/15 --- Page 12 --- Figure9. ExperimentresultsofvisualizingtheJSdivergenceofdifferentkindsofRPLLMs,figureA-CshowtheJSD betweendifferentlayers Acentralquestiondrivingthisresearchwaswhetherrole-playingcouldinducerole-specificreasoningpathwaysinLLMs, analogoustothecognitivestrategiesusedbyhumandoctorsofdifferentexpertiselevels. However,ourfindingsindicatethat role-playingprimarilyimpactsthemodel’ssurface-levellanguageoutput,withouttriggeringtheactivationofdistinctreasoning circuits. This is evident from our experiments with neuron ablation, where blocking role-specific neurons did not lead to significant differences in the model’s performance. The minimal performance drop after neuron masking across different rolessuggeststhatthemodeldoesnotdeveloprole-specificcognitivepathways,butinsteadreliesonamonolithicreasoning mechanismthatoperatessimilarlyacrossdifferentprofessionalroles. Moreover,ouranalysisofthemodel’shiddenstaterepresentationsatdifferentlayersrevealednoevidenceofhierarchical differentiation between doctor roles. While role prompts did influence the early layers of the Transformer, these effects dissipatedinthedeeperlayers,wherethemodel’srepresentationsconverged. Thissuggeststhatalthoughrolepromptscan influencethemodel’sinitialresponse,theydonotleadtosubstantialchangesinthecorereasoningstructure,whichremains largelyunaffectedbytheprofessionalroleofthesimulateddoctor. Oneofthekeytakeawaysfromthisstudyisthatcurrentprompt-basedrole-playingmethodsareinsufficientforreplicating thenuancedcognitivedifferencesobservedinreal-worldclinicaldecision-making. Inamedicalsetting,differentrolesinvolve notjustdifferencesinknowledgebutalsodifferencesincognitivestrategies,prioritization,andclinicaljudgment. Thelack ofcognitivedifferentiationinLLMs,asshownbyourexperiments,impliesthatrelyingonrole-playingtosimulateclinical expertisecouldleadtomisleadingorunreliablemedicaldecisionsupport. Specifically,incomplexclinicalscenariosrequiring differentiated reasoning, such as diagnosing rare conditions or managing high-risk patients, the model may fall short of human-levelreasoningabilities,potentiallyposingriskstopatientsafety. Our findings also underscore the limitations of the current paradigm in clinical AI, which often equates the language producedbyamodelwiththereasoningabilitiesassociatedwiththatlanguage. AlthoughLLMshavedemonstratedimpressive performanceinlanguagegenerationtasks,theircurrentarchitecturesdonotenablethemtotrulysimulatethementalmodelsof medicalprofessionals. Role-playingpromptsmayshapehowthemodelexpressesitselfbutdonotequipitwiththeabilityto reasonlikeamedicalexpert. Thisdistinctioniscritical,asithighlightsthegapbetweensuperficiallanguageimitationand genuinecognitivemodeling. Looking ahead, the future of medical AI should focus on developing models that go beyond language imitation and incorporate cognitive modeling techniques. Rather than simply simulating roles, future models should aim to understand andreplicatethecognitiveprocessesunderlyingclinicaldecision-making. Thiscouldinvolveintegratingdomain-specific knowledge into the training process and designing systems that can simulate the reasoning strategies of different medical professionals. SuchadvancementswouldpavethewayformorereliableandinterpretableAIsystemscapableofproviding professional-levelmedicaldecisionsupport. Whilerole-playinginLLMscanalterlanguagestyle,itdoesnotprovidethemodelwiththedeepercognitiveabilities 12/15 --- Page 13 --- requiredforaccuratemedicaldecision-making. OurstudycallsforashiftinhowweapproachthedevelopmentofclinicalAI, advocatingformodelsthatsimulatecognitiveprocessesratherthanjustlinguisticbehavior. Bydoingso,wecanbetteralignAI systemswiththecomplexitiesofreal-worldclinicalpractice,ensuringtheirutilityandsafetyinmedicalapplications. Conclusion Thisstudysystematicallyevaluatedtheimpactofrole-playingpromptsonthereasoningcapabilitiesoflargelanguagemodels inmedicalquestionansweringtasks. Theresultsrevealthat,whilerole-playingpromptscansignificantlyalterthemodel’s languagestyle,theydonotinducereasoningpathwaysthatcorrespondtotheprofessionalrolesofdoctors. Despitetesting acrossmultipledatasets,role-playingfailedtoimprovethemodel’saccuracy,particularlyinhigh-complexitytasks. Instead,the effectofrole-playingwaslimitedtosuperficiallanguagechanges,withnoactivationofnewknowledgestructuresorreasoning strategies. Furthermore,neuronablationandhierarchicalmodelingtestsdemonstratedthatthereasoningpathwaysacross differentdoctorroleswerenearlyidentical,indicatingalackofrole-specificcognitivedifferentiation. Thesefindingshighlight thelimitationsofcurrentrole-playingmethodsinclinicalAI,astheyprimarilyalterlanguagebehaviorratherthanenabling modelstoreplicatethecognitiveprocessesofrealdoctors. Consequently,relyingonlanguage-basedrole-playingaloneis insufficientforbuildingreliablecognitiveagentsinmedicalapplications,signalingtheneedforashifttowardsmoreadvanced cognitivemodelinginthedevelopmentofmedicalAIsystems. References 1. Dillion,D.,Mondal,D.,Tandon,N.&Gray,K. Ailanguagemodelrivalsexpertethicistinperceivedmoralexpertise. Sci. Reports15,4084(2025). 2. Lo,J.-H.,Huang,H.-P.&Lo,J.-S. Llm-basedrobotpersonalitysimulationandcognitivesystem. Sci.Reports15,16993 (2025). 3. Massenon, R., Gambo, I., Khan, J. A., Agbonkhese, C. & Alwadain, A. ” my ai is lying to me”: User-reported llm hallucinationsinaimobileappsreviews. Sci.Reports15,30397(2025). 4. Jiao, J. et al. Llm ethics benchmark: a three-dimensional assessment system for evaluating moral reasoning in large languagemodels. Sci.Reports15,34642(2025). 5. Clusmann,J.etal. Thefuturelandscapeoflargelanguagemodelsinmedicine. Commun.medicine3,141(2023). 6. Safranek, C. W., Sidamon-Eristoff, A. E., Gilson, A. & Chartash, D. The role of large language models in medical education: applicationsandimplications(2023). 7. Huang,J.etal. Acriticalassessmentofusingchatgptforextractingstructureddatafromclinicalnotes. npjDigit.Medicine 7,106(2024). 8. Wu,L.etal. Asurveyonlargelanguagemodelsforrecommendation. WorldWideWeb27,60(2024). 9. Waisberg,E.etal. Gpt-4: aneweraofartificialintelligenceinmedicine. Ir.J.Med.Sci.(1971-)192,3197–3200(2023). 10. Lehman,E.&Johnson,A. Clinical-t5: Largelanguagemodelsbuiltusingmimicclinicaltext. PhysioNet(2023). 11. Vaswani,A.etal. Attentionisallyouneed. Adv.neuralinformationprocessingsystems30(2017). 12. Health,T.L.D. Largelanguagemodels: anewchapterindigitalhealth(2024). 13. VanVeen,D.etal. Adaptedlargelanguagemodelscanoutperformmedicalexpertsinclinicaltextsummarization. Nat. medicine30,1134–1142(2024). 14. Johri,S.etal. Anevaluationframeworkforclinicaluseoflargelanguagemodelsinpatientinteractiontasks. Nat.Medicine 1–10(2025). 15. Shanahan,M.,McDonell,K.&Reynolds,L. Roleplaywithlargelanguagemodels. Nature623,493–498(2023). 16. VanVeen,D.etal. Adaptedlargelanguagemodelscanoutperformmedicalexpertsinclinicaltextsummarization. Nat. medicine30,1134–1142(2024). 17. Li,J.etal. Agenthospital: Asimulacrumofhospitalwithevolvablemedicalagents. arXivpreprintarXiv:2405.02957 (2024). 18. Qian,H.&Liu,Z. Metaagent: Towardself-evolvingagentviatoolmeta-learning(2025). 2508.00271. 19. Elstein,A.S.,Shulman,L.S.&Sprafka,S.A. Medicalproblemsolving: Ananalysisofclinicalreasoning(Harvard UniversityPress,1978). 13/15 --- Page 14 --- 20. Schmidt,H.G.,Norman,G.R.&Boshuizen,H.P. Acognitiveperspectiveonmedicalexpertise: theoryandimplication [publishederratumappearsinacadmed1992apr;67(4): 287]. Acad.medicine65,611–21(1990). 21. Hicks,E.P.&Kluemper,G.T. Heuristicreasoningandcognitivebiases: Aretheyhindrancestojudgmentsanddecision makinginorthodontics? Am.journalorthodonticsdentofacialorthopedics139,297–304(2011). 22. Elstein,A.S. Heuristicsandbiases: selectederrorsinclinicalreasoning. Acad.Medicine74,791–4(1999). 23. Shin,H.S. Reasoningprocessesinclinicalreasoning: fromtheperspectiveofcognitivepsychology. Koreanjournal medicaleducation31,299(2019). 24. Bach,R.M. Heuristicreasoningandcognitivebiases. Am.J.Orthod.Dentofac.Orthop.140,2(2011). 25. Jin,D.etal. Whatdiseasedoesthispatienthave? alarge-scaleopendomainquestionansweringdatasetfrommedical exams. Appl.Sci.11,6421(2021). 26. Pal,A.,Umapathi,L.K.&Sankarasubbu,M. Medmcqa: Alarge-scalemulti-subjectmulti-choicedatasetformedical domainquestionanswering. InConferenceonhealth,inference,andlearning,248–260(PMLR,2022). 27. Wang, Y. et al. Mmlu-pro: A more robust and challenging multi-task language understanding benchmark. In The Thirty-eightConferenceonNeuralInformationProcessingSystemsDatasetsandBenchmarksTrack(2024). 28. Gibney,E. Scientistsflocktodeepseek: howthey’reusingtheblockbusteraimodel. Nature12(2025). 29. Ahmed,I.etal. Qwen2.5: Acomprehensivereviewoftheleadingresource-efficientllmwithpotentioaltosurpassall competitors. AuthoreaPrepr.. 30. Lin, K.-H. et al. Benchmarking large language models gpt-4o, llama 3.1, and qwen 2.5 for cancer genetic variant classification. NPJPrecis.Oncol.9,1–10(2025). 31. Wu,J.etal. Arch-evalbenchmarkforassessingchinesearchitecturaldomainknowledgeinlargelanguagemodels. Sci. Reports15,13485(2025). 32. Fang,K.,Tang,C.&Wang,J. Evaluatingsimulatedteachingaudioforteachertraineesusingragandlocalllms. Sci. Reports15,3633(2025). 33. Joshi,S. Acomprehensivereviewofqwenanddeepseekllms: Architecture,performanceandapplications. Perform.Appl. (May15,2025)(2025). 34. Lin,J. Divergencemeasuresbasedontheshannonentropy. IEEETransactionsonInf.theory37,145–151(1991). 35. Kornblith,S.,Norouzi,M.,Lee,H.&Hinton,G. Similarityofneuralnetworkrepresentationsrevisited. InInternational conferenceonmachinelearning,3519–3529(PMLR,2019). 2 Data availability Thedatasetsusedinthisstudyarepubliclyavailable. TheMedQAdataset(USMLEsubset)canbeaccessedat  evaluation. TheMedMCQAdatasetissourcedfromIndianmedicalexamsandisavailableat medmcqa/medmcqa. The MMLU-Med subset, comprising interdisciplinary medical knowledge tasks, can be found at  Allcodeforreproducingouranalysisisavailableinthefollowingrepository: RolePlay_LLMDoctor# Inclusion & Ethics Statement Thisstudywasconductedwithastrongcommitmenttoethicalresearchpracticesandinclusivescientificinquiry. Ourresearch focusesonthecognitivemodelingcapabilitiesoflargelanguagemodels(LLMs)inthecontextofmedicalrolesimulation. Nohumansubjectsorprivatehealthdatawereusedorinvolvedatanystageofthestudy. Alldatasetsemployed—MedQA, MedMCQA,andMMLU-Med—arepubliclyavailableandaccessedundertheirrespectiveopenlicenses,ensuringtransparency andreproducibility. Theauthorsaffirmthatnodiscriminatory,exclusionary,orharmfulcontentispresentinthedatasets,prompts,orexperimen- taldesign. Therolesdesignedinthisstudyspandiversemedicalbackgroundsandgeographies(e.g.,doctorsfromChina,the U.S.,andvariousmedicalranks),reflectingourintenttoensureinclusivityinprofessionalrepresentation. 14/15 --- Page 15 --- Acknowledgements ThisworkissupportedbytheNationalNaturalScienceFoundationofChinaundergrant62072463,theScientificResearch FundofRenminUniversityofChina(CentralUniversitiesBasicScientificResearchFunds)underproject24XNKJ31,andthe OpenFundoftheNationalKeyLaboratoryofDigitalPublishingTechnology,FounderGroup. Thecorrespondingauthorsof thispaperareYanfangChenandZhiyuLi. Author contributions statement X,L.Z.L.andH.L.conceivedthestudyandsupervisedtheoverallproject. H.L.andH.W.designedandexecutedthecore experiments,includingtherolepromptconstruction,accuracyevaluation,andneuralrepresentationanalyses. W.Z.andL.Z. implementedtheneuronablationframeworkandconductedtherole-specificmaskingexperiments. Y.C.curatedandprocessed themedicalQAdatasetsandcontributedtothedesignofthecognitivestratificationassessment. F.X.,H.L.,X.L.,H.W.,and W.Z.jointlyanalyzedtheresultsanddraftedthemanuscript. Z.L.andY.C.providedcriticalfeedbackontheexperimental methodologyandclinicalimplications. Allauthorscontributedtotherevisionofthemanuscriptandapprovedthefinalversion. Competing interests Theauthorsdeclarenocompetinginterests. 15/15