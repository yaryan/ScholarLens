--- Page 1 --- ADVANCING SITE-SPECIFIC DISEASE AND PEST MANAGEMENT IN PRECISION AGRICULTURE: FROM REASONING-BASED FOUNDATION MODELS TO ADAPTIVE, FEEDBACK-DRIVEN LEARNING NitinRai Daeun(Dana)Choi DepartmentofHorticulturalSciences DepartmentofAgriculturalandBiologicalEngineering GulfCoastResearchandEducationCenter GulfCoastResearchandEducationCenter UniversityofFlorida UniversityofFlorida Wimauma,FL,USA Wimauma,FL,USA {nitin.rai}ufl.edu NathanS.Boyd ArnoldW.Schumann DepartmentofHorticulturalSciences DepartmentofSoil,Water,andEcosystemSciences GulfCoastResearchandEducationCenter CitrusResearchandEducationCenter UniversityofFlorida UniversityofFlorida Wimauma,FL,USA Wimauma,FL,USA ABSTRACT Site-specificdiseasemanagement(SSDM)inagriculturalcropshaswitnessedtremendousadvance- mentsoverthepastfewdecadesusingconventionalmachineanddeeplearning(ML&DL)approaches forreal-timecomputervisionapplications. Thisresearchhasevolvedfromhandcraftedfeatureex- tractiontolarge-scaleautomatedfeaturelearninginsingle-modalitydatasets. However, withthe riseoffoundationmodels(FMs),thewaylarge-scalecropdiseasedatasetsareprocessedisbeing fundamentallytransformed. Unliketraditionalconvolutionalneuralnetworks,whichoftenstruggle tointegratemulti-modaldataorconnectvisualandtextualinformation,FMsenabledeeperlevelof understanding. Theycaninterpretdiseasesymptomsdescribedintext,reasonaboutrelationships betweensymptomsandmanagementfactors,andevensupportinteractiveQ&Aplatformsforgrowers andextensioneducators. Likewise,theintegrationofadaptiveandimitationlearninginroboticsis enablingnovelapplicationsforfield-baseddiseasemanagement. Theseemergingshiftsinadvanced computer vision and robotics research are redefining how crops are monitored and managed in in-fieldsettings. Therefore,thisstudyreviewed≈40researcharticles(withappropriatescreening criteria)tohighlighttheapplicationofFMsforSSDMincrops,focusingontwoprimarythemes: large-languagemodels(LLMs),andvisionlanguagemodels(VLMs). Additionally,theextendedrole ofFMsinenablingadaptivelearning(AL),reinforcementlearning(RL),anddigitaltwinframeworks forrobotics-basedtargetedsprayingisalsodiscussed. Basedontheresultsanddiscussion,several keyconclusionsemergefromthisreview: (a)FMsaregainingtraction,withanotableincreasein reportedtechnicalliteratureduring2023-24,(b)researchersareleveragingVLMsmorethanLLMs, withafive-totenfoldincreaseinpublishedarticlesfrom2023to2024,(c)approachessuchasRLor ALarestillintheirinfancyfordevelopingsmartsprayingtechnologiesthatcanlearnfromexperience, (d)theintegrationofdigitaltwinswithRLincyber-physicalsystemscouldofferatransformative approachforsimulatingtargetedsprayinginvirtualenvironments,(e)addressingthesim-to-realgap, theperformancedropwhenmodelstrainedinsimulatedorcontrolledenvironmentsaredeployedin real-worlddiseasescenarios,willbecriticalforensuringrobustandscalablemanagementsystems, (f)whileperceptionmodelsfordiseasedetectionareadvancing,human-robotcollaborationincrop diseasemanagementremainslimited,particularlyinleveraginghuman-in-the-loopapproacheswhere 5202 tcO 82 ]IA.sc[ 1v05642.0152:viXra --- Page 2 --- robotsautonomouslydetectearlysymptomsandhumansvalidateuncertaincases,and(g)continued advancementsinFMs,alongwithmulti-modalintegrationandreal-timefeedback,areexpectedto drivethenextgenerationofSSDMtechnologies.Forupdates,resources,andcontributions,please visitourAgriPathogenDatabaseGitHubrepositoryandconsidersubmittingpapers,code,ordatasets. Keywords Cropdiseases·Foundationmodels·Reinforcementlearning·Imitationlearning·Adaptivelearning· Digitaltwin·Targetspraying·Robotics·Precisionagriculture. Abbreviations Thetablebelowincludesalistofabbreviationsanditssubsequentdescriptionsusedinthereviewstudy. Abbreviations Descriptions AI Artificialintelligence AL Adaptivelearning BERT Bidirectionalencoderrepresentationsfromtransformers CLIP Contrastivelanguage-imagepre-training CNN Convolutionalneuralnetwork DINO DIstillationwithNOlabels DL Deeplearning DT Digitaltwin FM Foundationmodel GAN Generativeadversarialnetwork GPT Generativepre-trainedtransformer HS Hyperspectral IL Imitationlearning IoT Internetofthings LLM Largelanguagemodels LoRA Low-RankAdaptation ML Machinelearning MS Multispectral NLP Naturallanguageprocessing RGB Red,Green,andBlue RL Reinforcementlearning SAM Segmentanythingmodel SD Stablediffusion SSDM Site-specificdiseasemanagement UAV Unmannedaerialvehicle ViT Visiontransformer VLA Vision-language-action VLM Visionlanguagemodels YOLO YouOnlyLookOnce 1 Introduction Theapplicationofartificialintelligence(AI)hastransformedagriculturalautomationacrossdiversedomains,including weedclassificationforspotspraying [1,2],cropyieldestimation[3,4],diseasemonitoring[5,6],phenotyping[7,8], andplantbreeding[9,10].Amongthese,AI-drivencomputervisionmodelshaveemergedasparticularlyimpactful incropdiseaseandpestmanagement, whereaccuratevisualrecognitionispivotalforearlydetectionandtargeted intervention. These vision-based systems are increasingly integrated with smart sprayers and autonomous robots, enablingsite-specificfungicideapplicationwhilereducingchemicalinputsandoperationalcosts[11,12]. Amajor driverofthisprecisioncapabilityliesinthesynergybetweencomputervisionmodelsdeployedonedgesystems,which providesmachineswiththeabilitytoperceiveandinterpretcomplexagriculturalenvironments. At the heart of this development is data, large-scale image datasets, combined with the representation power of deeplearning(DL)models,havebeenpivotalintransmitting“vision”toagriculturalrobots,therebybridgingthegap betweenrawperceptionandactionableintelligenceinthefield.DespitetheseadvancementsthatDLmodels,particularly convolutionalneuralnetworks(CNNs),haveachievedtoaddresssite-specificdiseasemanagement(SSDM)incrops, theyfacenotablelimitationswhendeployedinagriculturalenvironments. Theirperformanceisoftenconstrainedby theavailabilityofannotateddatasets,whichareexpensiveandtime-consumingtocurateforthewidevarietyofcrops, diseases,andfieldconditions. Moreover,CNNmodelsoftenrequirefine-tuningortransferlearningapproacheswhen 2 --- Page 3 --- appliedtonewcrops, diseasesymptoms, orenvironmentalsettings. Thesemodelsarealsolimitedtoapplications wheremulti-modalitiesofdataisgenerated,astheycanonlytakeoneformatofdataatatime. Suchconstraintshave highlightedtheneedformoreadaptiveandgeneralizableapproaches, wherefoundationmodels(FMs), trainedon massivemulti-modaldatasetsdemonstrateclearadvantage. Theterm“foundationmodels”wasfirstusedbyresearchersatStanfordUniversity[13]. FMsarepretrainedonmassive anddiversedatasets,haveemergedasatransformativeparadigmincomputervision,withthepotentialtoovercome manylimitationsposedbyCNNmodels. Unlikeconventionalmodels,FMssuchasContrastiveLanguage-ImagePre- training(CLIP),SegmentAnything(SAM)[14,15],andGenerativePretrainedTransformer(GPT)[16]architectures, areinherentlyversatileastheycanbeadaptedtodownstreamagriculturaltaskswithminimalretrainingandarecapable offew-shotandevenzero-shotlearning[17,18]. Severalstudiesdemonstratetheirutilityincropdiseasedetectionand syntheticdatageneration,showcasingimprovedgeneralizationandrobustnesscomparedtotraditionaltask-specific models. Forinstance,thePlantCaFomodelwasdevelopedusingafew-shotapproachthatleveragesthemodel’sprior knowledge[19]. AnotherworkwasinspiredbytheCLIParchitectureandusedtheProgressiveMixupPromptLeaning (PMPL)framework,whichintegrateshierarchicalfeatureMixupwithpromptlearningforcropdiseaserecognition[20]. Theirabilitytoencodebroadsemanticunderstandingwiththehelpoftext-basedpromptshasintroducedastep-change inhowagriculturaltaskscanbeanalyzed,enablingmodelstomovebeyondnarrowclassificationtaskstowardmore context-awaredecisionsupporttools. WiththehelpofFMs,userscannowaccessinteractiveQ&Ainterfaceswhere theyuploadanimageofacropshowingdiseasesymptoms,andthemodelcanreasonaboutthepresenceofaparticular disease,unlikeconventionalmodelstrainedonlyonspecificlabels[21,22].Thisshifttransformsconventionalcomputer visionfromastaticdiagnostictoolintoadynamicalgorithmthatmakesthemuniquelysuitedforreal-timerobotic operationssuchastargetedspraying,whereadaptabilitytonovelscenarios,suchasunexpectedlightingconditions, unfamiliarcropvarieties,oroccludedtargets,isessential. Beyondperceptiontasks, theintegrationofvision-basedFMswithreinforcementlearning(RL),adaptivelearning (AL),imitationlearning(IL),androboticsrepresentsthenextfrontierinagriculturalautomation[23–25].RLallows autonomoussystemstooptimizeactionsthroughcontinuousfeedback, acriticalfeatureintaskssuchasprecision spraying,roboticscouting,orunmannedaerialsystem(UAS)-baseddiseasesurveillance[26].Adaptivelearningextends this further by enabling models to evolve with changing environmental conditions, crop growth stages, or disease dynamics,ensuringsustainedaccuracyindynamicfieldsettings[27,28].Whenembeddedwithinroboticplatforms, suchasgroundvehiclesoraerialdrones,foundationmodelscanempowerautonomoussystemstonotonlyperceive butalsoreasonandactincomplexenvironments,bridgingthegapbetweensensingandintelligentintervention. This couplingoflarge-scalepre-trainedvisionmodelswithautonomousdecision-makingframeworkssignalsaparadigm shifttowardfullyintegrated,self-improvingagriculturalrobotics. Despitetheirpromise,significantchallengesremainbeforeFMscanbefullyleveragedinagriculturaldomain,specifi- callyforcropdiseaseandpestmanagement. First ,thereisalackoflarge-scale,domain-specificbenchmarkingto assesstheirgeneralizationacrossdiversecropspeciesandfieldconditions[29]. Second ,identifyingcropdiseases isinherentlycomplexandoftenrequirestheinterventionofexpertplantpathologists. Sinceitinvolvesathorough understandingofliteratureoftencombinedwithlaboratoryvalidation,theapplicationofFMscanbechallenging. For instance,whentwodiseasesymptomsappearverysimilar,FMsmaystruggletoreasoncorrectlyabouttheircausesand differentiatebetweenthem.Insuchcases,reasoningmodelsmayalsosufferfroman“overthinking”phenomenon,gen- eratingredundantoutputsevenafteridentifyingthecorrectresult[30]. Third ,theintegrationofreasoningframeworks, RL,andadaptivemechanismswithFMsisstillinitsinfancy,limitingtheirpotentialforreal-timedecision-making inautonomoussystems[31,32]. Finally , issuessurroundingdatagovernance, modelinterpretability, andethical deploymentinagriculturalsettingsrequireurgentattention[33].Againstthisbackdrop,thisreviewprovidesatimely synthesisofthecurrentstateofFMsincropdiseaseandpestmanagement,examinestheiremergingapplicationsin adaptivelearningandrobotics,andoutlinespromisingdirectionsforfutureresearchthatmayshapethetrajectoryof agricultural AI beyond 2025. Building on current developments in leveraging FMs for real-time, feedback-driven sprayingsystems,thearticleofferreadersacomprehensiveoverviewofadvancements,identifieskeychallenges,and highlightsopportunitiesforfurtherexploration.Thespecificcontributionsofthisreviewareasfollows: 1. Examinecurrentresearchtrendstodeterminewhethereffortsareprimarilyfocusedonusinglargelanguage models(LLMs)tosynthesizeextensivecorporaofextensiontexts. 2. Investigatethegrowingemphasisonintegratingbothvisionandlanguagemodalitiestoenhancecropdisease decision-making. 3. Demonstratehowreasoning-basedmodelsaretransformingparadigms,notonlyinvision-basedsystemsbut alsothroughtextualexplanations,byengagingusersinunderstandingwhyamodelmadeaspecificdecision. 3 --- Page 4 --- 4. Explorefuturedirectionsinadaptivelearningbyfirstperformingsimulationswithindigitaltwinenvironments to test and refine models using reinforcement learning frameworks, and then developing and deploying practical,end-to-endsystemsthatcontinuouslyadapttoreal-worldfeedback. 2 MaterialsandMethods 2.1 Comprehensiveliteraturesearch Theoverallliteraturesearchandreviewanalysiswereperformedforthelastfiveyears(2019-2024),focusingontherole offoundationmodels(FMs)inadvancingsite-specificdiseasemanagement(SSDM).Beyondthiscentraltheme,the broaderaimwastoexaminehowthesemodelscouldevolveintofeedback-drivenreasoningframeworksbyintegrating digitaltwins(DT),reinforcementlearning(RL),androboticstofurthersupportSSDM.Therefore,theanalysiswas splitintotwocategories:(a)visionsystem, and(b)vision+brainforadaptivelearningandreasoninginreal-time applications(Fig.1). Foracomprehensiveliteraturesearch,twoacademicdatabaseswereselected,ScienceDirectandScopus.However, to critically provide assessment on the current technologies as per the industry 4.0 initiatives, autonomous robots forsite-specificdiseasemanagementwasalsoincluded[34].Aspartofadvancedliteraturesearch,severalkeywords wereusedinconjunctionwithmultipleBooleanoperators, “AND,”and“OR.”Additionally, retrievedpaperswere adjudicatedbasedonmultiplescreeningcriteria:(a)cropdiseaseidentificationwithanaimtoaddresssite-specific diseasemanagement,(b)peer-reviewed,(c)Englishlanguage,(d)onlyresearcharticles,and(e)duplicatepapersacross databases.Table1reportsthedifferencebetweenpapersretrievedandreportedafterliteraturesearchreviewprocess. Crop disease management through AI and robotics Vision system Vision + Brain = Adaptive learning through reasoning AI models Foundational models/GenAI s Traditional image processing Physics-based AI and Digital twin e v 01 92 90 12 s- Conventional ML tn e 1r 2r 0u 2c - Reinforcement learning ita itin i 0 .4 y rtsu d n Advanced DL Imitation learning I Figure1: Anoverviewofthereviewperformedinthisstudywithaperspectivetofocusontheindividualstepstakento addresssite-specificdiseasemanagement. 2.2 Articlescreeningcriteriaandframingquestionsderivedfromkeypoints Theoverallsearchandscreeningcriteriawasfurthersubdividedintotwocategoriesbasedontheoverallthemeof research performed in crop disease management in precision agriculture (Fig. 2). These were: (a) large-language models (LLMs) as smart advisors for crop diseases, and (b) large vision models (VLMs) for smart crop detection and textual understanding/reasoning. In the first category, technical research articles that focused on using LLMs tosynthesizetexts,suchasextensionarticlesorprescriptions,andtodevelopQ&Aplatformswereselected.Inthe secondcategory,articlesthatleveragedVLMs,suchasDINO,CLIP,orGPT,andcombinedmultimodaldatasuchas images,text,orsensorreadings(structureddata),wereincluded.Thiscategorizationwascarriedouttoreportresults anddiscussiononeachapproachtocropdiseasemanagementinprecisionagriculture. Toaccomplishthis,twokey phrasesintheadvancedsearchsectionofthedatabaseswereused.ForLLMS:(“large language models” OR “LLM” OR “foundation models”) AND (“plant disease” OR “crop disease” OR “pest management” OR “agricultural disease”), and for VLMs: (“vision language model” OR “VLM” OR “foundation 4 --- Page 5 --- Systematic literature search Perform advanced search on databases Use search keywords as per the theme of this review • ScienceDirect • Scopus • Large language models (LLMs) • Vision language models (VLMs) y g o lo d o h te Apply screening criteria Read the abstract M • peer-reviewed • English language • only technical articles • • Thoroughly read and report relevant application of foundation remove duplicate papers across the database search models • extract relevant papers from retrieved ones n Frame questions based on key points o is s u c s id d n • Evolution of vision only models • Perception + reasoning • a • Adoption trajectory • Research priorities • Year-wise trends Foundation models • LLM-VLM synergy • Emerging applications s t (2025) • Adaptive learning • Reinforcement learning • Experience- lu s driven robotics • Digital twin • Integrated approaches e R Figure 2: This review presents a systematic literature analysis focused on foundation models and their extended applicationsinsite-specificcropdiseasemanagement. Theboxontheleftillustratestheemployedmethodology,while theboxontherighthighlightskeyquestionsderivedfromtheretrievedresearcharticles. Table 1: Selected relevant publications on leveraging large language models and vision language models for crop diseaseandpestmanagement. Databases Retrievedarticles Relevantarticles (“large language models” OR “LLM” OR “foundation models”) AND (“plant disease” OR “crop disease” OR “pest management” OR “agricultural disease”) ScienceDirect 49 6 Scopus 141 5 (“vision language model” OR “VLM” OR “foundation models” OR “multi-modal”) AND (“plant disease” OR “crop disease” OR “pest management” OR “agricultural disease”) ScienceDirect 107 16 Scopus 569 11 Note:Studiesincludedwerepublishedbetween2019and2024. models” OR “multi-modal”) AND (“plant disease” OR “crop disease” OR “pest management” OR “agricultural disease”).Basedontheretrievedarticles,afewkeypointswereidentifiedandusedtoframetwo importantquestionsforresultsanalysisandeightadditionalquestionsfordiscussion(seeFig.2).Thesequestionswere: a. Whatdoestheoveralladoptiontrajectoryoffoundationmodelsincropdiseaseresearchrevealaboutthepace anddirectionofthisemergingfield? (Sec.3.1) b. Whatdoestheyear-wisedistributionoflargelanguagemodels(LLMs)andvisionlanguagemodels(VLMs)- basedstudiessuggestaboutevolvingresearchprioritiesinagriculturaldiseasemanagement? (Sec.3.2) c. Howdoestheincreasingcomplexityofimageacquisitionsensorsinfluencetheevolutionfromtraditional imageprocessingtoadvanceddeeplearning? (Sec.4.1) d. Howarefoundationmodelstransformingvisionsystemsinto‘vision+brain’frameworksthatbothperceive andreasonaboutcropdiseases? (Sec.4.2) e. Whataretheemergingtrendsintheadoptionandapplicationoffoundationmodelsforcropdiseasemanagement inthefirsthalfof2025? (Sec.4.3) 5 --- Page 6 --- f. How are reinforcement learning, adaptive learning, and experience-driven approaches being applied in agriculturalroboticsforcropdiseasemanagement? (Sec.4.4.1) g. How are digital twin technologies being leveraged for real-time monitoring and decision-making in crop diseasemanagement? (Sec.4.4.2) h. What are the benefits of combining reinforcement learning with digital twins in disease management? (Sec.4.4.3) 3 SearchResults 3.1 Whatdoestheoveralladoptiontrajectoryoffoundationmodelsincropdiseaseresearchrevealaboutthe paceanddirectionofthisemergingfield? Table1summarizestheresultsofaliteraturesearchacrosstwomajordatabasestoidentifyrecentstudiesleveraging LLMs and VLMss for crop disease management and pest control. The first query, which combined LLM-related keywordswithtermsforplantandcropdiseaseorpestmanagement,yielded49articlesfromScienceDirectand141 fromScopus,butonlyasmallsubsetdirectlyrelevanttothetopic(Table1).Althoughtheliteraturesearchcovereda five-yearperiod,themajorityofrelevantarticleswerepublishedin2023and2024.Thisindicatesthat,whileLLMs such as OpenAI’s GPT, released in 2018, are considered FMs, their application for synthesizing agricultural texts andcropdiseaseknowledgeonlybegantogainattractionaroundlate2022[35](Fig.3).Thesefindingshighlighta significantgapbetweentherapidlyexpandingbodyofAIresearchanditsdirectapplicationtoagricultural-centered crop disease and pest management, suggesting that although foundational AI methods exist, their integration into practicalagronomicsystemsremainslimited. 10 8 6 4 2 0 2019 2020 2021 2022 2023 2024 Year srepap fo rebmuN Publication trends (2019 2024) by database and theme 10 Database search themes ScienceDirect - VLM ScienceDirect - LLM ScienceDirect - VLM Scopus - LLM Scopus - VLM Scopus - VLM 6 5 Scopus - LLM 5 ScienceDirect - LLM 5 4 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Figure3: Publicationtrendsfrom2019to2024forlargelanguagemodels(LLM)andvisuallanguagemodels(VLM) acrossScienceDirectandScopusdatabases. 3.2 Whatdoestheyear-wisedistributionoflargelanguagemodels(LLMs)andvisionlanguagemodels (VLMs)-basedstudiessuggestaboutevolvingresearchprioritiesinagriculturaldiseasemanagement? Thepublicationtrendsfrom2019to2024revealanincreaseinresearchactivityonLLMsandVLMsacrossScienceDi- rectandScopusdatabases(Fig.3).ForLLM-relatedpublications,ScienceDirectshowsgrowthfrom0-1papersperyear during2019-2022to5papersin2024,indicatingafivefoldincrease,whileScopusrecordsarisefrom0papersin2019- 2022to6papersin2024,reflectingasimilartrajectory. Basedonthesearchterm(“vision language model” OR “foundational model”) AND (“plant disease” OR “crop disease”), over 107 and 569 research articles were retrieved in ScienceDirect and Scopus databases, respectively. Out of these VLM-centered research demon- strates an even sharper rise as ScienceDirect publications increase from 0-1 papers in 2019-2021 to 10 papers in 6 --- Page 7 --- 2024,representingatenfoldincrease,highlightingtherapidlygrowinginterestinvisual-languageintegrationincrop diseasediagnosticstudies. ScopusVLMpapersalsoincreasefrom0-5papersbetween2019-2023to6papersin2024, showingsteadygrowth. Notably,thelargestannualjumpoccursinScienceDirectVLMpapersbetween2023and2024, suggestingarecentsurgeinresearchactivity.Overall,thetrendsindicatethatVLMresearchisattractingmoreattention thanLLMresearch,particularlythroughtheuseofmulti-modaldatasetsandvision-basedFMs. Therelativegrowth inbothdatabasesreflectsthebroaderadoptionofFMsforapplications,suchasprompt-basedreasoningtointerpret diseasesymptomsandlarge-scaletextsynthesisfordevelopingQ&Aplatforms.Thesepatternsindicateagrowing focusonintegratingtextualandvisualdata,withVLMsemergingasacentralresearcharea. 4 Discussion 4.1 Howdoestheincreasingcomplexityofimageacquisitionsensorsinfluencetheevolutionfromtraditional imageprocessingtoadvanceddeeplearning? Current sensing platforms are the foundation for large-scale disease identification technologies, ranging from au- tonomousgroundrobotstotractor-mountedsmartsprayers.Overtheyearsthesesensorshavebeenmademorecompact inspacerequirementswithoutcompromisingonitshigh-resolutionimageacquisitioncapabilities.Threecategories ofsensingsystemutilizedlargelyfordiseaseidentificationare: RGB,multi-spectral(MS),andhyperspectral(HS) (Fig.4).Forimageacquisitioninin-fieldsettings,thesesensorsareeithermountedoncustombuiltchassisorcom- mercialized autonomous robotic platforms. Among all the three categories, RGB sensors have played a vital role inaccomplishingdiseaseidentificationtotargetsprayingtasks[36–38].WhileRGBsensorsworkonaverysmall wavelength(400-700nm),thermalsensorsarealsousedtoscoutfordiseasesandismostlyusedtomapwavelengths between8,000-14,000nm[39,40].Thesesensorsdoesnothaveaverywiderangeofapplicationsespeciallyconsidering its useful assessment in extracting more information from crops. Figure 4 showcases the inverted triangle which demonstratestheincreaseincomplexityandsensorapplicationfromRGBtoHS.Forinstance,RGBsensorsarea bestfittoclassifydiseasesthatarevisuallydistinct.Thisusecasealsofavorsitsreal-timeapplicationsabilityasthe sensordoesnotinvolvedetailedscanningofcropsinorderextractinformationinmultiplebands,unlikeMSandHS sensors.AssensorcomplexityincreasesfromRGBtoHSsensors, sodoesthevolumeanddimensionalityofdata captured,moreadvanceddataprocessingandanalyticalsolutions.ThisshifthasenabledAImodelstoprocesslarge, complexdatasetsfortimelyandaccuratediseasediagnosis. RGB MS HHanandd-h-heelldd DDSSLLRR RoWboattsaonnist Amifgaar m(fa-rnmg-ng) RWobaottsaonnist DDJJII PPhhaannttoomm 4 4 P rPoro • well-suited for real-time applications • faster processing times • large-scale image HS processing • best fit for visually distinct symptoms • low-cost and easily available MicaSense-RedEdge-P RedEdge-P dual Parrot SEQUOIA+ Sentera Snapshot • useful for plant stress identification • usually expensive • infused with spectral richness • requires calibration for goof results • occupies more storage space Specim FX17 Resonon Senop Black Mobile V2 CHNSpec-FS-IQ • extremely detailed spectral signatures • useful for early disease identification • large data volume • expensive • demands sophisticated analysis Figure4: Differentcategoriesofsensingsystemsandplatformsusedindiseaseimageacquisition.Theinvertedtriangle includes: RGB,multispectral(MS),andhyperspectral(HS)sensorswhereitsapplicationinsensingdiseaseinformation increasesfromRGBtoHS. 7 --- Page 8 --- TheintegrationofAImodels,particularlythosetrainedonnumerousexamplesoflarge-scalediseasedatasets,has significantly advanced the ability to monitor crops in real-time for disease threats. Between 2010 and 2017, most studiesreliedonleveragingeithertraditionalimageprocessingorconventionalmachinelearning(ML)modelbased onhandcraftedfeaturestoperformdiseaseclassificationtasksincropssuchastomato,grapes,andmaize[41–44] (Fig.1).Althoughtheseapproacheswerelimitedinscaleandreal-timecapability,itprovidedfoundationalresearch breakthroughsincropdiseaseidentification. Buildingonthisfoundation,deeplearning(DL)techniques,particularly, convolutionalneuralnetworks(CNNs),begantodominatethefieldpost2017.Thesemodelssignificantlyoutperformed traditional methods by automatically extracting high-level features from raw image data, eliminating the need for manual feature engineering. Because of this attribute, these models come in different sizes where optimizing and integratingtheseonsUAS,edgecomputingdevices,androboticplatformshavebecomepossible. OntheAImodelarchitectureside,thefirstwaveofCNN-basedmodelsforcropdiseaseclassemergedwithtransfer learning(2012-2015),wherepretrainedCNNssuchasAlexNet,VGG,andResNetwereadaptedtocropdiseasedatasets, significantlyimprovingclassificationaccuracydespitelimiteddata[45,46].Thesecondwave(2016-2019)sawreal-time objectdetectionmodelslikeFasterR-CNN,YOLO,andSSDappliedtobothidentifyandlocalizemultiplediseases withincropcanopies, enablingtargetedsprayingstrategies[47,48]. Morerecently, startingaround2020onwards, transformer-based architectures and hybrid CNN-transformer models have been introduced, leveraging attention mechanismstocaptureglobalcontextandfine-grainedspatialrelationships,furtherimprovingdiseaserecognitionand robustnessacrossvaryingfieldconditions[49,50].Together,theseadvancesinsensormodalitiesandlearningparadigms havelaidthefoundationfornext-generationprecisionagriculturesystemscapableofreal-timediseasemonitoringand autonomousspraying.Buildingontheseadvances,theriseofFMsmarksthenextleap,unifyingmulti-modalsensor dataandlearningmethodsintoscalable,generalizableframeworksforagriculturaldiseasemanagement,capabilitiesnot possibleafewyearsago. 4.2 Howarefoundationmodelstransformingvisionsystemsinto‘vision+brain’frameworksthatboth perceiveandreasonaboutcropdiseases? AsdiscussedinSection4.1,traditionalMLoradvancedDLalgorithmsweremostlytrainedononeformatofdataset, eitherimagesorstructureddataset,andnotboth. Onthecontrary,FMshavetheabilitytobetrainedonaverydiverse setofmulti-modaldatainthecontextofmanagingcropdiseases[51].Forinstance,FMstrainedonmillionsofimages, weatherpattern,soildata,andagriculturalextensionrecords(ortexts)canunderstandcropdiseasesvisually,interpret historicaldiseasereports,andevenprocesssensordataforpossiblediseaseoutbreaks.Thiscouldbeagame-changing application for growers and farmers, who not only wants to identify a particular disease with high accuracy, but also receive an explanation, suggested treatments, or an explanation how a particular disease could spread under diverse weather conditions. What makes a FM powerful is their ability to adapt to dynamic in-field conditions. A model originally trained on wheatcrop diseases in India can, with minimal adaptation, can also help a strawberry growerinFlorida.Therefore,a“true”FMisnotdefinedbyitsarchitecture,butbyitstrainingscale,generalizability, andtransferabilityacrosstasks(Fig.5).Amodelcanonlybeconsidered“foundational”ifitsatisfiesthefollowing criteria: (a)itispre-trainedonamassiveanddiversedatasetthatspansmultipledomains,(b)adaptabletosuitmultiple downstreamtaskspertainingtodetection,segmentationorevenreasoning,achievedthroughfine-tuningorfew-shot learning,(c)supportscross-modalormultimodalinputs,asseeninGPT-4[16],CLIP[52],andFlamingo[53].Without fulfillingthesecriteria,eventhemostpowerfulmodelwillbeaccuratelydescribedasatask-specificdeeplearning model,notafoundationalone. In the context of crop disease management in precision agriculture applications, the application of FMs could be integratedwithmultipleaspectsofdatamodalities:(a)language,(b)vision,and(c)vision-language-action(VLA).These modalitiesrepresentdifferentlayersofhowFMscanperceive,interpret,andactuponcomplexagriculturalenvironments. Language-basedmodelsenableinterpretationofextensionarticles,scientificliterature,orevengrower-centeredqueries innaturallanguage.Whereas,vision-basedmodelsfocusofextractingrelevantdisease-specificfeatures,suchaslesions andcanopystructure, fromdronesorground-robots.TheVLAintegrationextendsthesecapabilitiesbyextending reasoningandperception-baseddecision-making,allowingthesystemtoactautonomouslyinvarioustaskspertaining to spraying or alerting based on contextual understanding. Together, these modalities enable a holistic, intelligent frameworkforsite-specificdiseasemanagement,whichwasnotpossibleafewyearsago. 4.2.1 Largelanguagemodels(LLMs)assmartadvisorsforcropdiseases LLMsareemergingaspowerful“smartadvisors”forcropdiseasemanagementbysynthesizingscientificliterature, extensionmaterials,andlocalguidelinesintoconcise,actionabletextsthatcanbeunderstoodbygrowers,extension educators,andfarmers,alike. Forinstance,generativechatbotsandretrievalaugmentedsystem(RAG)-stylesystems have been deployed to deliver localized recommendations, answer farmer questions in natural language, and turn 8 --- Page 9 --- Multimodal data source Disease monitoring and management Disease Symptoms txeT sega m I Textual reasoning classificationand detection Q. What does this lesion mean? mage A le. s G ioi nve s,n i tr a ci on uy l dc o bn ed ait nio thn rs a a cn nd o st eh e cs ae u sed e I by fungus Colletotrichum orbiculare. cio v n a m u Adaptive smart H Training spraying Foundational model Adaptations that mimics human- Column 1 Column 2 Column 3 Column 4 level understanding ata 1 2 3 4 d d 9 11 45 78 e ru 56 67 89 09 tcu 54 32 48 81 rtS 33 78 90 50 sro sn e irgAs- Figure5:Overviewofafoundationalmodel-basedframeworkforcropdiseasediagnosticsandmanagement.Multimodal datasourcesincludingimages,textualdescriptions,structureddataset,andagri-sensorsdata. Ontheright,diverse downstreamapplicationssuchasdiseaseclassification,imagegeneration,smartspraying,questionanswering,and roboticnavigationareenabledbythemodel’sreasoningandgeneralizationcapabilities. complexresearchfindingsintostep-by-stepdiseasemanagementadvice(Link).ResearchershaveshownthatLLMscan summarizediseasesandpestslifecycles,generatetreatmentprotocols,producemultilingualextensioninformation,and generatescriptedtroubleshootingflowsforfieldtechnicians,ataskthatdirectlyreducethetimebetweenobservation andintervention[54,55]. Multi-modalextensionsofLLMsthatcombinecombineimageencoderswithtextdecodersarebeginningtolinkvisual diseasediagnosiswithtextgeneration,allowingausertouploadaleafphotoandreceivebothalikelydiagnosisandan extension-stylerecommendation.Inpractice,thesecapabilitiescanhelpsmall-scalefarmersandextensioneducatorsby: (1)generatinglocalizedmanagementplans(inlocallanguages)fromregionalweather/phenologydata,(2)converting researchpapersintofarmer-friendlyprotocols,and(3)producingtrainingmodulesandquizmaterialforextension workshops.AfewrecentstudieshaveleveragedLLMstosynthesizelargecorporaofagriculturaltextsandgenerate targetedsolutionsforspecificproblems.Forinstance,combiningLLMswithagriculturalknowledgegraphsenables efficientreasoningovercomplexdiseasesymptoms,providingaccurateplantdiseasedetectionguidance[54].LLMs canalsoautomatethesynthesisofpestcontrolliterature,reducingtheburdenofmanualreviewandrapidlyoffering actionableinsights[56]. Theirbroaderpotentialincropproductionincludessummarizingvastamountsofliterature andsupportingdecision-making[57].Beyondtextsynthesis,integratingLLMswithsensordataallowsplanthealth monitoringtobequeriedandexplainedinnaturallanguage[58].Atthesystemiclevel,LLMscanenhanceagricultural extensionservices, providingfarmerswithtimelyandcontextuallyaccuraterecommendationsondiseaseandpest management[55]. Table2summarizesstate-of-the-artLLMarchitecturesusedtosynthesizelarge-scaleinformation withrespecttocropdiseasesandpestmanagementinprecisionagricultureresearch. 4.2.2 Visionlanguagemodels(VLMs)forcropdiseasedetectionthroughreasoning Visionlanguagemodels(VLMs)forcropdiseasediagnosisoffertransformativeapproachtoplanthealthmonitoring anddiseaseclassification. ThesemodelsarebuiltonarchitectureslikeVisionTransformers(ViT)orself-supervised frameworks,suchasDINO,MAE,orCLIP,arepre-trainedonmassive,diverseimagedatasetsandcangeneralizeacross awiderangeofvisualtask. WhileViTsorothersimilararchitecturesarecommonlyusedinplantdiseasediagnosis tasks,itisimportanttonotethattheirusealonedoesnotqualifyamodelasfoundational.Forinstance,theapplication ofViTtoaccuratelydetectandclassifyJavaPlumleafdiseaseonlimitedsamplesofsixclassesdoesnotqualifytobea FMforcropdiseasediagnosis[59]. Anotherstudyby[60]usedover40,000imagesfromvariousopen-accessplatforms 9 --- Page 10 --- Table2: Summaryofrecentstudiesapplyinglargelanguagemodels(LLMs)foragriculturaltextsynthesis,diseasemanagement,andextensionservices. Approach/Models Open-accesssource Usecases Journal References 2024 UsedLLMwithAgriculturalKnowledge Nameofthemodelnot Plantdiseasediagnosissystems, MDPI(agriculture) [54] Graphs(KGs),GraphNeuralNetworks specified reasoningoversymptomdescriptions, (GNNs) linkingtextualdiseasecorporawith structuredknowledge UsedGPT-4(OpenAIAPI)forautomated Proprietary(OpenAI),not Automatingsystematicreviewsinpest MethodsinEcologyandEvolution [56] literaturesynthesisonpestcontrollers open-source control,reducingexpertworkloadin literaturemining ExperimentedwithGPT-basedlanguage Proprietary(OpenAI),not Query-basedplanthealthmonitoring. InternationalJournalofComputer [58] modelstoprocesssensor+textqueries open-source Example:“Whyismyleafshowing ApplicationsinTechnology yellowing?”explainedusingsensor readings+LLMreasoning Question-answeringsystemsin — Processingagriculturalqueries, Resources,ConservationandRecycling [61] agriculture(coveringcorpora,knowledge includingplantdiseasediagnosis,pest graphs,largelanguagemodelslike identification,anddiseasecontrol,using GPT-4) Q&Asystemsforintelligentproduction andsustainablemanagement GlyReShot(glyph-awarefew-shot — Recognizingentitieslikediseases,crop, Heliyon [62] Chineseagriculturalnamedentity pest,anddruginChineseagricultural recognitionintegratingalightweight text,includingimprovedrecognitionof GROMmoduleandtraining-freelabel plantdiseaseentitiesunderscarce refinementstrategy) labeleddataconditions RAGchatbotcombininghybridDeiT+ Notexplicitlyavailable Identifyingmedicinalplants(via TelematicsandInformaticsReport [63] VGG16CNNmodelformedicinalplant images)andgeneratingbilingual identificationandinsights,incorporates insights(Nepali&English),including Retrieval-AugmentedGenerationand healthbenefits,cultivationtips,using explainableAI hybriddeeplearning+RAG AgriculturalKnowledgeGraph(AGKG): Notspecified AgriculturalentityretrievalandQ&A Displays [64] integratesNLPanddeeplearningwith viadomain-specificAGKGbuiltfrom LLMstoautomaticallyextract Internetdata agriculturalentitiesandconstructa knowledgegraphforengineering technologyapplications 2023 UsedGPT-3.5foragriculturalextension Proprietary(OpenAI),but Farmeradvisorychatbots,pestand NatureFood [55] services canbereplicatedwithopen diseasediagnosis,locallanguage HuggingFacemodels extensionsupport ChatAgri(ChatGPT-basedagricultural GitHublink Cross-linguisticagriculturalnewstext Neurocomputing [65] textclassificationusingprompt classification;few-shotand engineeringstrategiesacrosslanguages) prompt-basedclassificationusing GPT-3.5andGPT-4 10 --- Page 11 --- Table2(continued) Approach/Models Open-accesssource Usecases Journal References 2022 AgriBERT(BERT-based,pretrainedon — Semanticmatchingoffooddescriptions InternationalJointConferenceson [66] 300Magri-foodtokens, tonutritionentries,cuisine ArtificialIntelligence(IJCAI)2022 knowledge-infusedwith classification,andagriculturalNLP FoodOn/Wikidata) tasks 2018 OriginalGPTpre-trainingpaper Notopen-sourceatthetime, Laidfoundationworkforallthelater OpenAI [35] (OpenAI) laterGPT-2/3derivatives agriculturalLLMapplications inspiredopen-source releases 11 --- Page 12 --- tointegratevisiontransformerswithCNNstoaddressdiseaseclassificationinmultiplecrops. Althoughthenumber ofdatasetusedinthisresearchwasmoderatelylarge-scale, itdidnotinvolveanycross-domainadaptations, akey requirementforamodeltobecalledasaFM.Therefore,aFMshouldgobeyondclassificationtaskanddemonstrate broadgeneralizationacrosscrops,sensormodalities,anddiseasetypes,therebyhighlightingitsversatilityandcross- domainadaptations. Inarecentstudy,theauthorsproposedavision-languageframeworkthatusestextspromptstoguideavisionmodel fordiseaseanomalydetection[67]. Anothernotableworkfrom2023integratedtheYouOnlyLookOnce(YOLO) modelwithGPT-guidedtextualunderstandingtogeneratecropdiagnosticsreport[68].Similarly,[69]employedthe Segment Anything Model (SAM) to first isolate wheat diseases and then applied a reasoning chain framework to generatewell-structureddiagnosticexplanations.Inanotherstudy,afew-shotlearningtechniquewasappliedtotrain the PlantCaFo model for disease recognition [19]. With this growing interest in this space, it is evident that FMs willplayadominantroleinfutureagriculturalAIresearch,particularlyinsupportingmulti-modaloutputs,notjust classification,butexplanation,generation,andrecommendationswithreasoning. Thismirrorstrendsobservedinthe earlyevolutionofDL,whereCNN-basedapproachesinitiallydominatedbeforebeingsurpassedbymoregeneralized models.Additionally,mostoftheexistingstudiesmostlyrelyonpre-existingmodels,suchasGPT,CLIP,orSAM, whicharethenfine-tunedonagricultural-centeredtexts.Althoughthesemodelscanbeadaptedthroughone-shotor few-shot learning, their veracity remains limited when it comes to handling domain-specific terminology in plant pathology. Someexistingdomain-specificmodels(BERT-basedmodels),suchasAgriBERT,doexist,buttheseare relativelysmall-scaleandareprimarilytailoredfornaturallanguageprocessing(NLP)tasks,ratherthanservingasfull LLMs[66]. Table3summarizestheapplicationofmulti-modalVLMsspecificallyusedtosynthesizetextsandpresent reasoningwithrespecttodiseasedleafimages. 4.3 Whataretheemergingtrendsintheadoptionandapplicationoffoundationmodelsforcropdisease managementinthefirsthalfof2025? In2025,cropdiseaseandpestmanagementusingAIapproachesisshiftingfromsimplevisionclassifierstowardFM pipelinesthataremulti-modalandlabel-efficient.VLMs,CLIP-stylebackbones,diffusiongenerators,andFMadapters arebeingintegratedwithvariousspectralandphysiologicalinformationaboutcropdiseases.Additionally,FMsare beingintegratedwithroboticstoenablediagnosis,explanation,andaction. Thestudiesbelowhighlightemergingtrends intheirapplicationtoSSDMinprecisionagriculture. Theseare: a. Domain-adaptedVLMsreplacetask-specificCNNs: ThedevelopmentofPlantCaFodemonstratedthat FMscouldbeusedforcropdiseasetasksthroughlightweightadaptersandweightdecomposition,enabling accurateclassificationeveninfew-shotscenarios[19].Inparallel,FMs,suchasDINOv2couldbeeffectively repurposedfortaskssuchascropdiseaserecognitionwithminimaladaptation.Toenhancepracticalityand efficiency,thestudyemployedstrategiesincludinglinearprobing,parameter-efficientfine-tuningusingLoRA techniques,andknowledgedistillationintosmallerarchitectureslikeMobileNetV3[70]. b. Few-shot/zero-shotwithpromptoradaptertuningbecomespractical: Furtheradvancementsinthefield havealsobeenfueledduetoapproachessuchasone-shotandfew-shot. Forinstance,ProgressiveMixup PromptLearningcombinedwithCLIPDynamicCalibration(CDC)introducedaninnovativeapproachto unsupervisedtest-timedomainadaptation,enablingmodelstogeneralizetonoveldiseasedatasetswithout relyingonfullysupervisedretraining[20].Complementingthis,ChatLeafDiseasedemonstratestheeffective integration of LLM chain-of-thought reasoning with curated disease descriptions, achieving training-free tomatodiseaseclassificationthatsurpassesgenericGPTandvision-languagemodelbaselines[71]. c. Multi-modal fusion (image + language +spectral signatures) improves disease assessment and field robustness: Recent works in 2025 also highlights an merging trend where researchers are increasingly integratingVLMswithLLMstonotonlydetectcropdiseasesbutalsogenerateactionableprescriptionsfor farmers.Forinstance,aDL-basedcomputervisionmodel,YOLO,wasintegratedwithanLLMtogenerate bothcropdetectionandtreatmentrecommendations[72]. AnotherworkdevelopedtheSCOLD(Soft-target COntrastiveLearningforLeafDiseaseidentification)modelandtraineditonover186,000image-caption pairscovering97uniqueconceptstoaddresscontext-awarecropdiseaseclassification[21]. d. Text-to-image-basedsyntheticgenerationofcropdiseaseimages:Togainmorecontroloverthegenerated images,researchershavestartedutilizingtextpromptstodescribespecificdiseasesymptomssuchaslesion color,shape,orleaftexture. Forinstance,workby[73]comparedthreeStableDiffusion(SD)architectures, SDXL,SD3.5-medium,andSD3.5-large,togeneraterealisticlookingimagesmultiplediseasesinwatermelons (Fig. 6). Their research found out that training as small as 36 real images could generate 500 (or more) syntheticimagesofvaryingenvironmentalanddynamicbackgroundswhentrainedonA100NvidiaGPUfor only1.5hours. 12 --- Page 13 --- Table3: Summaryofrecentstudiesapplyingvisionlanguagemodels(VLMs)tocombinebothimagesandtextsofcropdiseasesforcontext-basedreasoningand learning. Models Type Open-accesssource Usecases Journal References 2024 DINOv2 Visionmodel HuggingFace Self-supervisedfeatureextraction, ScienceDirect [74] clusteringofdiseasesymptoms BLIP/BLIP-2 Multi-modalmodel HuggingFace Imagecaptioningandvisualreasoningfor [75] diseaseexplanation LLaVA Multi-modalmodel HuggingFace Multi-modalreasoningforplantdisease [76] recognition SAM VLM Facebook Wheatdiseasediagnosisthroughreasoning ScienceDirect [69] ViT+GPT-2 VLM OpenAI,HuggingFace Alignplantdiseasephenotypeswithtrait PlantPhenomics [77] descriptions Inception-v4+LSTM VLM — Aligningcropdiseaseimageswithquestion PlantPhenomics [78] embeddings PDC-VLD Multi-modal(vision+text) Nospecificmention Tomatoleafdiseasedetectionwithunseen PlantPhenomics [79] classgeneralization FHTW-Net Visionlanguagemodel GitHub(Nospecific Retrievematchingtextfromaqueryimage PlantPhenomics [80] (image-textretrieval) mentionofthemodel) (andviceversa)forriceleafdisease descriptions Amulti-modalChinese Multi-modalprompting+ Notspecified Identifyingdiseases,pests,andcontrol Computersand [81] model texts relatedentitiesinChineseagriculturaltexts Electronicsin Agriculture ILCD(Informed-learning Multi-modalvisual GitHub Thedevleopedmodeladdressedcomplex PlantPhenomics [78] guidedmodelofcrop questionansweringmodel questionsaboutcropdiseasestagesand diseases) attributes PhenoTraittextdescription Multi-modal(image-to-text PlanText Novelmodelgeneratesplantdiseasetext PlantPhenomics [77] model(GPT-4and generation) fromimages GPT-4o) Multi-modalvegetable Multi-modalknowledge Notspecified Usedasafoundationaltooltoextractand Computersand [82] knowledgegraph(No graphconstruction processknowledgefromtext Electronicsin specificmodelname) Agriculture Namenotspecified Multi-modalfoundation Notspecified Vision-languagemodelwithvisual Computersand [67] model informationtoimproveperformanceon Electronicsin fine-grainedplantdiseaseanomaly Agriculture detection WDLM(Wheatdisease Visuallanguagemodel Notspecified Fine-tuningfoundationmodelsforwheat Computersand [69] languagemodel) (VLM) diseasediagnosis Electronicsin Agriculture PepperNet Multi-modal Notspecified Detectingpepperdiseasesandpestsin Nature-Scientific [29] vision-languagemodel complexagriculturalenvironmentsusing Reports naturallanguagedescriptions 13 --- Page 14 --- Table3(continued) Models Type Open-accesssource Usecases Journal References APD-229(Agricultural Multi-modal Linkisgivenbutdoesnot Amulti-modalapproachthatusestext MultimediaToolsand [83] pestsanddiseases) (Textual-Visual) work descriptionstoguideanimagerecognition Application systemforfine-grainedclassification Qwen-VL Pre-trainedVLM GoogleDrive(Onlydataset, Usedtogeneratemeticuloustext MDPI(sensors) [84] nospecifiedmodel) descriptionsfordiseaseimages,whichserve asprompttextforgeneratingclassifier weights SegmentAnythingModel Imagesegmentation SAM-MetaAI Indentifiesandsegmentsoutallthe IEEEAccess [85] (SAM) suggestedregionswithinthediseasedleaf image Specificnamenot Fine-tuningparadigmsfor GitHub multi-modalmodel(specifically,a NatureScientific [86] mentioned out-of-distributiondetection visual-languagemodel)wasusedtoexplore Reports itseffectivenessinOODplantdisease detection Visualanswermodel Multi-modalVQA Notspecified Amodeldesignedtoanswerquestions FrontiersinPlant [22] (VQA) aboutfruittreediseasesbyfusingimage Science andQ&Aknowledge 2023 ITLMLP(Image-to-text Visionlanguage Notspecified Few-shotlearningtorecognizecucumber Computersand [87] multi-modalmodel) pre-training diseasesusingamulti-modalapproachthat Electronicsin combinesimage,text,andlabelinformation Agriculture YOLOandGPTcombined Multi-modalmodel GitHub,OpenAI Usedforitsdeeplogicalreasoning Computersand [68] capabilitiestogenerateagricultural Electronicsin diagnosticreports Agriculture ITF-WPImodel Cross-modalfeaturefusion GitHub Theproposedmodelovercomesthe Computersand [88] model challengesofcomplexagricultural Electronicsin backgroundsbyusingcross-modaldata Agriculture (imagesandtext)forwolfberrypest identification Specificnamenot Neuro-symbolicAI(deep GitHub Themainapproachdevelopedtoimprove ExpertSystemswith [89] mentioned learning+knowledge predictionaccuracyandgenerateuser-level, Applications graphs) understandableexplanationsfor non-experts,suchasfarmers,bycombining deeplearningwithdomainknowledge ShuffleNetV2+TextCNN Multi-modalmodel Notspecified Modelsareusedtoextracttextualfeatures Nature-Scientific [90] andsemanticrelationshipsfromdescriptive Report text MMFGT(Multimodal Multi-modaltransformer Notspecified Anovelmodelforfew-shotpestrecognition MDPI(electronics) [91] fine-grainedtransformer) model thatcombinesmulti-modalinformation fromimagesandtext 14 --- Page 15 --- Table3(continued) Models Type Open-accesssource Usecases Journal References ODP-Tranformer Multi-modal(image-to-text Notspecified Atwo-stagemodelproposedtointerpret Computersand [92] generation+classification) pestimageclassificationresultsby Electronicsin generatingcaptions,inadditionto Agriculture predictinglabels 2021 ITK-Net Multi-modal Notspecified Theprimarymodeldevelopedtoidentify Computersand [93] (Image-text-Knowledge (Image-text-Knowledge) commoninvasivediseasesintomatoand Electronicsin Network) cucumberbyleveragingmultimodaldata Agriculture andhigh-leveldomainknowledge 15 --- Page 16 --- Example illustrating the impact of disease description text (a) (original vs. condensed) on the scoring process of the ChatLD framework (Pan et al., 2025). Image generation using a multi-modal Stable Diffusion model (b) fine-tuned using LoRA and Dreambooth techniques, and applying prompt engineering to produce synthetic images (Rai et al., 2025). Figure6: Examplerepresentingtheroleoffoundationmodels(FMs)inthecontextofcropdiseaseresearch,including vision-languageintegration,text-to-imagegeneration,andmulti-modalscoringframeworks. 4.4 Closingtheloopincropdiseasemanagementbyintegratingreinforcementlearninganddigitaltwinsin cyber-physicalsystem Amajorfuturedirectionforprecisioncropdiseaseandpestmanagementisthetransitionfromperception-drivensystems toclosed-loop,feedback-basedlearningframeworks(sense→simulate→decide→act→update).Twocomplementary technologiesarecentraltothisvision: reinforcementlearning(RL)anddigitaltwins(DTs).Reinforcementlearning (RL)isanAIapproachinwhichanagentdiscoversthebestactionsbyinteractingwithitsenvironmentandlearning fromtrialanderror[94].DTs,incontrast,aredata-drivenvirtualreplicasofrealfarmsystemsthatstaysyncedwithlive sensorstreams.IntegrationofRLandDTsenableadaptivedecision-making.Forexample,RLcanoptimizerobotic sprayersunderthehighlyvariableconditionsfoundinthefield,whileDTscansimulatediseasedynamics,cropgrowth, andmanagementstrategiesunderdifferentscenarios.Whenfedreal-timesensordataandAIpredictions,DTscan simulatetheoutcomesofproposedinterventions,providingasafeenvironmentforRLagentstorefinepoliciesbefore deployment.Thissectionsurveysstate-of-the-artapplicationsofRLinagriculturalroboticsandspraying,theuseof digitaltwinsforcropmonitoringandsimulation,theircombinedroleindisease-specificpesticidespraying,real-world casestudies,andforward-lookingperspectivesontheseemergingtechnologies. 4.4.1 Howarereinforcementlearning,adaptivelearning,andexperience-drivenapproachesbeingappliedin agriculturalroboticsforcropdiseasemanagement? RecentadvancementsinRLhavedemonstratedsignificantpotentialfortransformingprecisionagriculturethrough autonomoustechnologies[95,96].Thesedevelopmentsencompassawiderangeofagriculturalroboticsapplications, fromautonomousnavigation[97,98]andhardwarecontrol[99,100]toprecisionresourceapplicationsystems[101, 102].Modernprecisionagriculturedemandsintelligentsystemscapableofmakingcomplexdecisionsindynamicfield environments,andRLprovidesaframeworkfordevelopingautonomoustechnologiesthatcanadapttovaryingcrop conditions,weatherpatterns,andfieldcharacteristics.Precisionsprayingservesasonecompellingexampleofthis broadertransformationtowardintelligent,data-drivenagriculturaltechnologies,demonstratinghowRLcanoptimize bothoperationalefficiencyandenvironmentalsustainability(Fig.7).AlthoughRLapplicationsinprecisionagriculture arestillemerging,existingexamplesillustratearangeofusesfromlow-levelhardwarecontroltohigh-levelstrategic decision-making,potentiallyaddressingfundamentalchallengesoftraditionalrule-basedcropmanagementsystems. 16 --- Page 17 --- Reinforcement Learning Pipeline andrelaytothe controlagent Observation pture ca ata d d Fiel Disease Healthy Reward Agent • From Agent to Reward is a loop in which the Agent learns from trial-and-error approach. • During positive rewards, the Agent learns to do more of good spraying. • During negative rewards, the Agent learns to avoid ward AgentdeterminU inA gV ths eactionreS sm poa nrt s esprayers Targeted fungicide sprsp ar yay ining g on healthy crops Fb ey e r ded bu ac ci kng is c ph re om viic da el d w ia ns tt he e. form ofscalarre Figure 7: The overall agent and reward components of reinforcement learning for leveraging site-specific disease managementinprecisionagriculture. Unlikeconventionalrule-basedagriculturalsystems,RL-enabledtechnologieslearnfromcontinuousfielddataand operationaloutcomes,enablingmoresophisticatedandcontext-awaredecision-makingprocesses.Forexample,[103] developedanRL-baseddecisionsystemforUAVcropsprayersthatdynamicallyadjustssprayvolume,dropletsize,and flightheightbasedonreal-timecropcharacteristics. Theiractor-criticneuralnetwork,trainedoncomprehensivefield experimentdata,achieveda14%reductioninpesticidevolumeacrosswheatfieldswhilemaintainingequivalentpest controlefficacy,demonstratingthepotentialforresourceoptimizationacrossagriculturaloperations.Otherstudieshave useddeepRLforpathplanningsounmannedaerialvehicle(UAV)onlytreatinfectedzones,avoidinghealthycropsto savechemicals. Inarecentsimulation,ahierarchicalRLagentwastrainedtonavigateafieldandsprayonlydiseased plants,significantlyimprovingyieldprotectionwhilereducingunnecessaryspraying[23].BeyondasingleUAV,RL hasbeenextendedtocomplex,multi-robotsprayingscenarios.Inasimulationstudy,[104]exploredhowon-policy reinforcement-learningalgorithmscouldcoordinatemultipleUAVsandgroundvehiclesforcropspraying.OneRL agentplannedefficientcoveragepathsforseveraldrones,whileasecondagentcontinuallyadjustedeachUAV’sposition tocountersimulatedwinddrift. Innarrowfieldsections,theframeworkreassignedsprayingdutiestogroundrobots, demonstratinghowhybridairandgroundagentsmightimproveoverallefficiency. RLforcropdiseasemanagementisnotlimitedtoroboticshardwarecontrol. RLalsooffersaframeworkfordecision supportsystemsinpestcontrol. Bycastingsprayingschedulesasasequentialdecisionproblem,RLcanlearnwhen andhowmuchtospraybasedonpestordiseasepopulationdynamics. Forexample,[102]addressedtheproblemofan orchardmanagerdecidingwhethertoapplypesticidesateachtimestepgivenpestpopulationlevels.Theyformulated this scenario as an RL challenge and developed a reinforcement learning method that computes spraying policies likelytoperformwelldespitenoisy,imperfectpestdata. TheRLagentessentiallylearnsanoptimalintegratedpest managementstrategy(whentosprayorholdoff)thatmaximizeslong-termorchardhealthandyield. Byincorporating uncertainty(viaBayesianmodelingandrobustoptimization),theirapproachyieldspestcontrolpoliciesthatremain effectiveevenwithincompleteinformation. 4.4.2 Howaredigitaltwintechnologiesbeingleveragedforreal-timemonitoringanddecision-makingincrop diseasemanagement? Digitaltwintechnologyisrapidlygainingtractioninprecisionagricultureasameanstomodelandsimulatecrop systemsforbettermonitoringanddecision-making.Adigitaltwinisessentiallyavirtualrepresentationofaphysical 17 --- Page 18 --- entity(croporfarm)thatiscontinuouslyupdatedwithreal-worlddata[105–109](Fig.8).Inagriculture,digitaltwins canintegratesensorreadings,suchassoilmoisture,weather,crophealthimageswithcropmodelstomirrorthefield’s stateinrealtime.Thisallowsgrowersandresearcherstovisualizeconditions,run“what-if”scenarios,andpredict futureoutcomeswithoutriskingtheactualcrop.Forexample,[109]describea“Digital-TwinOrchard”concept: a virtualmodelofeachtreeinanorchard,pairedwithreal-timedataonthattree’scondition. Intheirstudy,3DLiDAR andcamerasystemsontractorsweredeployedtoscanthousandsoforchardtreesandcreatetheirvirtualcounterpartsin realtime.Over15,000mango,macadamia,avocado,andgrapevinetreesweredigitized,andthedatawasusedtomodel canopycharacteristicsandhealthindicators. Suchasystemenablescontinuousmonitoringoforchardhealth,predicting plantstress,diseaseonset,andyieldlossesacrossthefarm. Capturi ng data Physical space se ns or d at a Simulating Virtual space Digital twin Robotic arm Virtual replica of the field Hybrid simulations Data acquisition + ng • fruit maturity • leaf/canopy texture • disease progression Real-time processing Decision-maki Model updat• in p gest outbreaks • optim siz imin ug l an tu iotr nie snt intake • energy-based Figure8: Schematicrepresentationofadigitaltwinframeworkactingasabridgebetweenthephysicalandvirtual spaces. Real-world data from sensors are continuously synchronized with virtual simulations, enabling predictive analytics,scenariotesting,anddecision-making.Insightsfromthedigital(virtual)spacearethentransferredbacktothe physicalsystemthroughactuatorcontrol,creatingaclosed-loopcycleofmonitoring,simulation,andintervention. Whilethisprojectfocusedonmonitoring(e.g. foliagedensity,lightpenetration)ratherthanautomatedspraying,it laysthegroundworkfortree-specificdiseasemanagementandAI-drivendecisionsupportplatform,whereonecould test, forinstance, howanewsprayingregimenorpruningstrategymightimpactdiseasespreadbeforeapplyingit ontherealorchard.SeveralrecentstudieshighlighttheeffectivenessofDTsforcropmonitoringandsimulation. In a 2024 study, [107] built an agricultural digital twin for mandarin orange orchards. By aggregating big data from 185,000hectaresofmandarinfarmsintoavirtualplatform,theycouldanalyzevariationsinfruitqualityatregional, orchard, andeventreelevel. Theirintra-orcharddigitaltwinanalysisexplainedfruitqualityvariationmuchbetter thanbroadinter-orcharddata,demonstratinghowdigitaltwinsenable“micro-precision”agriculturewhereeachplant couldreceivecustomizedtreatmentbasedonitsdigitalprofile.Anotherexampleisthedigitaltwinsystemforpepper pestmanagementreportedby[110].Thissystemcreatedavirtualgreenhouseofpepperplantsinfestedwithaphids, continuouslyfedbyIoTsensorsandcameradata. Thetwinemployedapredictivemodel(geneticalgorithm-optimized randomforest)toforecastpestpopulationtrends,anditevaluatedcontrolactionsinsimulationtorecommendoptimal intervention. Intrials,thedigitaltwinaccuratelypredictedaphidpopulationchanges(≈85%accuracy)andhelped optimizesprayingdecisions,improvingeconomicoutcomesbyover20%comparedtothegrowers’standardpractice. Despitethesepromisingdevelopments,theadoptionofDTsinagricultureisstillatanearlystage. Reviewsofthefield indicatethatmanydigitaltwinapplicationsremainproof-of-conceptorconfinedtolab/pilotstudies. Forinstance,using digitaltwinsforcropgrowthanddiseasepredictivemonitoringislargelyintheresearchphase,andcertainareassuch assoilhealthmanagementhaveseenonlylimitedexploration[64].Challengesincludethecomplexityofbiological systems, the need for extensive data integration, and the real-time synchronization required between the physical farmanditsvirtualcounterpart.Nevertheless,thetrajectoryisclear: assensingtechnologies,datainfrastructure,and modelingtechniquesadvance, digitaltwinsarepoisedtobecomeintegraltoprecisionagriculture. Theyprovidea holistic platform to monitor crop health, simulate interventions (like targeted spraying or irrigation changes), and foreseeissuessuchasdiseaseoutbreaksbeforetheyhappen. 18 --- Page 19 --- 4.4.3 Whatarethebenefitsofcombiningreinforcementlearningwithdigitaltwinsindiseasemanagement? The literature shows that RL algorithms can drive robotic sprayers to make smarter decisions pertaining to what, when,andhowtotreat,therebyimprovingprecisionandefficiencyinthefield. Atthesametime,digitaltwinssupply high-fidelityvirtualenvironmentsthatmirrorfarmconditions,whichisexactlywhatanRLagentneedstolearneffective policiessafelyandefficiently[97]. Insteadofdeployinguntestedalgorithmsonrealcrops(withpotentiallycostly errors), one can train an RL-based sprayer agent within a digital twin simulation of the crop, disease spread, and sprayerdynamics. TheRLagentcaninteractmillionsoftimeswiththetwin(tryingdifferentspraytimings,dosages, paths,etc.) tolearnanoptimaldisease-controlstrategy,whilethetwin’smodelsensurethescenariosremainrealistic. Researchers have started experimenting with such integrations. For example, [97] note that this synergy between environmentsimulationandlearningispavingthewayfor“reinforcementlearning-baseddigitaltwin”applicationsin farming.Inaddition,[111]demonstratedadigitaltwin-drivenverticalfarmingsysteminwhichaQ-learningalgorithm optimizesproductionschedulinginsidethetwin.BylinkingtheRLmodelwiththevirtualfarmwhichwascontinuously updatedwithrealsensordata,theyachievedupto78%demandfulfillmentinlettuceproduction,outperformingstatic optimizationmethods.Thisstudy,whilefocusedonyieldandresourceuse,illustratesthegeneralapproachofembedding RLinadigitaltwintohandledynamicdecisionproblems. Inthecontextofcropprotectionandspraying,[23]builta simulatedcropfieldinfectedwithapathogenandtrainedahierarchicalRLagenttomanagearoboticsprayerwithin thisdigitalenvironment. TheRLagenthadtwolevelsofdecision-making,ahighlevelthatdecidedwheretherobotshouldgonextinthefield, andalowerlevelthatfine-tunedthepathandsprayingactiononthedetecteddiseasedspots. Theagentlearnedapolicy thatmaximizeddiseasecoveragewhileminimizingwastedchemicalsandenergy. Whenbenchmarked,theRL-driven approachsignificantlyoutperformedaconventionaluniformsprayingstrategywithhighercropyieldrecoverywithless pesticideacrossvariousinfectionscenariosandsensornoiselevels. Furthermore,thetwincanbeusedtocontinually retrainorfine-tunetheRLpolicyasnewdatacomesin,creatinganadaptivesystemthatimproveswithtime. Inpractice, anautonomoussprayercouldhaveitsonboardAI“living”partlyinthecloud-baseddigitaltwin: ittestsvariousspray plansinthetwinusingthelatestfieldstateandthenexecutesthebestplaninthefield,receivingreal-worldfeedbackto updatethetwin. ThiskindofRL-twinintegrationcouldhandlediseaseoutbreaksinaproactivemanner(e.g.,predicting whereafungaldiseasewillspreadnextandpreemptivelyguidingtherobottothatarea,orexperimentingwithdifferent bio-controlmeasuresvirtuallybeforeapplyingthem). ThejointuseofRLanddigitaltwinsisexpectedtotacklemany agriculturalchallengesandenablemoreefficient,adaptivefarmingprocesses,ultimatelymovingcropprotectionfrom reactivetopredictiveandoptimized[97]. Aclearfuturedirectionisthedevelopmentoffullyautonomouscropprotectionsystemsthatcandetect,decide,andact inaclosedloop. Insuchasystem,high-resolutioncropimaging(fromdronesorfieldcameras)wouldfeedintoadigital twinthatcontinuouslyupdatesthelocationandseverityofdiseasesorpests. AnRLagent,possiblytrainedthrough thousandsofsimulatedoutbreakscenariosinthetwin,wouldthendeterminetheoptimalintervention–whetherthat’sa targetedspray,releasingabio-controlorganism,adjustingirrigationtoreducepathogenspread,orsomecombination. Thisdecisionwouldbeexecutedbyrobotsorsmartmachineryinthefield,andtheoutcomes(e.g. diseasereduction, anysideeffects)wouldbemeasuredandfedbackintothetwinforthenextcycle. Overtime,thisself-learningapproach couldhandlenewdiseasesorevolvingpestresistancebyexploringadaptivestrategiesinsimulationbeforeapplying themonthefarm. Theresultwouldbeadiseaseforecastingandproactivesprayingsystemthatispreventativerather thanreactiveandimproveswithexperience,muchlikehowahumancropscoutgainsintuitionovermanyseasons, exceptheretheintuitionisencodedinAIandaugmentedbydatafromanentirenetworkoffarms. 5 ChallengesandOpportunitiesofFoundationModelsforPrecisionCropDisease Management AlthoughFMsareofferingmulti-modalitiesofdataformatstobeprocessed,itstillstruggleswithafewchallenges withincropdiseaseandpestmanagementdomain. Theseareassociatedin-fieldchallengesthatFMsrightnowcannot addressorisincompetenttoachieveanyformsofsuccess. a. Cropdiseaseandpestdatarequiresverificationbyanexpertpathologist: WhileFMssuchasStable DiffusionorGPT-basedimagegeneratorscanproducelargenumbersofhigh-resolutionsyntheticimagesof cropdiseases,thequalityoftheseimagesheavilydependsontheaccuracyofthetrainingdata.Verificationby anexpertpathologistremainscriticaltoensurethatthesyntheticimagesaccuratelyreflectrealdiseasesymp- toms.Moreover,in-fieldidentificationisinherentlychallengingduetoenvironmentalvariability,overlapping symptoms,andearly-stagesubtlemanifestations. Inmanycases,lab-basedconfirmation,suchasPCRtesting orpathogenisolation,isnecessarytovalidatethediagnosis. 19 --- Page 20 --- b. Confusionbetweenvisuallysimilardiseasesymptoms: Manytext-to-imagegenerativeFMsmaystruggle todifferentiatebetweenvisuallysimilardiseasesymptoms,potentiallyproducingunrealisticormisleading images. For example, in watermelons, early anthracnose lesions may resemble damage from leaf miners. Similarly,intomatoes,earlybacterialspotinfectionscanappearsimilartoearlyblightlesions,andinwheat, Septorialeafblotchcanbemistakenfortanspot. Suchconfusionsunderscoretheneedforcarefulcuration andverificationoftrainingdatasetstoensuretheFMlearnsaccuratesymptomrepresentations. c. Simulationfidelityandbiologicalcomplexity:Digitaltwinspromisetomirrorcropanddiseasedynamicsin realtime,buttheireffectivenesshingesonthefidelityofunderlyingmodels.Biologicalsystemsareinherently variable,andintegratingmulti-modalsensordataintoaccurate,continuouslyupdatedsimulationsremainsa challenge.Reflectingthestochasticnatureofpestoutbreaks,weathereffects,andhost-pathogeninteractionsin virtualenvironmentsremainsacriticalhurdle. d. Safeandefficientreinforcementlearning:ApplyingRLinreal-worldagricultureisconstrainedbysafety andefficiencyconcerns. TraininganRLagentdirectlyinthefieldriskscroplosses,excesschemicaluse,or equipmentdamage. Whiledigitaltwinsprovideasafertrainingground, thedesignofappropriatereward functions,coverageofdiversescenarios,andtransferofpoliciesfromsimulationtofield(thesim-to-realgap) remainopenresearchproblems. e. Towardintegratedclosed-loopsystems:Mostcurrentresearchstilltreatsperception,simulation,anddecision- makingseparately. Achievingrobustclosed-loopdiseasemanagementrequiresunifyingFMsforperception, DTs for simulation, and RL for adaptive decision-making in dynamic environments. The complexity of buildingsuchcyber-physicalsystems,resilienttoweathervariability,pathogenevolution,andincompletedata, isbothachallengeandanopportunityforthefield. f. Opportunitiesahead: Despitethesebarriers,opportunitiesaresignificant.Hybridpipelinesthatcombine FM-basedperception,DT-basedforecasting,andRL-baseddecision-makingcouldtransformpestanddisease managementfromreactivesprayingtoproactiveintervention. Regionalormulti-farmdigitaltwinnetworks could facilitate collaborative forecasting of outbreaks, while adaptive RL policies could evolve alongside shifting disease pressures and resistance patterns. Integrating these frameworks with other site-specific managementdomains,suchasirrigationandbio-control,couldultimatelyyieldautonomous,resilientsystems forsustainablecropprotection. 6 Conclusion Inconclusion,FMsarereshapingSSDMincropsbyaddressingkeylimitationsoftraditionalmachineanddeeplearning methods. Theyenableeffectiveanalysisofmulti-modaldatasets,connecttextualdescriptionstovisualsymptoms,and supportinteractivedecision-makingtoolsforfarmersandextensionpersonnel.Theintegrationofadaptiveandimitation learninginroboticsystemsfurtheropensthedoortoprecise,autonomous,andfield-readyautonomoussystems. Recent literatureshowsrapidgrowthinVLMresearch,highlightingtheirincreasingimportance. Althoughreinforcement learningandadaptivelearningapplicationsarestillinearlystages,combiningthemwithdigitaltwinsimulationsoffers promisingopportunitiesfortestingandoptimizingtargetedstrategies. Overall,thesedevelopmentsindicatethatFMs willplayacriticalroleinadvancingintelligent,data-driven,andpracticalsolutionsforin-fieldcropmonitoringand management. CRediTauthorshipstatement Nitin Rai: Data curation, Formal analysis, Investigation, Methodology, Writing-original draft. Daeun (Dana) Choi:Conceptualization,Writing-review&editing.NathanS.Boyd:Methodology,Writing-review&editing.Arnold W.Schumann:Supervision,Fundingacquisition,Writing-review&editing. Declarationofcompetinginterest Theauthorsdeclarethattheyhavenoknowncompetingfinancialinterestsorpersonalrelationshipsthatcouldhave appearedtoinfluencetheworkreportedinthispaper. Acknowledgment This research was supported by the United States Department of Agriculture (USDA)-Small Business Innovation Research&TechnologyTransferPrograms(SBIR/STTR)grant#2024-51402-42007.Additionally,theauthorsdeclare 20 --- Page 21 --- thatgenerativeAI(ChatGPT,OpenAI,SanFrancisco,CA,USA)wasusedtoimprovegrammarandlanguageclarity duringthepreparationofthismanuscript. References [1] Enhui Wu, Yu Chen, Ruijun Ma, and Xiande Zhao. A review of weed image identification based on deep few-shotlearning. ComputersandElectronicsinAgriculture,237:110675,2025. [2] NitinRai. WeedIdentificationonDrone-CapturedImagesUsingEdgeDeviceforSpotSprayingApplication. PhDthesis,NorthDakotaStateUniversity,2023. [3] JieSun,ZulongLai,LipingDi,ZihengSun,JianbinTao,andYonglinShen. Multileveldeeplearningnetwork forcounty-levelcornyieldestimationintheuscornbelt. IEEEJournalofSelectedTopicsinAppliedEarth ObservationsandRemoteSensing,13:5048–5060,2020. [4] Xingguo Xiong, Renhai Zhong, Qiyu Tian, Jingfeng Huang, Linchao Zhu, Yi Yang, and Tao Lin. Daily deepcropnet: Ahierarchicaldeeplearningapproachwithdailytimeseriesofvegetationindicesandclimatic variablesforcornyieldestimation. ISPRSJournalofPhotogrammetryandRemoteSensing,209:249–264,2024. [5] MNandhini,KUKala,MThangadarshini,andSMadhusudhanaVerma. Deeplearningmodelofsequential imageclassifierforcropdiseasedetectioninplantaintreecultivation. ComputersandElectronicsinAgriculture, 197:106915,2022. [6] YangHu,GangWang,ExianLiu,JialeZhu,andMingfangHe. Amf: Amulti-modalframeworkforcropleaf diseasessegmentation. ComputersandElectronicsinAgriculture,237:110550,2025. [7] ZRui,ZZhang,MZhang,AAzizi,CIgathinathane,HCen,SVougioukas,HLi,JZhang,YJiang,etal. High- throughputproximalgroundcropphenotypingsystems–acomprehensivereview. ComputersandElectronicsin Agriculture,224:109108,2024. [8] JiangtaoQi,FangfangGao,YangWang,WeirongZhang,SisiYang,KangkangQi,andRuiruiZhang. Multiscale phenotyping of grain crops based on three-dimensional models: A comprehensive review of trait detection. ComputersandElectronicsinAgriculture,237:110597,2025. [9] LucasCUzal,GuillermoLGrinblat,RafaelNamías,MónicaGLarese,JulietaSofiaBianchi,EligioNMorandi, andPabloMGranitto.Seed-per-podestimationforplantbreedingusingdeeplearning.Computersandelectronics inagriculture,150:196–204,2018. [10] ZheZhang,XiuJin,YuanRao,TianyuWan,XiaoboWang,JiajiaLi,HaoranChen,KangleiWu,FanchenKong, ZhuoTian,etal. Dsbean:Aninnovativeframeworkforintelligentsoybeanbreedingphenotypeanalysisbasedon variousmainstemstructuresanddeeplearningmethods. ComputersandElectronicsinAgriculture,224:109135, 2024. [11] LeiLiu,FanYang,XiangyiLiu,YuefengDu,XiaoyuLi,GuorunLi,DuChen,ZhongxiangZhu,andZhenghe Song. Areviewofthecurrentstatusandcommonkeytechnologiesforagriculturalfieldrobots. Computersand ElectronicsinAgriculture,227:109630,2024. [12] YanqiuYang,PriyankaMali,LawrenceArthur,FaezehMolaei,SenaAtsyo,JiaruiGeng,LongHe,andShirin Ghatrehsamani. Advancedtechnologiesforprecisiontreefruitdiseasemanagement: Areview. Computersand ElectronicsinAgriculture,229:109704,2025. [13] RishiBommasani,DrewAHudson,EhsanAdeli,RussAltman,SimranArora,SydneyvonArx,MichaelS Bernstein,JeannetteBohg,AntoineBosselut,EmmaBrunskill,etal. Ontheopportunitiesandrisksoffoundation models. arXivpreprintarXiv:2108.07258,2021. [14] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,LauraGustafson,TeteXiao,Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. Segment anything. In Proceedings of the IEEE/CVF internationalconferenceoncomputervision,pages4015–4026,2023. [15] HarshPathak,YaguangZhang,NathanCSprague,DennisRBuckmaster,JohnTEvans,SomaliChaterji,and JamesVKrogmeier. Autonomousnavigationindigitalagriculture: Usingthesegment-anything-modelforcorn rowidentification. pages1–4,2023. [16] JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,FlorenciaLeoniAleman,Diogo Almeida,JankoAltenschmidt,SamAltman,ShyamalAnadkat,etal. Gpt-4technicalreport. arXivpreprint arXiv:2303.08774,2023. [17] ArchitParnamiandMinwooLee. Learningfromfewexamples: Asummaryofapproachestofew-shotlearning. arXivpreprintarXiv:2203.04291,2022. 21 --- Page 22 --- [18] HaiziYu,IgorMineyev,LavRVarshney,andJamesAEvans. Learningfromoneandonlyoneshot. npjArtificial Intelligence,1(1):13,2025. [19] XueJiang, JiashiWang, KaiXie, ChenxiCui, AoboDu, XianglongShi, WannengYang, andRuifangZhai. Plantcafo: Anefficientfew-shotplantdiseaserecognitionmethodbasedonfoundationmodels. PlantPhenomics, 7(1):100024,2025. [20] HaoChen,HaidongLi,JinlingZhao,ChaoRuan,andLinshengHuang. Enhancingcropdiseaserecognition viapromptlearning-basedprogressivemixupandcontrastivelanguage-imagepre-trainingdynamiccalibration. EngineeringApplicationsofArtificialIntelligence,152:110805,2025. [21] KhangNguyenQuoc,LanLeThiThu,andLuyl-DaQuach. Avision-languagefoundationmodelforleafdisease identification. arXivpreprintarXiv:2505.07019,2025. [22] Yubin Lan, Yaqi Guo, Qizhen Chen, Shaoming Lin, Yuntong Chen, and Xiaoling Deng. Visual question answeringmodelforfruittreediseasedecision-makingbasedonmultimodaldeeplearning. FrontiersinPlant Science,13:1064399,2023. [23] MahsaKhosravi,ZhanhongJiang,JoshuaRWaite,SarahEJones,HernanTorresPacin,ArtiSingh,Baskar Ganapathysubramanian, Asheesh Kumar Singh, and Soumik Sarkar. Optimizing navigation and chemical application in precision agriculture with deep reinforcement learning and conditional action tree. Smart AgriculturalTechnology,page101194,2025. [24] Chung Hee Kim, Abhisesh Silwal, and George Kantor. Autonomous robotic pepper harvesting: Imitation learninginunstructuredagriculturalenvironments. IEEERoboticsandAutomationLetters,2025. [25] Lun Li and Hamidreza Kasaei. Enhanced view planning for robotic harvesting: Tackling occlusions with imitationlearning. arXivpreprintarXiv:2503.10334,2025. [26] RickvanEssen,EldertvanHenten,andGertKootstra. Uav-basedpathplanningforefficientlocalizationof non-uniformlydistributedweedsusingpriorknowledge: Areinforcement-learningapproach. Computersand ElectronicsinAgriculture,237:110651,2025. [27] MohammedAbdalla,OsamaMohamed,andElshaimaaMAzmi. Adaptivelearningmodelfordetectingwheat diseases. InternationalJournalofAdvancedComputerScience&Applications,15(5),2024. [28] ChangXu,YidingZhang,LeiZhao,HaojieWen,andLingxianZhang. Knowledge-guidedadaptivespatial- temporalgraphcontrastivelearningframework: Regionalcropdiseasespredictionbasedonelectronicmedical records. NeuralNetworks,page107597,2025. [29] XiangLiu,ZhaoxiangLiu,HuanHu,ZezhouChen,KohouWang,KaiWang,andShiguoLian. Amultimodal benchmarkdatasetandmodelforcropdiseasediagnosis. InEuropeanConferenceonComputerVision,pages 157–170.Springer,2024. [30] PShojaee,IMirzadeh,KAlizadeh,MHorton,SBengio,andMFarajtabar. Theillusionofthinking: Under- standingthestrengthsandlimitationsofreasoningmodelsviathelensofproblemcomplexity.apple,2025. [31] DongChenandYanboHuang. Integratingreinforcementlearningandlargelanguagemodelsforcropproduc- tionprocessmanagementoptimizationandcontrolthroughanewknowledge-baseddeeplearningparadigm. ComputersandElectronicsinAgriculture,232:110028,2025. [32] Hossein Zaremehrjerdi, Shreyan Ganguly, Ashlyn Rairdin, Elizabeth Tranel, Benjamin Feuer, Juan Ignacio DiSalvo,SrikanthPanthulugiri,HernanTorresPacin,VictoriaMoser,SarahJones,etal. Towardslargereasoning modelsforagriculture. arXivpreprintarXiv:2505.19259,2025. [33] EmmanouilPapagiannidis,PatrickMikalef,andKieranConboy. Responsibleartificialintelligencegovernance: Areviewandresearchframework. TheJournalofStrategicInformationSystems,34(2):101885,2025. [34] Rabiya Abbasi, Pablo Martinez, and Rafiq Ahmad. The digitization of agricultural industry–a systematic literaturereviewonagriculture4.0. SmartAgriculturalTechnology,2:100042,2022. [35] AlecRadford,KarthikNarasimhan,TimSalimans,IlyaSutskever,etal. Improvinglanguageunderstandingby generativepre-training. 2018. [36] JaeYoungKimandYongSukChung. Ashortreviewofrgbsensorapplicationsforaccessiblehigh-throughput phenotyping. JournalofCropScienceandBiotechnology,24(5):495–499,2021. [37] JunFu,JindaiLiu,RongqiangZhao,ZhiChen,YongliangQiao,andDanLi. Maizediseasedetectionbasedon spectralrecoveryfromrgbimages. FrontiersinPlantScience,13:1056842,2022. [38] Corey Davidson, Vishnu Jaganathan, Arun Narenthiran Sivakumar, Joby M Prince Czarnecki, and Girish Chowdhary. Ndvi/ndre prediction from standard rgb aerial imagery using deep learning. Computers and ElectronicsinAgriculture,203:107396,2022. 22 --- Page 23 --- [39] HongyanZhu,ChengzhiLin,GengqiLiu,DaniWang,ShuaiQin,AnjieLi,Jun-LiXu,andYongHe. Intelligent agriculture: Deeplearninginuav-basedremotesensingimageryforcropdiseasesandpestsdetection. Frontiers inPlantScience,15:1435016,2024. [40] Abhishek Upadhyay, Narendra Singh Chandel, Krishna Pratap Singh, Subir Kumar Chakraborty, Balaji M Nandede, Mohit Kumar, A Subeesh, Konga Upendar, Ali Salem, and Ahmed Elbeltagi. Deep learning and computervisioninplantdiseasedetection:acomprehensivereviewoftechniques,models,andtrendsinprecision agriculture. ArtificialIntelligenceReview,58(3):92,2025. [41] ACamargoandJSSmith. Imagepatternclassificationfortheidentificationofdiseasecausingagentsinplants. Computersandelectronicsinagriculture,66(2):121–125,2009. [42] DanutaPacka,MarianWiwart,Elz˙bietaSuchowilska,andTeresaBienkowska. Morpho-anatomicaltraitsof twolowestinternodesrelatedtolodgingresistanceinselectedgenotypesoftriticum. Internationalagrophysics, 29(4),2015. [43] SanjeevSSannakki,VijaySRajpurohit,VBNargund,andPallaviKulkarni.Diagnosisandclassificationofgrape leafdiseasesusingneuralnetworks. In2013FourthInternationalConferenceonComputing,Communications andNetworkingTechnologies(ICCCNT),pages1–5.IEEE,2013. [44] SachinBJadhavandSanjayBPatil. Gradingofsoybeanleafdiseasebasedonsegmentedimageusingk-means clustering. IAESInternationalJournalofArtificialIntelligence,5(1):13–13,2016. [45] PunamBedi,PushkarGole,andSumitKumarAgarwal. 18usingdeeplearningforimage-basedplantdisease detection. InternetOfthingsandmachinelearninginagriculture,pages369–402,2021. [46] Mohammed Brahimi, Kamel Boukhalfa, and Abdelouahab Moussaoui. Deep learning for tomato diseases: classificationandsymptomsvisualization. AppliedArtificialIntelligence,31(4):299–315,2017. [47] JundeChen,JinxiuChen,DefuZhang,YuandongSun,andYaserAhangariNanehkaran. Usingdeeptransfer learningforimage-basedplantdiseaseidentification. Computersandelectronicsinagriculture,173:105393, 2020. [48] AlvaroFuentes,SookYoon,SangCheolKim,andDongSunPark. Arobustdeep-learning-baseddetectorfor real-timetomatoplantdiseasesandpestsrecognition. Sensors,17(9):2022,2017. [49] PoornimaSinghThakur,PriteeKhanna,TanujaSheorey,andAparajitaOjha. Explainablevisiontransformer enabledconvolutionalneuralnetworkforplantdiseaseidentification:Plantxvit.arXivpreprintarXiv:2207.07919, 2022. [50] MoshiurRahmanTonmoy, MdMithunHossain, NilanjanDey, andMFMridha. Mobileplantvit: Amobile- friendlyhybridvitforgeneralizedplantdiseaseimageclassification. arXivpreprintarXiv:2503.16628,2025. [51] NVIDIA. Whatarefoundationmodels?,March2024. Accessed: 2025-08-05. [52] AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,SandhiniAgarwal,GirishSastry, AmandaAskell,PamelaMishkin,JackClark,etal. Learningtransferablevisualmodelsfromnaturallanguage supervision. InInternationalconferenceonmachinelearning,pages8748–8763.PmLR,2021. [53] Jean-BaptisteAlayrac,JeffDonahue,PaulineLuc,AntoineMiech,IainBarr,YanaHasson,KarelLenc,Arthur Mensch,KatherineMillican,MalcolmReynolds,etal. Flamingo: avisuallanguagemodelforfew-shotlearning. Advancesinneuralinformationprocessingsystems,35:23716–23736,2022. [54] XinyanZhao,BaiyanChen,MengxueJi,XinyueWang,YuhanYan,JinmingZhang,ShiyingjieLiu,MuyangYe, andChunliLv. Implementationoflargelanguagemodelsandagriculturalknowledgegraphsforefficientplant diseasedetection. Agriculture(Switzerland),14(8),2024. Citedby: 8;AllOpenAccess;GoldOpenAccess. [55] AsafTzachor,MedhaDevare,CatherineRichards,PieterPypers,AniruddhaGhosh,JawooKoo,SJohal,and BrianKing. Largelanguagemodelsandagriculturalextensionservices. Naturefood,4(11):941–948,2023. [56] DaanR.Scheepens,JosephW.Millard,MaxwellJ.Farrell,andTimNewbold. Largelanguagemodelshelp facilitatetheautomatedsynthesisofinformationonpotentialpestcontrollers. MethodsinEcologyandEvolution, 15(7):1261–1273,2024. Citedby: 6;AllOpenAccess;GoldOpenAccess;GreenAcceptedOpenAccess; GreenOpenAccess. [57] MatheusThomasKuska,MirwaesWahabzada,andStefanPaulus. Aiforcropproduction–wherecanlarge languagemodels(llms)providesubstantialvalue? ComputersandElectronicsinAgriculture,221,2024. Cited by: 25;AllOpenAccess;HybridGoldOpenAccess. [58] ParamAhirandNikunjV.Tahilramani. Integratinglanguagemodelswithsensordataforenhancedplanthealth monitoringandqueryresponse. InternationalJournalofComputerApplicationsinTechnology,75(2-4):178– 187,2024. Citedby: 0. 23 --- Page 24 --- [59] Auvick Chandra Bhowmik, Md Taimur Ahad, Yousuf Rayhan Emon, Faruk Ahmed, Bo Song, and Yan Li. A customised vision transformer for accurate detection and classification of java plum leaf disease. Smart AgriculturalTechnology,8:100500,2024. [60] PoornimaSinghThakur,ShubhangiChaturvedi,PriteeKhanna,TanujaSheorey,andAparajitaOjha.Visiontrans- formermeetsconvolutionalneuralnetworkforplantdiseaseclassification. EcologicalInformatics,77:102245, 2023. [61] TianYang,YupengMei,LingXu,HuihuiYu,andYingyiChen. Applicationofquestionansweringsystems forintelligentagricultureproductionandsustainablemanagement: Areview. Resources, Conservationand Recycling,204:107497,2024. [62] HaitaoLiu,JihuaSong,andWeimingPeng. Glyreshot: Aglyph-awaremodelwithlabelrefinementforfew-shot chineseagriculturalnamedentityrecognition. Heliyon,10(12),2024. [63] BiplovPaneru,BipulThapa,andBishwashPaneru. Leveragingaiinayurvedicagriculture: Aragchatbotfor comprehensivemedicinalplantinsightsusinghybriddeeplearningapproaches. TelematicsandInformatics Reports,16:100181,2024. [64] LiWang. Digitaltwinsinagriculture: areviewofrecentprogressandopenissues. Electronics,13(11):2209, 2024. [65] Biao Zhao, Weiqiang Jin, Javier Del Ser, and Guang Yang. Chatagri: Exploring potentials of chatgpt on cross-linguisticagriculturaltextclassification. Neurocomputing,557:126708,2023. [66] SaedRezayi,ZhengliangLiu,ZihaoWu,ChandraDhakal,BaoGe,ChenZhen,TianmingLiu,andShengLi. Agribert: Knowledge-infusedagriculturallanguagemodelsformatchingfoodandnutrition. InIJCAI,pages 5150–5156,2022. [67] JiuqingDong,YifanYao,AlvaroFuentes,YongchaeJeong,SookYoon,andDongSunPark. Visualinformation guidedmulti-modalmodelforplantdiseaseanomalydetection. SmartAgriculturalTechnology,9:100568,2024. [68] JiajunQing,XiaolingDeng,YubinLan,andZhikaiLi. Gpt-aideddiagnosisonagriculturalimagebasedona newlightYOLOPC. Computersandelectronicsinagriculture,213:108168,2023. [69] KunpengZhang,LiMa,BeibeiCui,XinLi,BoqiangZhang,andNaXie. Visuallargelanguagemodelforwheat diseasediagnosisinthewild. ComputersandElectronicsinAgriculture,227:109587,2024. [70] BorjaEspejo-Garcia,RonjaGüldenring,LazarosNalpantidis,andSpyrosFountas. Foundationvisionmodels inagriculture: Dinov2, loraandknowledgedistillationfordiseaseandweedidentification. Computersand ElectronicsinAgriculture,239:110900,2025. [71] JiandongPan,RenhaiZhong,FulinXia,JingfengHuang,LinchaoZhu,YiYang,andTaoLin. Chatleafdisease: a chain-of-thought prompting approach for crop disease classification using large language models. Plant Phenomics,page100094,2025. [72] ChangqingYan,ZeyunLiang,HanCheng,ShuyangLi,GuangpengYang,ZhiweiLi,LingYin,JunjieQu,Jing Wang,GenghongWu,etal. Cdip-chatglm3: Adual-modelapproachintegratingcomputervisionandlanguage modelingforcropdiseaseidentificationandprescription. ComputersandElectronicsinAgriculture,236:110442, 2025. [73] NitinRai,ArnoldSchumann,andNathanBoyd. Phytosynth: Leveragingmulti-modalgenerativemodelfor cropdiseasedatagenerationwithnovelbenchmarkingandpromptengineeringapproach. InProceedingsofthe ComputerVisionandPatternRecognitionConference,pages5371–5380,2025. [74] ChunhuiBai,LilianZhang,LutaoGao,LinPeng,PeishanLi,andLinnanYang. Dinov2-fcs: amodelforfruit leafdiseaseclassificationandseverityprediction. FrontiersinPlantScience,15:1475282,2024. [75] FangfangLiang,ZilongHuang,WenjianWang,ZhenxueHe,andQingEn.Dynamictextpromptjointmultimodal featuresforaccurateplantdiseaseimagecaptioning. TheVisualComputer,pages1–15,2024. [76] GuoweiXu,WeitingZhao,YuhuiBie,MingliangGe,ZekunCui,andYaojunWang. Agro-llava-next: Alarge multimodalmodelforplantdiseasesrecognization. InInternationalConferenceonIntelligentComputing,pages 291–302.Springer,2025. [77] Kejun Zhao, Xingcai Wu, Yuanyuan Xiao, Sijun Jiang, Peijia Yu, Yazhou Wang, and Qi Wang. Plantext: Gradually masked guidance to align image phenotypes with trait descriptions for plant disease texts. Plant Phenomics,6:0272,2024. [78] YunpengZhao,ShansongWang,QingtianZeng,WeijianNi,HuaDuan,NengfuXie,andFengjinXiao.Informed- learning-guidedvisualquestionansweringmodelofcropdisease. PlantPhenomics,6:0277,2024. 24 --- Page 25 --- [79] Jinyang Li, Fengting Zhao, Hongmin Zhao, Guoxiong Zhou, Jiaxin Xu, Mingzhou Gao, Xin Li, Weisi Dai, HonliangZhou,YahuiHu,etal. Amulti-modalopenobjectdetectionmodelfortomatoleafdiseaseswithstrong generalizationperformanceusingpdc-vld. PlantPhenomics,6:0220,2024. [80] HongliangZhou,YufanHu,ShuaiLiu,GuoxiongZhou,JiaxinXu,AibinChen,YanfengWang,LiujunLi,and YahuiHu. Apreciseframeworkforriceleafdiseaseimage–textretrievalusingfhtw-net. PlantPhenomics, 6:0168,2024. [81] Chenshuo Zhang, Lijie Zhang, Huarui Wu, Chunshan Wang, Cheng Chen, Huaji Zhu, and Fangfang Liang. Chinese named entity recognition for agricultural diseases based on entity-related visual prompts injection. ComputersandElectronicsinAgriculture,227:109493,2024. [82] BowenLv,HuaruiWu,WenbaiChen,ChengChen,YishengMiao,andChunjiangZhao.Veg-mmkg:Multimodal knowledgegraphconstructionforvegetablesbasedonpre-trainedmodelextraction. Computersandelectronics inagriculture,226:109398,2024. [83] Shan-SongWang,Wei-JianNi,Qing-TianZeng,Neng-FuXie,andChaoLi. Apd-229: atextual-visualdatabase foragriculturalpestsanddiseases. MultimediaToolsandApplications,83(8):22189–22220,2024. [84] YueyueZhou,HongpingYan,KunDing,TingtingCai,andYanZhang. Few-shotimageclassificationofcrop diseasesbasedonvision–languagemodels. Sensors,24(18):6109,2024. [85] EmmanuelMoupojou,FlorentRetraint,HyppoliteTapamo,MarcellinNkenlifack,CheikhKacfah,andAppoli- naireTagne. Segmentanythingmodel&fullyconvolutionaldatadescriptionforplantmulti-diseasedetectionon fieldimages. IEEEAccess,2024. [86] JiuqingDong,AlvaroFuentes,HengZhou,YongchaeJeong,SookYoon,andDongSunPark. Theimpactof fine-tuningparadigmsonunknownplantdiseasesrecognition. ScientificReports,14(1):17900,2024. [87] YiyiCao,LeiChen,YuanYuan,andGuanglingSun. Cucumberdiseaserecognitionwithsmallsamplesusing image-text-label-basedmulti-modallanguagemodel. Computersandelectronicsinagriculture,211:107993, 2023. [88] GuoweiDai,JingchaoFan,andChristineDewi. Itf-wpi: Imageandtextbasedcross-modalfeaturefusionmodel forwolfberrypestrecognition. ComputersandElectronicsinAgriculture,212:108129,2023. [89] TekRajChhetri,ArminHohenegger,AnnaFensel,MariamAramideKasali,andAsiruAfeezAdekunle. Towards improvingpredictionaccuracyanduser-levelexplainabilityusingdeeplearningandknowledgegraphs: Astudy oncassavadisease. ExpertSystemswithApplications,233:120955,2023. [90] XiaQiu,HongwenChen,PingHuang,DanZhong,TaoGuo,ChangbinPu,ZongnanLi,YonglingLiu,JinChen, andSiWang. Detectionofcitrusdiseasesincomplexbackgroundsbasedonimage–textmultimodalfusionand knowledgeassistance. FrontiersinPlantScience,14:1280365,2023. [91] YinshuoZhang,LeiChen,andYuanYuan. Multimodalfine-grainedtransformermodelforpestrecognition. Electronics,12(12):2620,2023. [92] ShansongWang,QingtianZeng,WeijianNi,ChengCheng,andYanxueWang. Odp-transformer: Interpretation ofpestclassificationresultsusingimagecaptiongenerationtechniques.ComputersandElectronicsinAgriculture, 209:107863,2023. [93] JiZhou,JiuxiLi,ChunshanWang,HuaruiWu,ChunjiangZhao,andGuifaTeng. Cropdiseaseidentification and interpretation method based on multimodal deep learning. Computers and Electronics in Agriculture, 189:106408,2021. [94] MLLittmanandAWMoore. Reinforcementlearning: Asurvey,journalofartificialintelligenceresearch4, 1996. [95] Marcin Woz´niak and Muhammad Fazal Ijaz. Recent advances in big data, machine, and deep learning for precisionagriculture. FrontiersinPlantScience,15:1367538,2024. [96] DaríoFernandoYépez-Ponce, JoséVicenteSalcedo, PaúlDRosero-Montalvo, andJavierSanchis. Mobile roboticsinsmartfarming: currenttrendsandapplications. FrontiersinArtificialIntelligence,6:1213330,2023. [97] Georg Goldenits, Kevin Mallinger, Sebastian Raubitzek, and Thomas Neubauer. Current applications and potential future directions of reinforcement learning-based digital twins in agriculture. Smart Agricultural Technology,8:100512,2024. [98] JiachenYang,JingfeiNi,YangLi,JiabaoWen,andDeshengChen. Theintelligentpathplanningsystemof agriculturalrobotviareinforcementlearning. Sensors,22(12):4316,2022. 25 --- Page 26 --- [99] YajunLi,QingchunFeng,YifanZhang,ChuanlangPeng,YuhangMa,ChengLiu,MengfeiRu,JiahuiSun,and ChunjiangZhao. Pedunclecollision-freegraspingbasedondeepreinforcementlearningfortomatoharvesting robot. ComputersandElectronicsinAgriculture,216:108488,2024. [100] FranciscoYandun,TanvirParhar,AbhiseshSilwal,DavidClifford,ZhiqiangYuan,GabriellaLevine,Sergey Yaroshenko,andGeorgeKantor. Reachingpruninglocationsinavineusingadeepreinforcementlearningpolicy. In2021IEEEInternationalConferenceonRoboticsandAutomation(ICRA),pages2400–2406.IEEE,2021. [101] TDKelly,TFoster,andDavidMSchultz. Assessingthevalueofdeepreinforcementlearningforirrigation scheduling. SmartAgriculturalTechnology,7:100403,2024. [102] TalhaSiddique,JiaLinHau,ShadiAtallah,andMarekPetrik. Robustpestmanagementusingreinforcement learning. InTheMulti-disciplinaryConferenceonReinforcementLearningandDecisionMaking,2019. [103] ZiyuanHao,XinzeLi,ChaoMeng,WeiYang,andMinzanLi. Adaptivesprayingdecisionsystemforplant protectionunmannedaerialvehiclebasedonreinforcementlearning. InternationalJournalofAgriculturaland BiologicalEngineering,15(4):16–26,2022. [104] AliMoltajaeiFarid,JafarRoshanian,andMalekMouhoub. Multipleaerial/groundvehiclescoordinatedspraying usingreinforcementlearning. EngineeringApplicationsofArtificialIntelligence,151:110686,2025. [105] JeffMulhollem. Usdagranttofundroboticprecisionpesticidesprayerdevelopment,2024. Accessed: 2025-04- 24. [106] OmeedMirbod,DaeunChoi,andJohnKSchueller. Fromsimulationtofieldvalidation: Adigitaltwin-driven sim2realtransferapproachforstrawberryfruitdetectionandsizing. AgriEngineering,7(3):81,2025. [107] StevenKimandSeongHeo. Anagriculturaldigitaltwinformandarinsdemonstratesthepotentialforindividual- izedagriculture. NatureCommunications,15(1):1561,2024. [108] DRajeswari,AthishVenkatachalamParthiban,andSivaramPonnusamy. Digitaltwin-basedcropyieldprediction inagriculture. InHarnessingAIandDigitalTwinTechnologiesinBusinesses,pages99–110.IGIGlobal,2024. [109] PeymanMoghadam,ThomasLowe,andEverardJEdwards. Digitaltwinforthefutureoforchardproduction systems. InProceedings,volume36,page92.MDPI,2020. [110] MinDai,YutianShen,XiaoyinLi,JingjingLiu,ShanwenZhang,andHongMiao. Digitaltwinsystemofpest managementdrivenbydataandmodelfusion. Agriculture,14(7):1099,2024. [111] YujiaLuoandPeterBall. Adaptiveproductionstrategyinverticalfarmdigitaltwinswithq-learningalgorithms. ScientificReports,15(1):15129,2025. 26