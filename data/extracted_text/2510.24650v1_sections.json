{
  "abstract": "abstract M \u2022 peer-reviewed \u2022 English language \u2022 only technical articles \u2022 \u2022 Thoroughly read and report relevant application of foundation remove duplicate papers across the database search models \u2022 extract relevant papers from retrieved ones n Frame questions based on key points o is s u c s id d n \u2022 Evolution of vision only models \u2022 Perception + reasoning \u2022 a \u2022 Adoption trajectory \u2022 Research priorities \u2022 Year-wise trends Foundation models \u2022 LLM-VLM synergy \u2022 Emerging applications s t (2025) \u2022 Adaptive learning \u2022 Reinforcement learning \u2022 Experience- lu s driven robotics \u2022 Digital twin \u2022 Integrated approaches e R Figure 2: This review presents a systematic literature analysis focused on foundation models and their extended applicationsinsite-specificcropdiseasemanagement. Theboxontheleftillustratestheemployedmethodology,while theboxontherighthighlightskeyquestionsderivedfromtheretrievedresearcharticles. Table 1: Selected relevant publications on leveraging large language models and vision language models for crop diseaseandpestmanagement. Databases Retrievedarticles Relevantarticles (\u201clarge language models\u201d OR \u201cLLM\u201d OR \u201cfoundation models\u201d) AND (\u201cplant disease\u201d OR \u201ccrop disease\u201d OR \u201cpest management\u201d OR \u201cagricultural disease\u201d) ScienceDirect 49 6 Scopus 141 5 (\u201cvision language model\u201d OR \u201cVLM\u201d OR \u201cfoundation models\u201d OR \u201cmulti-modal\u201d) AND (\u201cplant disease\u201d OR \u201ccrop disease\u201d OR \u201cpest management\u201d OR \u201cagricultural disease\u201d) ScienceDirect 107 16 Scopus 569 11 Note:Studiesincludedwerepublishedbetween2019and2024. models\u201d OR \u201cmulti-modal\u201d) AND (\u201cplant disease\u201d OR \u201ccrop disease\u201d OR \u201cpest management\u201d OR \u201cagricultural disease\u201d).Basedontheretrievedarticles,afewkeypointswereidentifiedandusedtoframetwo importantquestionsforresultsanalysisandeightadditionalquestionsfordiscussion(seeFig.2).Thesequestionswere: a. Whatdoestheoveralladoptiontrajectoryoffoundationmodelsincropdiseaseresearchrevealaboutthepace anddirectionofthisemergingfield? (Sec.3.1) b. Whatdoestheyear-wisedistributionoflargelanguagemodels(LLMs)andvisionlanguagemodels(VLMs)- basedstudiessuggestaboutevolvingresearchprioritiesinagriculturaldiseasemanagement? (Sec.3.2) c. Howdoestheincreasingcomplexityofimageacquisitionsensorsinfluencetheevolutionfromtraditional imageprocessingtoadvanceddeeplearning? (Sec.4.1) d. Howarefoundationmodelstransformingvisionsystemsinto\u2018vision+brain\u2019frameworksthatbothperceive andreasonaboutcropdiseases? (Sec.4.2) e. Whataretheemergingtrendsintheadoptionandapplicationoffoundationmodelsforcropdiseasemanagement inthefirsthalfof2025? (Sec.4.3) 5 --- Page 6 --- f. How are reinforcement learning, adaptive learning, and experience-driven approaches being applied in agriculturalroboticsforcropdiseasemanagement? (Sec.4.4.1) g. How are digital twin technologies being leveraged for real-time monitoring and decision-making in crop diseasemanagement? (Sec.4.4.2) h. What are the benefits of combining reinforcement learning with digital twins in disease management? (Sec.4.4.3) 3 SearchResults 3.1 Whatdoestheoveralladoptiontrajectoryoffoundationmodelsincropdiseaseresearchrevealaboutthe paceanddirectionofthisemergingfield? Table1summarizestheresultsofaliteraturesearchacrosstwomajordatabasestoidentifyrecentstudiesleveraging LLMs and VLMss for crop disease management and pest control. The first query, which combined LLM-related keywordswithtermsforplantandcropdiseaseorpestmanagement,yielded49articlesfromScienceDirectand141 fromScopus,butonlyasmallsubsetdirectlyrelevanttothetopic(Table1).Althoughtheliteraturesearchcovereda five-yearperiod,themajorityofrelevantarticleswerepublishedin2023and2024.Thisindicatesthat,whileLLMs such as OpenAI\u2019s GPT, released in 2018, are considered FMs, their application for synthesizing agricultural texts andcropdiseaseknowledgeonlybegantogainattractionaroundlate2022[35](Fig.3).Thesefindingshighlighta significantgapbetweentherapidlyexpandingbodyofAIresearchanditsdirectapplicationtoagricultural-centered crop disease and pest management, suggesting that although foundational AI",
  "introduction": "1 Introduction Theapplicationofartificialintelligence(AI)hastransformedagriculturalautomationacrossdiversedomains,including weedclassificationforspotspraying [1,2],cropyieldestimation[3,4],diseasemonitoring[5,6],phenotyping[7,8], andplantbreeding[9,10].Amongthese,AI-drivencomputervisionmodelshaveemergedasparticularlyimpactful incropdiseaseandpestmanagement, whereaccuratevisualrecognitionispivotalforearlydetectionandtargeted intervention. These vision-based systems are increasingly integrated with smart sprayers and autonomous robots, enablingsite-specificfungicideapplicationwhilereducingchemicalinputsandoperationalcosts[11,12]. Amajor driverofthisprecisioncapabilityliesinthesynergybetweencomputervisionmodelsdeployedonedgesystems,which providesmachineswiththeabilitytoperceiveandinterpretcomplexagriculturalenvironments. At the heart of this development is data, large-scale image datasets, combined with the representation power of deeplearning(DL)models,havebeenpivotalintransmitting\u201cvision\u201dtoagriculturalrobots,therebybridgingthegap betweenrawperceptionandactionableintelligenceinthefield.DespitetheseadvancementsthatDLmodels,particularly convolutionalneuralnetworks(CNNs),haveachievedtoaddresssite-specificdiseasemanagement(SSDM)incrops, theyfacenotablelimitationswhendeployedinagriculturalenvironments. Theirperformanceisoftenconstrainedby theavailabilityofannotateddatasets,whichareexpensiveandtime-consumingtocurateforthewidevarietyofcrops, diseases,andfieldconditions. Moreover,CNNmodelsoftenrequirefine-tuningortransferlearningapproacheswhen 2 --- Page 3 --- appliedtonewcrops, diseasesymptoms, orenvironmentalsettings. Thesemodelsarealsolimitedtoapplications wheremulti-modalitiesofdataisgenerated,astheycanonlytakeoneformatofdataatatime. Suchconstraintshave highlightedtheneedformoreadaptiveandgeneralizableapproaches, wherefoundationmodels(FMs), trainedon massivemulti-modaldatasetsdemonstrateclearadvantage. Theterm\u201cfoundationmodels\u201dwasfirstusedbyresearchersatStanfordUniversity[13]. FMsarepretrainedonmassive anddiversedatasets,haveemergedasatransformativeparadigmincomputervision,withthepotentialtoovercome manylimitationsposedbyCNNmodels. Unlikeconventionalmodels,FMssuchasContrastiveLanguage-ImagePre- training(CLIP),SegmentAnything(SAM)[14,15],andGenerativePretrainedTransformer(GPT)[16]architectures, areinherentlyversatileastheycanbeadaptedtodownstreamagriculturaltaskswithminimalretrainingandarecapable offew-shotandevenzero-shotlearning[17,18]. Severalstudiesdemonstratetheirutilityincropdiseasedetectionand syntheticdatageneration,showcasingimprovedgeneralizationandrobustnesscomparedtotraditionaltask-specific models. Forinstance,thePlantCaFomodelwasdevelopedusingafew-shotapproachthatleveragesthemodel\u2019sprior knowledge[19]. AnotherworkwasinspiredbytheCLIParchitectureandusedtheProgressiveMixupPromptLeaning (PMPL)framework,whichintegrateshierarchicalfeatureMixupwithpromptlearningforcropdiseaserecognition[20]. Theirabilitytoencodebroadsemanticunderstandingwiththehelpoftext-basedpromptshasintroducedastep-change inhowagriculturaltaskscanbeanalyzed,enablingmodelstomovebeyondnarrowclassificationtaskstowardmore context-awaredecisionsupporttools. WiththehelpofFMs,userscannowaccessinteractiveQ&Ainterfaceswhere theyuploadanimageofacropshowingdiseasesymptoms,andthemodelcanreasonaboutthepresenceofaparticular disease,unlikeconventionalmodelstrainedonlyonspecificlabels[21,22].Thisshifttransformsconventionalcomputer visionfromastaticdiagnostictoolintoadynamicalgorithmthatmakesthemuniquelysuitedforreal-timerobotic operationssuchastargetedspraying,whereadaptabilitytonovelscenarios,suchasunexpectedlightingconditions, unfamiliarcropvarieties,oroccludedtargets,isessential. Beyondperceptiontasks, theintegrationofvision-basedFMswithreinforcementlearning(RL),adaptivelearning (AL),imitationlearning(IL),androboticsrepresentsthenextfrontierinagriculturalautomation[23\u201325].RLallows autonomoussystemstooptimizeactionsthroughcontinuousfeedback, acriticalfeatureintaskssuchasprecision spraying,roboticscouting,orunmannedaerialsystem(UAS)-baseddiseasesurveillance[26].Adaptivelearningextends this further by enabling models to evolve with changing environmental conditions, crop growth stages, or disease dynamics,ensuringsustainedaccuracyindynamicfieldsettings[27,28].Whenembeddedwithinroboticplatforms, suchasgroundvehiclesoraerialdrones,foundationmodelscanempowerautonomoussystemstonotonlyperceive butalsoreasonandactincomplexenvironments,bridgingthegapbetweensensingandintelligentintervention. This couplingoflarge-scalepre-trainedvisionmodelswithautonomousdecision-makingframeworkssignalsaparadigm shifttowardfullyintegrated,self-improvingagriculturalrobotics. Despitetheirpromise,significantchallengesremainbeforeFMscanbefullyleveragedinagriculturaldomain,specifi- callyforcropdiseaseandpestmanagement. First ,thereisalackoflarge-scale,domain-specificbenchmarkingto assesstheirgeneralizationacrossdiversecropspeciesandfieldconditions[29]. Second ,identifyingcropdiseases isinherentlycomplexandoftenrequirestheinterventionofexpertplantpathologists. Sinceitinvolvesathorough understandingofliteratureoftencombinedwithlaboratoryvalidation,theapplicationofFMscanbechallenging. For instance,whentwodiseasesymptomsappearverysimilar,FMsmaystruggletoreasoncorrectlyabouttheircausesand differentiatebetweenthem.Insuchcases,reasoningmodelsmayalsosufferfroman\u201coverthinking\u201dphenomenon,gen- eratingredundantoutputsevenafteridentifyingthecorrectresult[30]. Third ,theintegrationofreasoningframeworks, RL,andadaptivemechanismswithFMsisstillinitsinfancy,limitingtheirpotentialforreal-timedecision-making inautonomoussystems[31,32]. Finally , issuessurroundingdatagovernance, modelinterpretability, andethical deploymentinagriculturalsettingsrequireurgentattention[33].Againstthisbackdrop,thisreviewprovidesatimely synthesisofthecurrentstateofFMsincropdiseaseandpestmanagement,examinestheiremergingapplicationsin adaptivelearningandrobotics,andoutlinespromisingdirectionsforfutureresearchthatmayshapethetrajectoryof agricultural AI beyond 2025. Building on current developments in leveraging FMs for real-time, feedback-driven sprayingsystems,thearticleofferreadersacomprehensiveoverviewofadvancements,identifieskeychallenges,and highlightsopportunitiesforfurtherexploration.Thespecificcontributionsofthisreviewareasfollows: 1. Examinecurrentresearchtrendstodeterminewhethereffortsareprimarilyfocusedonusinglargelanguage models(LLMs)tosynthesizeextensivecorporaofextensiontexts. 2. Investigatethegrowingemphasisonintegratingbothvisionandlanguagemodalitiestoenhancecropdisease decision-making. 3. Demonstratehowreasoning-basedmodelsaretransformingparadigms,notonlyinvision-basedsystemsbut alsothroughtextualexplanations,byengagingusersinunderstandingwhyamodelmadeaspecificdecision. 3 --- Page 4 --- 4. Explorefuturedirectionsinadaptivelearningbyfirstperformingsimulationswithindigitaltwinenvironments to test and refine models using reinforcement learning frameworks, and then developing and deploying practical,end-to-endsystemsthatcontinuouslyadapttoreal-worldfeedback. 2 MaterialsandMethods 2.1 Comprehensiveliteraturesearch Theoverallliteraturesearchandreviewanalysiswereperformedforthelastfiveyears(2019-2024),focusingontherole offoundationmodels(FMs)inadvancingsite-specificdiseasemanagement(SSDM).Beyondthiscentraltheme,the broaderaimwastoexaminehowthesemodelscouldevolveintofeedback-drivenreasoningframeworksbyintegrating digitaltwins(DT),reinforcementlearning(RL),androboticstofurthersupportSSDM.Therefore,theanalysiswas splitintotwocategories:(a)visionsystem, and(b)vision+brainforadaptivelearningandreasoninginreal-time applications(Fig.1). Foracomprehensiveliteraturesearch,twoacademicdatabaseswereselected,ScienceDirectandScopus.However, to critically provide assessment on the current technologies as per the industry 4.0 initiatives, autonomous robots forsite-specificdiseasemanagementwasalsoincluded[34].Aspartofadvancedliteraturesearch,severalkeywords wereusedinconjunctionwithmultipleBooleanoperators, \u201cAND,\u201dand\u201cOR.\u201dAdditionally, retrievedpaperswere adjudicatedbasedonmultiplescreeningcriteria:(a)cropdiseaseidentificationwithanaimtoaddresssite-specific diseasemanagement,(b)peer-reviewed,(c)Englishlanguage,(d)onlyresearcharticles,and(e)duplicatepapersacross databases.Table1reportsthedifferencebetweenpapersretrievedandreportedafterliteraturesearchreviewprocess. Crop disease management through AI and robotics Vision system Vision + Brain = Adaptive learning through reasoning AI models Foundational models/GenAI s Traditional image processing Physics-based AI and Digital twin e v 01 92 90 12 s- Conventional ML tn e 1r 2r 0u 2c - Reinforcement learning ita itin i 0 .4 y rtsu d n Advanced DL Imitation learning I Figure1: Anoverviewofthereviewperformedinthisstudywithaperspectivetofocusontheindividualstepstakento addresssite-specificdiseasemanagement. 2.2 Articlescreeningcriteriaandframingquestionsderivedfromkeypoints Theoverallsearchandscreeningcriteriawasfurthersubdividedintotwocategoriesbasedontheoverallthemeof research performed in crop disease management in precision agriculture (Fig. 2). These were: (a) large-language models (LLMs) as smart advisors for crop diseases, and (b) large vision models (VLMs) for smart crop detection and textual understanding/reasoning. In the first category, technical research articles that focused on using LLMs tosynthesizetexts,suchasextensionarticlesorprescriptions,andtodevelopQ&Aplatformswereselected.Inthe secondcategory,articlesthatleveragedVLMs,suchasDINO,CLIP,orGPT,andcombinedmultimodaldatasuchas images,text,orsensorreadings(structureddata),wereincluded.Thiscategorizationwascarriedouttoreportresults anddiscussiononeachapproachtocropdiseasemanagementinprecisionagriculture. Toaccomplishthis,twokey phrasesintheadvancedsearchsectionofthedatabaseswereused.ForLLMS:(\u201clarge language models\u201d OR \u201cLLM\u201d OR \u201cfoundation models\u201d) AND (\u201cplant disease\u201d OR \u201ccrop disease\u201d OR \u201cpest management\u201d OR \u201cagricultural disease\u201d), and for VLMs: (\u201cvision language model\u201d OR \u201cVLM\u201d OR \u201cfoundation 4 --- Page 5 --- Systematic literature search Perform advanced search on databases Use search keywords as per the theme of this review \u2022 ScienceDirect \u2022 Scopus \u2022 Large language models (LLMs) \u2022 Vision language models (VLMs) y g o lo d o h te Apply screening criteria Read the",
  "methods": "Methodology,Writing-review&editing.Arnold W.Schumann:Supervision,Fundingacquisition,Writing-review&editing. Declarationofcompetinginterest Theauthorsdeclarethattheyhavenoknowncompetingfinancialinterestsorpersonalrelationshipsthatcouldhave appearedtoinfluencetheworkreportedinthispaper. Acknowledgment This research was supported by the United States Department of Agriculture (USDA)-Small Business Innovation Research&TechnologyTransferPrograms(SBIR/STTR)grant#2024-51402-42007.Additionally,theauthorsdeclare 20 --- Page 21 --- thatgenerativeAI(ChatGPT,OpenAI,SanFrancisco,CA,USA)wasusedtoimprovegrammarandlanguageclarity duringthepreparationofthismanuscript.",
  "discussion": "Discussion 4.1 Howdoestheincreasingcomplexityofimageacquisitionsensorsinfluencetheevolutionfromtraditional imageprocessingtoadvanceddeeplearning? Current sensing platforms are the foundation for large-scale disease identification technologies, ranging from au- tonomousgroundrobotstotractor-mountedsmartsprayers.Overtheyearsthesesensorshavebeenmademorecompact inspacerequirementswithoutcompromisingonitshigh-resolutionimageacquisitioncapabilities.Threecategories ofsensingsystemutilizedlargelyfordiseaseidentificationare: RGB,multi-spectral(MS),andhyperspectral(HS) (Fig.4).Forimageacquisitioninin-fieldsettings,thesesensorsareeithermountedoncustombuiltchassisorcom- mercialized autonomous robotic platforms. Among all the three categories, RGB sensors have played a vital role inaccomplishingdiseaseidentificationtotargetsprayingtasks[36\u201338].WhileRGBsensorsworkonaverysmall wavelength(400-700nm),thermalsensorsarealsousedtoscoutfordiseasesandismostlyusedtomapwavelengths between8,000-14,000nm[39,40].Thesesensorsdoesnothaveaverywiderangeofapplicationsespeciallyconsidering its useful assessment in extracting more information from crops. Figure 4 showcases the inverted triangle which demonstratestheincreaseincomplexityandsensorapplicationfromRGBtoHS.Forinstance,RGBsensorsarea bestfittoclassifydiseasesthatarevisuallydistinct.Thisusecasealsofavorsitsreal-timeapplicationsabilityasthe sensordoesnotinvolvedetailedscanningofcropsinorderextractinformationinmultiplebands,unlikeMSandHS sensors.AssensorcomplexityincreasesfromRGBtoHSsensors, sodoesthevolumeanddimensionalityofdata captured,moreadvanceddataprocessingandanalyticalsolutions.ThisshifthasenabledAImodelstoprocesslarge, complexdatasetsfortimelyandaccuratediseasediagnosis. RGB MS HHanandd-h-heelldd DDSSLLRR RoWboattsaonnist Amifgaar m(fa-rnmg-ng) RWobaottsaonnist DDJJII PPhhaannttoomm 4 4 P rPoro \u2022 well-suited for real-time applications \u2022 faster processing times \u2022 large-scale image HS processing \u2022 best fit for visually distinct symptoms \u2022 low-cost and easily available MicaSense-RedEdge-P RedEdge-P dual Parrot SEQUOIA+ Sentera Snapshot \u2022 useful for plant stress identification \u2022 usually expensive \u2022 infused with spectral richness \u2022 requires calibration for goof",
  "results": "results \u2022 occupies more storage space Specim FX17 Resonon Senop Black Mobile V2 CHNSpec-FS-IQ \u2022 extremely detailed spectral signatures \u2022 useful for early disease identification \u2022 large data volume \u2022 expensive \u2022 demands sophisticated analysis Figure4: Differentcategoriesofsensingsystemsandplatformsusedindiseaseimageacquisition.Theinvertedtriangle includes: RGB,multispectral(MS),andhyperspectral(HS)sensorswhereitsapplicationinsensingdiseaseinformation increasesfromRGBtoHS. 7 --- Page 8 --- TheintegrationofAImodels,particularlythosetrainedonnumerousexamplesoflarge-scalediseasedatasets,has significantly advanced the ability to monitor crops in real-time for disease threats. Between 2010 and 2017, most studiesreliedonleveragingeithertraditionalimageprocessingorconventionalmachinelearning(ML)modelbased onhandcraftedfeaturestoperformdiseaseclassificationtasksincropssuchastomato,grapes,andmaize[41\u201344] (Fig.1).Althoughtheseapproacheswerelimitedinscaleandreal-timecapability,itprovidedfoundationalresearch breakthroughsincropdiseaseidentification. Buildingonthisfoundation,deeplearning(DL)techniques,particularly, convolutionalneuralnetworks(CNNs),begantodominatethefieldpost2017.Thesemodelssignificantlyoutperformed traditional",
  "references": "References [1] Enhui Wu, Yu Chen, Ruijun Ma, and Xiande Zhao. A review of weed image identification based on deep few-shotlearning. ComputersandElectronicsinAgriculture,237:110675,2025. [2] NitinRai. WeedIdentificationonDrone-CapturedImagesUsingEdgeDeviceforSpotSprayingApplication. PhDthesis,NorthDakotaStateUniversity,2023. [3] JieSun,ZulongLai,LipingDi,ZihengSun,JianbinTao,andYonglinShen. Multileveldeeplearningnetwork forcounty-levelcornyieldestimationintheuscornbelt. IEEEJournalofSelectedTopicsinAppliedEarth ObservationsandRemoteSensing,13:5048\u20135060,2020. [4] Xingguo Xiong, Renhai Zhong, Qiyu Tian, Jingfeng Huang, Linchao Zhu, Yi Yang, and Tao Lin. Daily deepcropnet: Ahierarchicaldeeplearningapproachwithdailytimeseriesofvegetationindicesandclimatic variablesforcornyieldestimation. ISPRSJournalofPhotogrammetryandRemoteSensing,209:249\u2013264,2024. [5] MNandhini,KUKala,MThangadarshini,andSMadhusudhanaVerma. Deeplearningmodelofsequential imageclassifierforcropdiseasedetectioninplantaintreecultivation. ComputersandElectronicsinAgriculture, 197:106915,2022. [6] YangHu,GangWang,ExianLiu,JialeZhu,andMingfangHe. Amf: Amulti-modalframeworkforcropleaf diseasessegmentation. ComputersandElectronicsinAgriculture,237:110550,2025. [7] ZRui,ZZhang,MZhang,AAzizi,CIgathinathane,HCen,SVougioukas,HLi,JZhang,YJiang,etal. High- throughputproximalgroundcropphenotypingsystems\u2013acomprehensivereview. ComputersandElectronicsin Agriculture,224:109108,2024. [8] JiangtaoQi,FangfangGao,YangWang,WeirongZhang,SisiYang,KangkangQi,andRuiruiZhang. Multiscale phenotyping of grain crops based on three-dimensional models: A comprehensive review of trait detection. ComputersandElectronicsinAgriculture,237:110597,2025. [9] LucasCUzal,GuillermoLGrinblat,RafaelNam\u00edas,M\u00f3nicaGLarese,JulietaSofiaBianchi,EligioNMorandi, andPabloMGranitto.Seed-per-podestimationforplantbreedingusingdeeplearning.Computersandelectronics inagriculture,150:196\u2013204,2018. [10] ZheZhang,XiuJin,YuanRao,TianyuWan,XiaoboWang,JiajiaLi,HaoranChen,KangleiWu,FanchenKong, ZhuoTian,etal. Dsbean:Aninnovativeframeworkforintelligentsoybeanbreedingphenotypeanalysisbasedon variousmainstemstructuresanddeeplearningmethods. ComputersandElectronicsinAgriculture,224:109135, 2024. [11] LeiLiu,FanYang,XiangyiLiu,YuefengDu,XiaoyuLi,GuorunLi,DuChen,ZhongxiangZhu,andZhenghe Song. Areviewofthecurrentstatusandcommonkeytechnologiesforagriculturalfieldrobots. Computersand ElectronicsinAgriculture,227:109630,2024. [12] YanqiuYang,PriyankaMali,LawrenceArthur,FaezehMolaei,SenaAtsyo,JiaruiGeng,LongHe,andShirin Ghatrehsamani. Advancedtechnologiesforprecisiontreefruitdiseasemanagement: Areview. Computersand ElectronicsinAgriculture,229:109704,2025. [13] RishiBommasani,DrewAHudson,EhsanAdeli,RussAltman,SimranArora,SydneyvonArx,MichaelS Bernstein,JeannetteBohg,AntoineBosselut,EmmaBrunskill,etal. Ontheopportunitiesandrisksoffoundation models. arXivpreprintarXiv:2108.07258,2021. [14] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,LauraGustafson,TeteXiao,Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. Segment anything. In Proceedings of the IEEE/CVF internationalconferenceoncomputervision,pages4015\u20134026,2023. [15] HarshPathak,YaguangZhang,NathanCSprague,DennisRBuckmaster,JohnTEvans,SomaliChaterji,and JamesVKrogmeier. Autonomousnavigationindigitalagriculture: Usingthesegment-anything-modelforcorn rowidentification. pages1\u20134,2023. [16] JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,FlorenciaLeoniAleman,Diogo Almeida,JankoAltenschmidt,SamAltman,ShyamalAnadkat,etal. Gpt-4technicalreport. arXivpreprint arXiv:2303.08774,2023. [17] ArchitParnamiandMinwooLee. Learningfromfewexamples: Asummaryofapproachestofew-shotlearning. arXivpreprintarXiv:2203.04291,2022. 21 --- Page 22 --- [18] HaiziYu,IgorMineyev,LavRVarshney,andJamesAEvans. Learningfromoneandonlyoneshot. npjArtificial Intelligence,1(1):13,2025. [19] XueJiang, JiashiWang, KaiXie, ChenxiCui, AoboDu, XianglongShi, WannengYang, andRuifangZhai. Plantcafo: Anefficientfew-shotplantdiseaserecognitionmethodbasedonfoundationmodels. PlantPhenomics, 7(1):100024,2025. [20] HaoChen,HaidongLi,JinlingZhao,ChaoRuan,andLinshengHuang. Enhancingcropdiseaserecognition viapromptlearning-basedprogressivemixupandcontrastivelanguage-imagepre-trainingdynamiccalibration. EngineeringApplicationsofArtificialIntelligence,152:110805,2025. [21] KhangNguyenQuoc,LanLeThiThu,andLuyl-DaQuach. Avision-languagefoundationmodelforleafdisease identification. arXivpreprintarXiv:2505.07019,2025. [22] Yubin Lan, Yaqi Guo, Qizhen Chen, Shaoming Lin, Yuntong Chen, and Xiaoling Deng. Visual question answeringmodelforfruittreediseasedecision-makingbasedonmultimodaldeeplearning. FrontiersinPlant Science,13:1064399,2023. [23] MahsaKhosravi,ZhanhongJiang,JoshuaRWaite,SarahEJones,HernanTorresPacin,ArtiSingh,Baskar Ganapathysubramanian, Asheesh Kumar Singh, and Soumik Sarkar. Optimizing navigation and chemical application in precision agriculture with deep reinforcement learning and conditional action tree. Smart AgriculturalTechnology,page101194,2025. [24] Chung Hee Kim, Abhisesh Silwal, and George Kantor. Autonomous robotic pepper harvesting: Imitation learninginunstructuredagriculturalenvironments. IEEERoboticsandAutomationLetters,2025. [25] Lun Li and Hamidreza Kasaei. Enhanced view planning for robotic harvesting: Tackling occlusions with imitationlearning. arXivpreprintarXiv:2503.10334,2025. [26] RickvanEssen,EldertvanHenten,andGertKootstra. Uav-basedpathplanningforefficientlocalizationof non-uniformlydistributedweedsusingpriorknowledge: Areinforcement-learningapproach. Computersand ElectronicsinAgriculture,237:110651,2025. [27] MohammedAbdalla,OsamaMohamed,andElshaimaaMAzmi. Adaptivelearningmodelfordetectingwheat diseases. InternationalJournalofAdvancedComputerScience&Applications,15(5),2024. [28] ChangXu,YidingZhang,LeiZhao,HaojieWen,andLingxianZhang. Knowledge-guidedadaptivespatial- temporalgraphcontrastivelearningframework: Regionalcropdiseasespredictionbasedonelectronicmedical records. NeuralNetworks,page107597,2025. [29] XiangLiu,ZhaoxiangLiu,HuanHu,ZezhouChen,KohouWang,KaiWang,andShiguoLian. Amultimodal benchmarkdatasetandmodelforcropdiseasediagnosis. InEuropeanConferenceonComputerVision,pages 157\u2013170.Springer,2024. [30] PShojaee,IMirzadeh,KAlizadeh,MHorton,SBengio,andMFarajtabar. Theillusionofthinking: Under- standingthestrengthsandlimitationsofreasoningmodelsviathelensofproblemcomplexity.apple,2025. [31] DongChenandYanboHuang. Integratingreinforcementlearningandlargelanguagemodelsforcropproduc- tionprocessmanagementoptimizationandcontrolthroughanewknowledge-baseddeeplearningparadigm. ComputersandElectronicsinAgriculture,232:110028,2025. [32] Hossein Zaremehrjerdi, Shreyan Ganguly, Ashlyn Rairdin, Elizabeth Tranel, Benjamin Feuer, Juan Ignacio DiSalvo,SrikanthPanthulugiri,HernanTorresPacin,VictoriaMoser,SarahJones,etal. Towardslargereasoning modelsforagriculture. arXivpreprintarXiv:2505.19259,2025. [33] EmmanouilPapagiannidis,PatrickMikalef,andKieranConboy. Responsibleartificialintelligencegovernance: Areviewandresearchframework. TheJournalofStrategicInformationSystems,34(2):101885,2025. [34] Rabiya Abbasi, Pablo Martinez, and Rafiq Ahmad. The digitization of agricultural industry\u2013a systematic literaturereviewonagriculture4.0. SmartAgriculturalTechnology,2:100042,2022. [35] AlecRadford,KarthikNarasimhan,TimSalimans,IlyaSutskever,etal. Improvinglanguageunderstandingby generativepre-training. 2018. [36] JaeYoungKimandYongSukChung. Ashortreviewofrgbsensorapplicationsforaccessiblehigh-throughput phenotyping. JournalofCropScienceandBiotechnology,24(5):495\u2013499,2021. [37] JunFu,JindaiLiu,RongqiangZhao,ZhiChen,YongliangQiao,andDanLi. Maizediseasedetectionbasedon spectralrecoveryfromrgbimages. FrontiersinPlantScience,13:1056842,2022. [38] Corey Davidson, Vishnu Jaganathan, Arun Narenthiran Sivakumar, Joby M Prince Czarnecki, and Girish Chowdhary. Ndvi/ndre prediction from standard rgb aerial imagery using deep learning. Computers and ElectronicsinAgriculture,203:107396,2022. 22 --- Page 23 --- [39] HongyanZhu,ChengzhiLin,GengqiLiu,DaniWang,ShuaiQin,AnjieLi,Jun-LiXu,andYongHe. Intelligent agriculture: Deeplearninginuav-basedremotesensingimageryforcropdiseasesandpestsdetection. Frontiers inPlantScience,15:1435016,2024. [40] Abhishek Upadhyay, Narendra Singh Chandel, Krishna Pratap Singh, Subir Kumar Chakraborty, Balaji M Nandede, Mohit Kumar, A Subeesh, Konga Upendar, Ali Salem, and Ahmed Elbeltagi. Deep learning and computervisioninplantdiseasedetection:acomprehensivereviewoftechniques,models,andtrendsinprecision agriculture. ArtificialIntelligenceReview,58(3):92,2025. [41] ACamargoandJSSmith. Imagepatternclassificationfortheidentificationofdiseasecausingagentsinplants. Computersandelectronicsinagriculture,66(2):121\u2013125,2009. [42] DanutaPacka,MarianWiwart,Elz\u02d9bietaSuchowilska,andTeresaBienkowska. Morpho-anatomicaltraitsof twolowestinternodesrelatedtolodgingresistanceinselectedgenotypesoftriticum. Internationalagrophysics, 29(4),2015. [43] SanjeevSSannakki,VijaySRajpurohit,VBNargund,andPallaviKulkarni.Diagnosisandclassificationofgrape leafdiseasesusingneuralnetworks. In2013FourthInternationalConferenceonComputing,Communications andNetworkingTechnologies(ICCCNT),pages1\u20135.IEEE,2013. [44] SachinBJadhavandSanjayBPatil. Gradingofsoybeanleafdiseasebasedonsegmentedimageusingk-means clustering. IAESInternationalJournalofArtificialIntelligence,5(1):13\u201313,2016. [45] PunamBedi,PushkarGole,andSumitKumarAgarwal. 18usingdeeplearningforimage-basedplantdisease detection. InternetOfthingsandmachinelearninginagriculture,pages369\u2013402,2021. [46] Mohammed Brahimi, Kamel Boukhalfa, and Abdelouahab Moussaoui. Deep learning for tomato diseases: classificationandsymptomsvisualization. AppliedArtificialIntelligence,31(4):299\u2013315,2017. [47] JundeChen,JinxiuChen,DefuZhang,YuandongSun,andYaserAhangariNanehkaran. Usingdeeptransfer learningforimage-basedplantdiseaseidentification. Computersandelectronicsinagriculture,173:105393, 2020. [48] AlvaroFuentes,SookYoon,SangCheolKim,andDongSunPark. Arobustdeep-learning-baseddetectorfor real-timetomatoplantdiseasesandpestsrecognition. Sensors,17(9):2022,2017. [49] PoornimaSinghThakur,PriteeKhanna,TanujaSheorey,andAparajitaOjha. Explainablevisiontransformer enabledconvolutionalneuralnetworkforplantdiseaseidentification:Plantxvit.arXivpreprintarXiv:2207.07919, 2022. [50] MoshiurRahmanTonmoy, MdMithunHossain, NilanjanDey, andMFMridha. Mobileplantvit: Amobile- friendlyhybridvitforgeneralizedplantdiseaseimageclassification. arXivpreprintarXiv:2503.16628,2025. [51] NVIDIA. Whatarefoundationmodels?,March2024. Accessed: 2025-08-05. [52] AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,SandhiniAgarwal,GirishSastry, AmandaAskell,PamelaMishkin,JackClark,etal. Learningtransferablevisualmodelsfromnaturallanguage supervision. InInternationalconferenceonmachinelearning,pages8748\u20138763.PmLR,2021. [53] Jean-BaptisteAlayrac,JeffDonahue,PaulineLuc,AntoineMiech,IainBarr,YanaHasson,KarelLenc,Arthur Mensch,KatherineMillican,MalcolmReynolds,etal. Flamingo: avisuallanguagemodelforfew-shotlearning. Advancesinneuralinformationprocessingsystems,35:23716\u201323736,2022. [54] XinyanZhao,BaiyanChen,MengxueJi,XinyueWang,YuhanYan,JinmingZhang,ShiyingjieLiu,MuyangYe, andChunliLv. Implementationoflargelanguagemodelsandagriculturalknowledgegraphsforefficientplant diseasedetection. Agriculture(Switzerland),14(8),2024. Citedby: 8;AllOpenAccess;GoldOpenAccess. [55] AsafTzachor,MedhaDevare,CatherineRichards,PieterPypers,AniruddhaGhosh,JawooKoo,SJohal,and BrianKing. Largelanguagemodelsandagriculturalextensionservices. Naturefood,4(11):941\u2013948,2023. [56] DaanR.Scheepens,JosephW.Millard,MaxwellJ.Farrell,andTimNewbold. Largelanguagemodelshelp facilitatetheautomatedsynthesisofinformationonpotentialpestcontrollers. MethodsinEcologyandEvolution, 15(7):1261\u20131273,2024. Citedby: 6;AllOpenAccess;GoldOpenAccess;GreenAcceptedOpenAccess; GreenOpenAccess. [57] MatheusThomasKuska,MirwaesWahabzada,andStefanPaulus. Aiforcropproduction\u2013wherecanlarge languagemodels(llms)providesubstantialvalue? ComputersandElectronicsinAgriculture,221,2024. Cited by: 25;AllOpenAccess;HybridGoldOpenAccess. [58] ParamAhirandNikunjV.Tahilramani. Integratinglanguagemodelswithsensordataforenhancedplanthealth monitoringandqueryresponse. InternationalJournalofComputerApplicationsinTechnology,75(2-4):178\u2013 187,2024. Citedby: 0. 23 --- Page 24 --- [59] Auvick Chandra Bhowmik, Md Taimur Ahad, Yousuf Rayhan Emon, Faruk Ahmed, Bo Song, and Yan Li. A customised vision transformer for accurate detection and classification of java plum leaf disease. Smart AgriculturalTechnology,8:100500,2024. [60] PoornimaSinghThakur,ShubhangiChaturvedi,PriteeKhanna,TanujaSheorey,andAparajitaOjha.Visiontrans- formermeetsconvolutionalneuralnetworkforplantdiseaseclassification. EcologicalInformatics,77:102245, 2023. [61] TianYang,YupengMei,LingXu,HuihuiYu,andYingyiChen. Applicationofquestionansweringsystems forintelligentagricultureproductionandsustainablemanagement: Areview. Resources, Conservationand Recycling,204:107497,2024. [62] HaitaoLiu,JihuaSong,andWeimingPeng. Glyreshot: Aglyph-awaremodelwithlabelrefinementforfew-shot chineseagriculturalnamedentityrecognition. Heliyon,10(12),2024. [63] BiplovPaneru,BipulThapa,andBishwashPaneru. Leveragingaiinayurvedicagriculture: Aragchatbotfor comprehensivemedicinalplantinsightsusinghybriddeeplearningapproaches. TelematicsandInformatics Reports,16:100181,2024. [64] LiWang. Digitaltwinsinagriculture: areviewofrecentprogressandopenissues. Electronics,13(11):2209, 2024. [65] Biao Zhao, Weiqiang Jin, Javier Del Ser, and Guang Yang. Chatagri: Exploring potentials of chatgpt on cross-linguisticagriculturaltextclassification. Neurocomputing,557:126708,2023. [66] SaedRezayi,ZhengliangLiu,ZihaoWu,ChandraDhakal,BaoGe,ChenZhen,TianmingLiu,andShengLi. Agribert: Knowledge-infusedagriculturallanguagemodelsformatchingfoodandnutrition. InIJCAI,pages 5150\u20135156,2022. [67] JiuqingDong,YifanYao,AlvaroFuentes,YongchaeJeong,SookYoon,andDongSunPark. Visualinformation guidedmulti-modalmodelforplantdiseaseanomalydetection. SmartAgriculturalTechnology,9:100568,2024. [68] JiajunQing,XiaolingDeng,YubinLan,andZhikaiLi. Gpt-aideddiagnosisonagriculturalimagebasedona newlightYOLOPC. Computersandelectronicsinagriculture,213:108168,2023. [69] KunpengZhang,LiMa,BeibeiCui,XinLi,BoqiangZhang,andNaXie. Visuallargelanguagemodelforwheat diseasediagnosisinthewild. ComputersandElectronicsinAgriculture,227:109587,2024. [70] BorjaEspejo-Garcia,RonjaG\u00fcldenring,LazarosNalpantidis,andSpyrosFountas. Foundationvisionmodels inagriculture: Dinov2, loraandknowledgedistillationfordiseaseandweedidentification. Computersand ElectronicsinAgriculture,239:110900,2025. [71] JiandongPan,RenhaiZhong,FulinXia,JingfengHuang,LinchaoZhu,YiYang,andTaoLin. Chatleafdisease: a chain-of-thought prompting approach for crop disease classification using large language models. Plant Phenomics,page100094,2025. [72] ChangqingYan,ZeyunLiang,HanCheng,ShuyangLi,GuangpengYang,ZhiweiLi,LingYin,JunjieQu,Jing Wang,GenghongWu,etal. Cdip-chatglm3: Adual-modelapproachintegratingcomputervisionandlanguage modelingforcropdiseaseidentificationandprescription. ComputersandElectronicsinAgriculture,236:110442, 2025. [73] NitinRai,ArnoldSchumann,andNathanBoyd. Phytosynth: Leveragingmulti-modalgenerativemodelfor cropdiseasedatagenerationwithnovelbenchmarkingandpromptengineeringapproach. InProceedingsofthe ComputerVisionandPatternRecognitionConference,pages5371\u20135380,2025. [74] ChunhuiBai,LilianZhang,LutaoGao,LinPeng,PeishanLi,andLinnanYang. Dinov2-fcs: amodelforfruit leafdiseaseclassificationandseverityprediction. FrontiersinPlantScience,15:1475282,2024. [75] FangfangLiang,ZilongHuang,WenjianWang,ZhenxueHe,andQingEn.Dynamictextpromptjointmultimodal featuresforaccurateplantdiseaseimagecaptioning. TheVisualComputer,pages1\u201315,2024. [76] GuoweiXu,WeitingZhao,YuhuiBie,MingliangGe,ZekunCui,andYaojunWang. Agro-llava-next: Alarge multimodalmodelforplantdiseasesrecognization. InInternationalConferenceonIntelligentComputing,pages 291\u2013302.Springer,2025. [77] Kejun Zhao, Xingcai Wu, Yuanyuan Xiao, Sijun Jiang, Peijia Yu, Yazhou Wang, and Qi Wang. Plantext: Gradually masked guidance to align image phenotypes with trait descriptions for plant disease texts. Plant Phenomics,6:0272,2024. [78] YunpengZhao,ShansongWang,QingtianZeng,WeijianNi,HuaDuan,NengfuXie,andFengjinXiao.Informed- learning-guidedvisualquestionansweringmodelofcropdisease. PlantPhenomics,6:0277,2024. 24 --- Page 25 --- [79] Jinyang Li, Fengting Zhao, Hongmin Zhao, Guoxiong Zhou, Jiaxin Xu, Mingzhou Gao, Xin Li, Weisi Dai, HonliangZhou,YahuiHu,etal. Amulti-modalopenobjectdetectionmodelfortomatoleafdiseaseswithstrong generalizationperformanceusingpdc-vld. PlantPhenomics,6:0220,2024. [80] HongliangZhou,YufanHu,ShuaiLiu,GuoxiongZhou,JiaxinXu,AibinChen,YanfengWang,LiujunLi,and YahuiHu. Apreciseframeworkforriceleafdiseaseimage\u2013textretrievalusingfhtw-net. PlantPhenomics, 6:0168,2024. [81] Chenshuo Zhang, Lijie Zhang, Huarui Wu, Chunshan Wang, Cheng Chen, Huaji Zhu, and Fangfang Liang. Chinese named entity recognition for agricultural diseases based on entity-related visual prompts injection. ComputersandElectronicsinAgriculture,227:109493,2024. [82] BowenLv,HuaruiWu,WenbaiChen,ChengChen,YishengMiao,andChunjiangZhao.Veg-mmkg:Multimodal knowledgegraphconstructionforvegetablesbasedonpre-trainedmodelextraction. Computersandelectronics inagriculture,226:109398,2024. [83] Shan-SongWang,Wei-JianNi,Qing-TianZeng,Neng-FuXie,andChaoLi. Apd-229: atextual-visualdatabase foragriculturalpestsanddiseases. MultimediaToolsandApplications,83(8):22189\u201322220,2024. [84] YueyueZhou,HongpingYan,KunDing,TingtingCai,andYanZhang. Few-shotimageclassificationofcrop diseasesbasedonvision\u2013languagemodels. Sensors,24(18):6109,2024. [85] EmmanuelMoupojou,FlorentRetraint,HyppoliteTapamo,MarcellinNkenlifack,CheikhKacfah,andAppoli- naireTagne. Segmentanythingmodel&fullyconvolutionaldatadescriptionforplantmulti-diseasedetectionon fieldimages. IEEEAccess,2024. [86] JiuqingDong,AlvaroFuentes,HengZhou,YongchaeJeong,SookYoon,andDongSunPark. Theimpactof fine-tuningparadigmsonunknownplantdiseasesrecognition. ScientificReports,14(1):17900,2024. [87] YiyiCao,LeiChen,YuanYuan,andGuanglingSun. Cucumberdiseaserecognitionwithsmallsamplesusing image-text-label-basedmulti-modallanguagemodel. Computersandelectronicsinagriculture,211:107993, 2023. [88] GuoweiDai,JingchaoFan,andChristineDewi. Itf-wpi: Imageandtextbasedcross-modalfeaturefusionmodel forwolfberrypestrecognition. ComputersandElectronicsinAgriculture,212:108129,2023. [89] TekRajChhetri,ArminHohenegger,AnnaFensel,MariamAramideKasali,andAsiruAfeezAdekunle. Towards improvingpredictionaccuracyanduser-levelexplainabilityusingdeeplearningandknowledgegraphs: Astudy oncassavadisease. ExpertSystemswithApplications,233:120955,2023. [90] XiaQiu,HongwenChen,PingHuang,DanZhong,TaoGuo,ChangbinPu,ZongnanLi,YonglingLiu,JinChen, andSiWang. Detectionofcitrusdiseasesincomplexbackgroundsbasedonimage\u2013textmultimodalfusionand knowledgeassistance. FrontiersinPlantScience,14:1280365,2023. [91] YinshuoZhang,LeiChen,andYuanYuan. Multimodalfine-grainedtransformermodelforpestrecognition. Electronics,12(12):2620,2023. [92] ShansongWang,QingtianZeng,WeijianNi,ChengCheng,andYanxueWang. Odp-transformer: Interpretation ofpestclassificationresultsusingimagecaptiongenerationtechniques.ComputersandElectronicsinAgriculture, 209:107863,2023. [93] JiZhou,JiuxiLi,ChunshanWang,HuaruiWu,ChunjiangZhao,andGuifaTeng. Cropdiseaseidentification and interpretation method based on multimodal deep learning. Computers and Electronics in Agriculture, 189:106408,2021. [94] MLLittmanandAWMoore. Reinforcementlearning: Asurvey,journalofartificialintelligenceresearch4, 1996. [95] Marcin Woz\u00b4niak and Muhammad Fazal Ijaz. Recent advances in big data, machine, and deep learning for precisionagriculture. FrontiersinPlantScience,15:1367538,2024. [96] Dar\u00edoFernandoY\u00e9pez-Ponce, Jos\u00e9VicenteSalcedo, Pa\u00falDRosero-Montalvo, andJavierSanchis. Mobile roboticsinsmartfarming: currenttrendsandapplications. FrontiersinArtificialIntelligence,6:1213330,2023. [97] Georg Goldenits, Kevin Mallinger, Sebastian Raubitzek, and Thomas Neubauer. Current applications and potential future directions of reinforcement learning-based digital twins in agriculture. Smart Agricultural Technology,8:100512,2024. [98] JiachenYang,JingfeiNi,YangLi,JiabaoWen,andDeshengChen. Theintelligentpathplanningsystemof agriculturalrobotviareinforcementlearning. Sensors,22(12):4316,2022. 25 --- Page 26 --- [99] YajunLi,QingchunFeng,YifanZhang,ChuanlangPeng,YuhangMa,ChengLiu,MengfeiRu,JiahuiSun,and ChunjiangZhao. Pedunclecollision-freegraspingbasedondeepreinforcementlearningfortomatoharvesting robot. ComputersandElectronicsinAgriculture,216:108488,2024. [100] FranciscoYandun,TanvirParhar,AbhiseshSilwal,DavidClifford,ZhiqiangYuan,GabriellaLevine,Sergey Yaroshenko,andGeorgeKantor. Reachingpruninglocationsinavineusingadeepreinforcementlearningpolicy. In2021IEEEInternationalConferenceonRoboticsandAutomation(ICRA),pages2400\u20132406.IEEE,2021. [101] TDKelly,TFoster,andDavidMSchultz. Assessingthevalueofdeepreinforcementlearningforirrigation scheduling. SmartAgriculturalTechnology,7:100403,2024. [102] TalhaSiddique,JiaLinHau,ShadiAtallah,andMarekPetrik. Robustpestmanagementusingreinforcement learning. InTheMulti-disciplinaryConferenceonReinforcementLearningandDecisionMaking,2019. [103] ZiyuanHao,XinzeLi,ChaoMeng,WeiYang,andMinzanLi. Adaptivesprayingdecisionsystemforplant protectionunmannedaerialvehiclebasedonreinforcementlearning. InternationalJournalofAgriculturaland BiologicalEngineering,15(4):16\u201326,2022. [104] AliMoltajaeiFarid,JafarRoshanian,andMalekMouhoub. Multipleaerial/groundvehiclescoordinatedspraying usingreinforcementlearning. EngineeringApplicationsofArtificialIntelligence,151:110686,2025. [105] JeffMulhollem. Usdagranttofundroboticprecisionpesticidesprayerdevelopment,2024. Accessed: 2025-04- 24. [106] OmeedMirbod,DaeunChoi,andJohnKSchueller. Fromsimulationtofieldvalidation: Adigitaltwin-driven sim2realtransferapproachforstrawberryfruitdetectionandsizing. AgriEngineering,7(3):81,2025. [107] StevenKimandSeongHeo. Anagriculturaldigitaltwinformandarinsdemonstratesthepotentialforindividual- izedagriculture. NatureCommunications,15(1):1561,2024. [108] DRajeswari,AthishVenkatachalamParthiban,andSivaramPonnusamy. Digitaltwin-basedcropyieldprediction inagriculture. InHarnessingAIandDigitalTwinTechnologiesinBusinesses,pages99\u2013110.IGIGlobal,2024. [109] PeymanMoghadam,ThomasLowe,andEverardJEdwards. Digitaltwinforthefutureoforchardproduction systems. InProceedings,volume36,page92.MDPI,2020. [110] MinDai,YutianShen,XiaoyinLi,JingjingLiu,ShanwenZhang,andHongMiao. Digitaltwinsystemofpest managementdrivenbydataandmodelfusion. Agriculture,14(7):1099,2024. [111] YujiaLuoandPeterBall. Adaptiveproductionstrategyinverticalfarmdigitaltwinswithq-learningalgorithms. ScientificReports,15(1):15129,2025. 26",
  "conclusion": "Conclusion Inconclusion,FMsarereshapingSSDMincropsbyaddressingkeylimitationsoftraditionalmachineanddeeplearning"
}