{
  "abstract": "Abstract WepresentTongyiDeepResearch,anagenticlargelanguagemodel,which isspecificallydesignedforlong-horizon,deepinformation-seekingresearch tasks. Toincentivizeautonomousdeepresearchagency,TongyiDeepResearch isdevelopedthroughanend-to-endtrainingframeworkthatcombinesagen- tic mid-training and agentic post-training, enabling scalable reasoning and informationseekingacrosscomplextasks. Wedesignahighlyscalabledata synthesis pipeline that is fully automatic, without relying on costly human annotation, and empowers all training stages. By constructing customized environmentsforeachstage,oursystemenablesstableandconsistentinterac- tionsthroughout. TongyiDeepResearch,featuring30.5billiontotalparameters, withonly3.3billionactivatedpertoken,achievesstate-of-the-artperformance acrossarangeofagenticdeepresearchbenchmarks,includingHumanity\u2019sLast Exam,BrowseComp,BrowseComp-ZH,WebWalkerQA,xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We open-source the model, frame- work,andcompletesolutionstoempowerthecommunity. 35 30 25 20 15 DeTe(op3nR0geBys-i Aea3rBc)h DeepSeek-V3.1 ReKsiemaircher DeGeepm Riensiearch DeOeppeRneA sIearch GLM-4.5 DPeeerpplReexsiteyarch  Humanity's Last Exam BrowseComp BrowseComp-ZH WebWalkerQA 32.9 29.8 45 55 51.5 43.4 50 46.7 42.9 77 05 72.2 71.7 26.9 26.9 26.6 21.2 21.1 123 555 30.0 28.3 26.4 14.1 12.2 34 00 37.5 29.1 28.8 66 05 65.6 63.0 61.7 61.2 5 DeOeppeRneA sIearch DeTe(op3nR0geBys-i Aea3rBc)h DeepSeek-V3.1 OpenAI-o4-mini GLM-4.5 Kimi-K2 Claude-4-Sonnet20 DeTe(op3nR0geBys-i Aea3rBc)h DeOeppeRneA sIearch GLM-4.5 Claude-4-Sonnet Kimi-K2 55 DeTe(op3nR0geBys-i Aea3rBc)h OpenAI-o3 GLM-4.5 Kimi-K2 Claude-4-Sonnet DeepSeek-V3.1 70 60 50 DeTe(op3nR0geBys-i Aea3rBc)h Claude-4-Sonnet DeOeppeRneA sIearch GLM-4.5 DeepSeek-V3.1 Kimi-K2  GAIA xbench-DeepSearch FRAMES xbench-DeepSearch-2510 70.9 68.3 67.4 66.0 63.1 57.7 67 55 75.0 71.0 70.0 69.0 67.0 65.0 789 555 90.6 84.0 83.7 80.7 78.9 78.8 72.0 4578 0505 75+ 55+ 40+ 35+ 35+ 35+ 25 55 DeTe(op3nR0geBys-i Aea3rBc)h DeepSeek-V3.1 GLM-4.5 ReKsiemaircher OpenAI-o3 Claude-4-Sonnet 65 DeTe(op3nR0geBys-i Aea3rBc)h OpenAI-o3 DeepSeek-V3.1 Claude-4-Sonnet GLM-4.5 ReKsiemaircher Kimi-K2 10 ChatGPT-5-Pro DeTe(op3nR0geBys-i Aea3rBc)h SupEexrpGerrotk DeDeop uRbeasoearch Manus Agent Minimax Agent Figure1: BenchmarkperformanceofTongyiDeepResearch. \u2217FullauthorlistavailableintheContributionssection. 1 5202 tcO 82 ]LC.sc[ 1v10742.0152:viXra --- Page 2 ---",
  "introduction": "1 Introduction AsweadvancetowardArtificialGeneralIntelligence(AGI),theemergenceofDeepResearchagentsoffers apromisingparadigmforaugmentingandpotentiallyliberatinghumanintellectualproductivity. Deep researchisanewagenticcapabilitythatautonomouslyconductsmulti-stepreasoningandinformation seekingontheinternetforcomplexresearchtasks. Itcanbecompletedintensofminutes,whichwould otherwise require several hours for a human (OpenAI, 2025a; Claude Team, 2025; Grok Team, 2025; GeminiTeam,2025). However,mostdeepresearchsystemsremainclosed-source,andtheirintermediate researchprocessesareinaccessible. Whilethecommunityhasmadepreliminaryexplorationsinthis area(Wuetal.,2025a;Lietal.,2025c;Taoetal.,2025),thereisstillalackofasystematicmethodologyand publiclyavailablemodelsthatcanbefullyopen-sourcedandsharedacrossthecommunity. Inthiswork,weintroduceTongyiDeepResearch,openingtheeraofopen-sourceAIresearchers. Our goalistoendowlargelanguagemodels(LLMs)withautonomousresearchcapabilitiesagency,theability toplan, search, reason, andsynthesizeknowledgeacrossextendedsequencesofactionsanddiverse informationsources. TongyiDeepResearchdeliversseveralkeyadvancements: \u2022 Weproposeanend-to-endagentictrainingparadigmthatunifiesagenticmid-trainingandagentic post-training,formingascalablefoundationfordeepreasoningandinformation-seekingbehaviors. Agenticmid-trainingcultivatesinherentagenticbiasesbyexposingthemodeltolarge-scale,high- quality agentic data, serving as a progressive transition from pre-training to post-training stages. Agenticpost-trainingfurtherunlocksthemodel\u2019spotentialviascalablemulti-turnreinforcement learningonastrongbasemodel. Together,theyenablethemodeltograduallydevelopfrombasic interactionskillstoadvancedautonomousresearchbehaviors. \u2022 Wedesignafullyautomated,highlyscalabledatasynthesispipelinethateliminateshumanannota- tionwhilegeneratingdiverse,high-qualityagenttrajectories. Wedesignstage-specificdatasynthesis strategiestailoredtotheobjectivesofeachtrainingphase,ensuringthateverystageissupported by appropriately structured and targeted data. Synthetic data is highly scalable, fast to validate, andenablestheconstructionofsuper-human-leveldatasetswithstabledistributions. Itservesasan indispensableengineforagenttraining. \u2022 Weconstructstage-specific,customizedenvironmentsthatrelyonrobustinfrastructuretodeliver consistentinteractionsfordatasynthesisacrosstrainingstages.Theseenvironmentsallowtheagentto engageinrich,specializedinteractionsthataretightlyalignedwithitsdevelopmentalstage. Theycan takevariousforms,frompriorworldmodelstosimulatedenvironmentsandreal-worldinteractive contexts. TongyiDeepResearchestablishesanewstate-of-the-artwithsubstantiallyfewerparameters,comprising atotalof30.5billionparameterswhileactivatingonly3.3billionpertoken,buildingupontheQwen3- 30B-A3B-Basemodel(Yangetal.,2025). Empiricalevaluationsondeepresearchbenchmarksdemonstrate the effectiveness of our agent. Tongyi DeepResearch reaches 32.9 on Humanity\u2019s Last Exam, 43.4 on BrowseComp, 46.7 on BrowseComp-ZH, 72.2 on WebWalkerQA, 70.9 on GAIA, 75.0 on xbench- DeepSearch, 90.6onFRAMESand55.0onxbench-DeepSearch-2510, outperformingstrongbaselines such as OpenAI-o3 (OpenAI, 2025b) and Deepseek-V3.1 (DeepSeek Team, 2025). We also provide a systematicanalysiscoveringagenticreinforcementlearning,syntheticdata,offeringkeyinsightsintothe developmentofdeepresearchagent. Inaddition,wepresenttheperformanceofTongyiDeepResearch ongeneralbenchmarks,includingAIME25,HMMT25andSimpleQA.Webelievethatagenticmodels representanemergingtrendforthefuture,asmodelsincreasinglyinternalizeagent-likecapabilitiesand canautonomouslyinvoketheappropriatetoolstosolveawiderangeofproblems. Inthefollowingsections,wefirstoutlinethedesignprinciplesunderlyingTongyiDeepResearch. We then describe the training pipeline, followed by a comprehensive evaluation of its performance. We 2 --- Page 3 --- releasethemodel,framework,andend-to-endsolutionstosupportandacceleratecommunityresearch. Thistechnicalreportsummarizesourmaininsightsandaimstoinspirefurtherprogresstowardscalable andcapableagenticsystems. 2 Design Principle AgentTrainingPipeline. Agenttrainingisinherentlymorecomplexandchallengingthanconventional LLMtraining. Weintroducetwostagesinouragenttrainingpipeline: mid-trainingandpost-training. Weintegratemid-trainingdirectlyintothedeepresearchtrainingprocess,andco-designtheend-to-end on-policyreinforcementlearningalgorithmanditsunderlyinginfrastructureforseamlessscalability andstability. Whilemostworkonlyappliespost-trainingphaseforDeepResearchagents,wenovelly introducemid-trainingforagenticlearning. Generalfoundationmodelsusuallylackagenticinductive bias. Mostgeneralfoundationmodelsaretypicallypretrainedonplaintextcrawledfromtheinternetand thenpost-trainedoninstruction-followingdata. Thesedatasetslackresearch-levelquestionsandagentic behaviors,resultinginthemodellearnsagenticcapabilitiesandalignmentsimultaneouslyduringthe post-trainingphase. Agenticpost-trainingonthesegeneralfoundationmodelscanresultinsub-optimal outcomesandinherentoptimizationconflicts. Mid-trainingendowsthepre-trainedbasemodelwith substantialagenticpriorknowledge,therebybridgingthegapbetweenpretrainingandagenticpost- training. Mid-trainingphaseprovidesapowerfulagenticfoundationmodeltosupporteffectiveagentic post-training. Duringpost-training,themodelfurtherinternalizesdeepresearchcapabilitiesthrough reinforcementlearningwithsupervisedfine-tuning(SFT)forcoldstart. SFTteachesthemodeltoreliably imitatecurateddemonstrations,establishingastablebehavioralbaselineforresearchworkflowsandtool use. However,behaviorcloningalonetendstoproducemimicrywithoutexploration. RLclosestheloop withtheenvironment,usingrewardsignalstorefinepoliciesandtointernalizeagenticplanningand execution. Inparticular,reinforcementlearning(1)exploresoptimalstrategiesthroughactiveinteraction withtheenvironment;(2)internalizesgoal-directedplanningandexecutioncapabilities;and3)achieves superiorsampleefficiencybyprioritizinghigh-rewardbehaviors. Theagentfirstacquiresgeneralagentic patternduringsupervisedfine-tuningphase,whilereinforcementlearningphaseeffectivelypushesthe limitsofitsagenticperformance. Synthetic Data Centric Scaling. Data serves as the foundation of training, while collecting data for DeepResearchproblemsisextremelyhard. Deepresearchproblemsrequireagents\u2019capabilityofconnect- inginformation,reasoningacrosssourcesandvalidatingconclusions. Unlikepre-trainingdata,which isnaturallyabundant,andconventionalLLMpost-trainingdata,whichisrelativelyeasytoannotate, agenticdataisinherentlyscarce. Research-levelproblemsaredifficulttoobtainthroughnaturaltexts fromtheweb. Manuallyannotatingtheseproblemsandagentictrajectoriesisextremelytime-consuming andcostly(Weietal.,2025). Buildingontheaforementionedagenttrainingpipeline,agenticmid-training requireslarge-scale,diversetrajectoriestoalignsubsequentagentbehaviors,whileagenticpost-training depends on high-quality, verifiable data to provide reliable reward signals. As a",
  "results": "results from google search\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"array\",\"items\": {\"type\": \"string\",\"description\": \"Thesearchquery.\"},\"minItems\": 1,\"description\": \"ThelistofsearchqueriesforGoogleScholar.\"}},\"required\": [\"query\"]}}}{\"type\": \"function\", \"function\": {\"name\": \"parse_file\", \"description\": \"This is a tool that can be used to parsemultipleuseruploadedlocalfilessuchasPDF,DOCX,PPTX,TXT,CSV,XLSX,DOC,ZIP, MP4,MP3.\",\"parameters\": {\"type\": \"object\",\"properties\": {\"files\": {\"type\": \"array\",\"items\": {\"type\": \"string\"},\"description\": \"Thefilenameoftheuseruploadedlocalfilestobeparsed.\"}},\"required\": [\"files\"]}}} </tools> For each function call, return a json object with function name and arguments within <tool_call></tool_call>XMLtags: <tool_call>{\"name\": <function-name>,\"arguments\": <args- json-object>}</tool_call> Currentdate: 21 --- Page 22 --- TheaboveconstitutesthesystempromptofourReActrollout. B Evaluation Details ForGAIAandWebWalkerQA,followingtheevaluationprotocolofLietal.(2025d),weadoptQwen2. 5-72B-Instruct as the judging model. The evaluation prompt is kept identical to that used in their worktoensureconsistencyandcomparability. Forxbench-DeepSearchandxbench-DeepSearch-2510,we adoptGemini-2.0-Flash-001asthejudgemodel. ForBrowseCompandBrowseComp-ZH,weemploy GPT-4o-2024-08-06 as the judge model. For Humanity\u2019s Last Exam, we evaluate the 2,154 text-only questions following Chai et al. (2025). The evaluation prompt follows the official protocol, with the o3-miniservingastheevaluator. Theevaluationpromptforthesebenchmarksiskeptconsistentwith thatdescribedintheoriginalpapertoensurealignmentandreproducibility. Theevaluationprompts usedforeachbenchmarkisprovidedindetailonourGitHubrepository5. Forgeneralbenchmarks,weadoptdifferentevaluationstrategiesbasedontasktype. Formathematical problems,sinceoursystemoutputsadetailedreportanddatasetssuchasAIME25andHMMT25are relativelysmallinscale,weemploymanualevaluationtoensureaccuracyandfairness. Forknowledge- based problems, we utilize the official evaluation script of SimpleQA to maintain consistency with establishedbenchmarks. C Post-training Synthetic Data Case Question: A military officer, who also served as governor in a western North American territory, commanded a mounted infantry unit during a period of significant mineral discovery in the region. His official report on the discovery prompted the minting of a special commemorative coin in a certain year in the mid-19th century. During that same year, the unit he commanded was involved in a military conflict against a neighboring country. Just over a decade later, this unit was officially redesignated and would be assigned to a new division in the early 1920s. In the 1930s, this redesignated regiment was involved in an organizational swap. Which other regiment was it exchanged for? Answer: 12th Cavalry Regiment Question: An 18th-century travelogue, later adapted for a radio series, describes a port town in southeastern England as notable for its rampant illicit trade. This town was also the home of a 16th-century gentleman whose murder led to his wife\u2019s execution. Centuries later, another resident of the same town was granted letters patent providing special commercial privileges in a particular year of the early 19th century. During that same year, a collector, whose large collection of manuscript poems was later auctioned, secured a patent for a method of grinding inks. In that year, a patent of nobility was issued to a German family; what is the German term for the princely status it conferred? Answer: F\u00fcrstenstand Question: In trisilylamine (N(SiH ) ), the Si-N bond length is 1.736 \u00c5. Substituting one silyl 3 3 group with methyl to form (CH )N(SiH ) elongates the Si-N bond to 1.752 \u00c5. Calculate the 3 3 2 percentage increase in bond length due to diminished hyperconjugation, and identify which specific orbital interaction weakens most significantly. Use covalent radii: Si=1.11 \u00c5, N=0.70 \u00c5, C=0.77 \u00c5. Answer: n \u2192 \u03c3\u2217 Si\u2212C Thefirsttwocasesabovearesyntheticallygeneratedhigh-quality,high-uncertainty,superhumanques- tion\u2013answerpairs,examplesofacaliberthatisexceptionallydifficulttoproduceviahumanannotation. ThethirdcaserepresentsaPhD-levelresearchquestion,demandingdeepdomainexpertise,multi-step reasoning. 5 22 --- Page 23 --- D Environment Details WeutilizefivetoolsforTongyiDeepResearch,namelySearch,Visit,PythonInterpreter,GoogleScholar, andFileParser6: \u2022 SearchleveragestheGooglesearchengineforinformationretrieval. Thetoolacceptsalistofoneor moresearchqueriestobeexecutedconcurrently. Foreachquery,itreturnsthetop-10rankedresults, witheachresultcomprisingatitle,adescriptivesnippet,anditscorrespondingURL. \u2022 Visitisdesignedfortargetedinformationextractionfromwebpages. Thetooltakesasinputaset ofwebpages, whereeachpageispairedwithadedicatedinformation-seekinggoal. Theprocess beginsbyemployingJina(Jina.ai,2025)toparsethefullcontentofagivenwebpage. Subsequently,a summarymodelprocessesthiscontenttoextractonlytheinformationpertinenttothatpage\u2019sspecific goal. \u2022 PythonInterpreterisusedtoexecutePythoncodewithinasandboxedenvironment. Theinputisa stringofPythoncode,whichmustbeenclosedwithin<code>tagsforproperexecution. Thetoolruns theprovidedcodeandcapturesitsstandardoutput;therefore,anyresultsorvaluesintendedtobe seenmustbeexplicitlypassedtotheprint()function. Thiscapabilityenablesdynamiccomputation, datamanipulation,andtheuseofvariousPythonlibrariesinasecureandisolatedmanner. \u2022 GoogleScholarisusedtoretrieveinformationfromacademicpublications. Theinputconsistsofa listofoneormoresearchqueries,allowingformultiple,distinctsearcheswithinasingletoolcall. The toolleveragestheGoogleScholarsearchenginetoexecuteeachqueryandgatherrelevantscholarly literature,suchasarticles,papers,andcitations. \u2022 FileParseranswersuserqueriesbyanalyzingamixofdocuments,webpages,andmultimediafiles (e.g.,PDF,DOCX,MP4)fromlocalorURLsources. Itworksintwosteps: first,itconvertsallinput intoplaintext,transcribingaudio/videocontentwhennecessary. Second,asummarymodelreads thisunifiedtexttogenerateadirectanswertotheuser\u2019squestion 6SinceoursystemreliesonseveralinternalAPIsandfallbackstrategies(asdescribedinSection3.4.3),weprovide alternativeopenimplementationsinouropen-sourceGitHubrepositorytofacilitatepublicuse.Wehaveverified throughextensivetestingthatthesesubstitutionscanfaithfullyreproduceourresults. 23",
  "experiments": "Experiments 4.1 Experimental Setup Backbones. WeevaluateTongyiDeepResearchonsevenpublicinformation-seekingbenchmarksspan- ning long-term reasoning and long-horizon tool use. The model is compared against two families of systems: 1) LLM-based ReAct agents: GLM-4.5 (Zeng et al., 2025), Kimi-K2 (Team et al., 2025), DeepSeek-V3.1(DeepSeekTeam,2025),Claude-4-Sonnet(anthropic,2025),OpenAIo3/o4-mini(Ope- nAI,2025b))and2)end-to-enddeep-researchagents: OpenAIDeepResearch(OpenAI,2025a),Gemini DeepResearch(GeminiTeam,2025),KimiResearcher(Kimi,2025). Benchmarks. We follow each benchmark\u2019s official evaluation protocol. The benchmarks cover: (1) Humanity\u2019sLastExam(Phanetal.,2025);(2)BrowseComp(Weietal.,2025)andBrowseComp-ZH(Zhou etal.,2025);(3)GAIA(Mialonetal.,2023);(4)xBench-DeepSearch(XbenchTeam,2025);(5)WebWalk- erQA(Wuetal.,2025b);(6)FRAMES(Krishnaetal.,2025);and(7)xbench-DeepSearch-2510. Allscoresarecomputedwiththeofficialscriptsreleasedbyeachbenchmark. Thedetailsofevaluation arepresentedinAppendixB. Evaluation. Weadoptfixedinferenceparameterstoensurestabilityandreproducibilityacrossevalua- tions: temperature=0.85,repetitionpenalty=1.1,andtop-p=0.95. Amaximumof128toolinvocations isallowedpertask,andthecontextlengthisconstrainedto128Ktokens. Eachbenchmarkisevaluated  Forcom-  analysis. AllresultsareobtainedonSeptember16,2025,exceptforxbench-DeepSearch-2510,whichis evaluatedonOctober28,2025. Reproduce. Tongyi DeepResearch operates utilizing an action space that includes the Search, Visit, Python,Scholar,andFileParsertools. WereleaseofficialreproductionscriptsonGitHub4,alongwiththe completetoolimplementationsandpromptconfigurations. 4.2 Main",
  "discussion": "Discussion 15 --- Page 16 --- 5.1 Limitations We acknowledge several limitations in our current work: First, the current 128K context length re- mainsinsufficientforhandlingthemostcomplexlong-horizontasks,motivatingfurtherexploration ofextendedcontextwindowsormoreadvancedcontextmanagementmechanisms(Qiaoetal.,2025; Wuetal.,2025c). Second,wehavenotyetreleasedalarger-scalemodel. Althoughthesmaller-sized modelalreadydemonstratesstrongperformance,alargermodeliscurrentlyinprogress. Third,weare continuouslyimprovingreportgenerationfidelityandoptimizingforuserpreferencestoensuremore faithful,useful,andpreference-alignedoutputs(Lietal.,2025e). Fourth,weaimtoimprovetheefficiency ofourreinforcementlearningframeworkbyexploringtechniquessuchaspartialrollouts,whichwill requireaddressingoff-policytrainingchallenges,includingdistributionalshift. Finally,ourcurrentDeep Researchtrainingfocusesonspecificpromptinstructionsandpredefinedtoolsets. Weplantoenhance itsrobustnessandextendtheframeworkfromDeepResearchtobroaderagentictoolusescenarios. 5.2 Model Scale Webelievethattrainingagenticcapabilitiesonrelativelysmallmodelsishighlyvaluable(Belcaketal., 2025). Smaller models are inherently more efficient to deploy on edge devices, broaden accessibility acrossdiversereal-worldscenarios,anddeliverfaster,moreresponsiveinteractions. Thisdirectionaligns withthebroadergoalofmakingautonomousresearchagentsbothpowerfulandpracticallydeployable. 5.3 What\u2019s Next Wehavealong-standingcommitmenttoadvancingresearchanddevelopmentindeepresearchagents. The Tongyi DeepResearch represents a significant step toward AI systems capable of autonomously transforminginformationintoinsight. Weadvocateforopen-sourcemodelswithemergentagency,which areessentialfordemocratizingagenticintelligenceanddeepeningourfundamentalunderstandingof howagencycanemergeandscaleinopensystems.Lookingahead,weaimtoevolvefromdomain-specific agentstogeneral-purposeagents,whicharecapableofreasoning,planning,andactingautonomously acrossdiversedomainswithminimalhumansupervision. Toachievethis,wearedevelopingthenext- generation agent foundation model, a unified model designed to endow AI systems with scalable reasoning,memory,andautonomy,enablingthemtooperateastrulygeneralagents. Webelieveitwill empowerindividualsandorganizationstoreachnewheightsofproductivityandinnovation. 6",
  "conclusion": "Conclusion We introduced Tongyi DeepResearch, an open-source deep research agent that unifies agentic mid- training and post-training into a scalable, end-to-end paradigm. Through automated data synthesis andstage-specificenvironments,themodellearnstoplan,search,reason,andsynthesizeinformation autonomously. Despiteitsefficiency,activatingonly3.3Bparameters,TongyiDeepResearchachieves state-of-the-artresultsonmultipledeepresearchbenchmarks,surpassingstrongproprietarysystems. Thisworkestablishesafoundationforopen,reproducibleresearchintoautonomousAIagentsandmarks asteptowardmoregeneral,self-improvingintelligence. 16 --- Page 17 --- Contributions Thenamesarelistedinalphabeticalorderbyfirstname. ProjectLeader YongJiang CoreContributors BaixuanLi,BoZhang,DingchuZhang,FeiHuang,GuangyuLi,GuoxinChen,HuifengYin,JialongWu, JingrenZhou,KuanLi,LiangcaiSu,LituOu,LiwenZhang,PengjunXie,RuiYe,WenbiaoYin,Xinmiao Yu,XinyuWang,XixiWu,XuanzhongChen,YidaZhao,ZhenZhang,ZhengweiTao,ZhongwangZhang, ZileQiao Contributors ChenxiWang,DongleiYu,GangFu,HaiyangShen,JiayinYang,JunLin,JunkaiZhang,KuiZeng,Li Yang,HailongYin,MaojiaSong,MingYan,PengXia,QianXiao,RuiMin,RuixueDing,RunnanFang, ShaoweiChen,ShenHuang,ShihangWang,ShihaoCai,WeizhouShen,XiaobinWang,XinGuan,Xinyu Geng,YingchengShi,YuningWu,ZhuoChen,ZijianLi 17 --- Page 18 ---",
  "references": "References anthropic. Introducingclaude4,2025. URL PeterBelcak,GregHeinrich,ShizheDiao,YongganFu,XinDong,SauravMuralidharan,YingyanCe- line Lin, and Pavlo Molchanov. Small language models are the future of agentic ai. arXiv preprint arXiv:2506.02153,2025. JingyiChai,ShuoTang,RuiYe,YuwenDu,XinyuZhu,MengchengZhou,YanfengWang,YuzhiZhang, LinfengZhang, SihengChen, etal. Scimaster: Towardsgeneral-purposescientificaiagents, parti. x-masterasfoundation: Canweleadonhumanity\u2019slastexam? arXivpreprintarXiv:2507.05241,2025. KevinChen,MarcoCusumano-Towner,BrodyHuval,AlekseiPetrenko,JacksonHamburger,Vladlen Koltun,andPhilippKr\u00e4henb\u00fchl. Reinforcementlearningforlong-horizoninteractivellmagents. arXiv preprintarXiv:2502.01600,2025. ClaudeTeam. Clauderesearch,2025. URL DeepSeek Team. Introducing deepseek-v3.1: our first step toward the agent era!, 2025. URL https: //api-docs.deepseek.com/news/news250821. RunnanFang,ShihaoCai,BaixuanLi,JialongWu,GuangyuLi,WenbiaoYin,XinyuWang,XiaobinWang, LiangcaiSu,ZhenZhang,etal. Towardsgeneralagenticintelligenceviaenvironmentscaling. arXiv preprintarXiv:2509.13311,2025. GeminiTeam. Geminideepresearch,2025. URL GrokTeam. Grok-3deepersearch,2025. URL DayaGuo,DejianYang,HaoweiZhang,JunxiaoSong,RuoyuZhang,RunxinXu,QihaoZhu,ShirongMa, PeiyiWang,XiaoBi,etal. DeepSeek-R1: IncentivizingreasoningcapabilityinLLMsviareinforcement learning. arXivpreprintarXiv:2501.12948,2025. Jina.ai. Jina,2025. URL Kimi. Kimi-researcher: End-to-endrltrainingforemergingagentic,2025. URL ithub.io/Kimi-Researcher/. SatyapriyaKrishna, KalpeshKrishna, AnhadMohananey, StevenSchwarcz, AdamStambler, Shyam Upadhyay,andManaalFaruqui. Fact,fetch,andreason: Aunifiedevaluationofretrieval-augmented generation. InProceedingsofthe2025ConferenceoftheNationsoftheAmericasChapteroftheAssociationfor ComputationalLinguistics: HumanLanguageTechnologies(Volume1: LongPapers),pp.4745\u20134759,2025. KuanLi, LiwenZhang, YongJiang, PengjunXie, FeiHuang, ShuaiWang, andMinhaoCheng. Lara: Benchmarking retrieval-augmented generation and long-context llms\u2013no silver bullet for lc or rag routing. arXivpreprintarXiv:2502.09977,2025a. KuanLi,ZhongwangZhang,HuifengYin,RuiYe,YidaZhao,LiwenZhang,LituOu,DingchuZhang, XixiWu,JialongWu,etal. Websailor-v2: Bridgingthechasmtoproprietaryagentsviasyntheticdata andscalablereinforcementlearning. arXivpreprintarXiv:2509.13305,2025b. KuanLi,ZhongwangZhang,HuifengYin,LiwenZhang,LituOu,JialongWu,WenbiaoYin,BaixuanLi, ZhengweiTao,XinyuWang,etal. Websailor: Navigatingsuper-humanreasoningforwebagent. arXiv preprintarXiv:2507.02592,2025c. Xiaoxi Li, Jiajie Jin, Guanting Dong, Hongjin Qian, Yutao Zhu, Yongkang Wu, Ji-Rong Wen, and Zhicheng Dou. Webthinker: Empowering large reasoning models with deep research capability. CoRR,abs/2504.21776,2025d. doi: 10.48550/ARXIV.2504.21776. URL rXiv.2504.21776. 18 --- Page 19 --- Zijian Li, Xin Guan, Bo Zhang, Shen Huang, Houquan Zhou, Shaopeng Lai, Ming Yan, Yong Jiang, PengjunXie,FeiHuang,etal. Webweaver: Structuringweb-scaleevidencewithdynamicoutlinesfor open-endeddeepresearch. arXivpreprintarXiv:2509.13312,2025e. Gr\u00e9goire Mialon, Cl\u00e9mentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a benchmarkforgeneralaiassistants. InTheTwelfthInternationalConferenceonLearningRepresentations, 2023. OpenAI. Deepresearchsystemcard,2025a. URL ard.pdf. OpenAI. Introducingopenaio3ando4-mini,2025b. URL 3-and-o4-mini/. OpenAI. Introducingsimpleqa,2025c. URL LongPhan,AliceGatti,ZiwenHan,NathanielLi,JosephinaHu,HughZhang,ChenBoCalvinZhang, MohamedShaaban,JohnLing,SeanShi,etal. Humanity\u2019slastexam. arXivpreprintarXiv:2501.14249, 2025. ZileQiao,GuoxinChen,XuanzhongChen,DongleiYu,WenbiaoYin,XinyuWang,ZhenZhang,Baixuan Li, Huifeng Yin, Kuan Li, et al. Webresearcher: Unleashing unbounded reasoning capability in long-horizonagents. arXivpreprintarXiv:2509.13309,2025. ZhihongShao,PeiyiWang,QihaoZhu,RunxinXu,JunxiaoSong,XiaoBi,HaoweiZhang,Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open languagemodels. arXivpreprintarXiv:2402.03300,2024. DavidSilverandRichardSSutton. Welcometotheeraofexperience. GoogleAI,1,2025. LiangcaiSu,ZhenZhang,GuangyuLi,ZhuoChen,ChenxiWang,MaojiaSong,XinyuWang,KuanLi, JialongWu,XuanzhongChen,ZileQiao,ZhongwangZhang,HuifengYin,ShihaoCai,RunnanFang, ZhengweiTao,WenbiaoYin,etal. Scalingagentsviacontinualpre-training,2025. RichardSutton. Thebitterlesson. IncompleteIdeas(blog),13(1):38,2019. SijunTan,MichaelLuo,ColinCai,TarunVenkat,KyleMontgomery,AaronHao,TianhaoWu,Arnav Balyan,MananRoongta,ChenguangWang,LiErranLi,RalucaAdaPopa,andIonStoica. rllm: A frameworkforpost-traininglanguageagents.  -Framework-for-Post-Training-Language-Agents-21b81902c146819db63cd98a54ba5f31, 2025. NotionBlog. ZhengweiTao,JialongWu,WenbiaoYin,JunkaiZhang,BaixuanLi,HaiyangShen,KuanLi,LiwenZhang, XinyuWang,YongJiang,etal. Webshaper: Agenticallydatasynthesizingviainformation-seeking formalization. arXivpreprintarXiv:2507.15061,2025. KimiTeam,YifanBai,YipingBao,GuanduoChen,JiahaoChen,NingxinChen,RuijueChen,YanruChen, YuankunChen,YutianChen,etal. Kimik2: Openagenticintelligence. arXivpreprintarXiv:2507.20534, 2025. HaomingWang,HaoyangZou,HuatongSong,JiazhanFeng,JunjieFang,JuntingLu,LongxiangLiu, QinyuLuo,ShihaoLiang,ShijueHuang,etal. Ui-tars-2technicalreport: Advancingguiagentwith multi-turnreinforcementlearning. arXivpreprintarXiv:2509.02544,2025. JasonWei,ZhiqingSun,SpencerPapay,ScottMcKinney,JeffreyHan,IsaFulford,HyungWonChung, Alex Tachard Passos, William Fedus, and Amelia Glaese. Browsecomp: A simple yet challenging benchmarkforbrowsingagents. arXivpreprintarXiv:2504.12516,2025. 19 --- Page 20 --- JialongWu,BaixuanLi,RunnanFang,WenbiaoYin,LiwenZhang,ZhengweiTao,DingchuZhang,Zekun Xi,YongJiang,PengjunXie,etal. Webdancer: Towardsautonomousinformationseekingagency. arXiv preprintarXiv:2505.22648,2025a. JialongWu,WenbiaoYin,YongJiang,ZhenglinWang,ZekunXi,RunnanFang,LinhaiZhang,Yulan He,DeyuZhou,PengjunXie,etal. Webwalker: Benchmarkingllmsinwebtraversal. arXivpreprint arXiv:2501.07572,2025b. Xixi Wu, Kuan Li, Yida Zhao, Liwen Zhang, Litu Ou, Huifeng Yin, Zhongwang Zhang, Yong Jiang, PengjunXie,FeiHuang,etal. Resum: Unlockinglong-horizonsearchintelligenceviacontextsumma- rization. arXivpreprintarXiv:2509.13313,2025c. XbenchTeam. Xbench-deepsearch,2025. URL AnYang,AnfengLi,BaosongYang,BeichenZhang,BinyuanHui,BoZheng,BowenYu,ChangGao, ChengenHuang,ChenxuLv,etal. Qwen3technicalreport. arXivpreprintarXiv:2505.09388,2025. ShunyuYao,JeffreyZhao,DianYu,NanDu,IzhakShafran,KarthikNarasimhan,andYuanCao. Re- act: Synergizing reasoning and acting in language models. In International Conference on Learning Representations(ICLR),2023. QiyingYu,ZhengZhang,RuofeiZhu,YufengYuan,XiaochenZuo,YuYue,TiantianFan,GaohongLiu, LingjunLiu,XinLiu,etal. Dapo: Anopen-sourcellmreinforcementlearningsystematscale. arXiv preprintarXiv:2503.14476,2025. AohanZeng,XinLv,QinkaiZheng,ZhenyuHou,BinChen,ChengxingXie,CunxiangWang,DaYin, HaoZeng,JiajieZhang,etal. Glm-4.5: Agentic,reasoning,andcoding(arc)foundationmodels. arXiv preprintarXiv:2508.06471,2025. PeilinZhou,BruceLeon,XiangYing,CanZhang,YifanShao,QichenYe,DadingChong,ZhilingJin, ChenxuanXie,MengCao,etal.Browsecomp-zh:Benchmarkingwebbrowsingabilityoflargelanguage modelsinchinese. arXivpreprintarXiv:2504.19314,2025. 20 --- Page 21 --- A Rollout Details SystemPrompt You are a deep research assistant. Your core function is to conduct thorough, multi-source investigationsintoanytopic. Youmusthandlebothbroad,open-domaininquiriesandqueries within specialized academic fields. For every request, synthesize information from credible, diversesourcestodeliveracomprehensive,accurate,andobjectiveresponse. Whenyouhave gatheredsufficientinformationandarereadytoprovidethedefinitiveresponse,youmustenclose theentirefinalanswerwithin<answer></answer>tags. #Tools Youmaycalloneormorefunctionstoassistwiththeuserquery. Youareprovidedwithfunctionsignatureswithin<tools></tools>XMLtags: <tools> {\"type\": \"function\",\"function\": {\"name\": \"search\",\"description\": \"PerformGooglewebsearches thenreturnsastringofthetopsearchresults. Acceptsmultiplequeries.\",\"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"array\", \"items\": {\"type\": \"string\", \"description\": \"The searchquery.\"},\"minItems\": 1,\"description\": \"Thelistofsearchqueries.\"}},\"required\": [\"query\"]}}} {\"type\": \"function\",\"function\": {\"name\": \"visit\",\"description\": \"Visitwebpage(s)andreturnthe summaryofthecontent.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"url\": {\"type\": \"array\", \"items\": {\"type\": \"string\"},\"description\": \"TheURL(s)ofthewebpage(s)tovisit. Canbeasingle URLoranarrayofURLs.\"},\"goal\": {\"type\": \"string\",\"description\": \"Thespecificinformationgoal forvisitingwebpage(s).\"}},\"required\": [\"url\",\"goal\"]}}} {\"type\": \"function\", \"function\": {\"name\": \"PythonInterpreter\", \"description\": \"Executes Python codeinasandboxedenvironment. Tousethistool,youmustfollowthisformat: 1. The\u2019arguments\u2019JSONobjectmustbeempty: {}. 2. ThePythoncodetobeexecutedmustbeplacedimmediatelyaftertheJSONblock,enclosed within<code>and</code>tags. IMPORTANT: Any output you want to see MUST be printed to standard output using theprint()function. Exampleofacorrectcall: <tool_call>{\"name\": \"PythonInterpreter\",\"arguments\": {}} <code>importnumpyasnp#Yourcodehereprint(f\"Theresultis: np.mean([1,2,3])\")</code> </tool_call>\",\"parameters\": {\"type\": \"object\",\"properties\": {},\"required\": []}}} {\"type\": \"function\",\"function\": {\"name\": \"google_scholar\",\"description\": \"LeverageGoogleScholar to retrieve relevant information from academic publications. Accepts multiple queries. This tool will also return"
}