{
  "abstract": "ABSTRACT Large language models (LLMs) have gained significant traction in medical decision support systems, particularly in the contextofmedicalquestionansweringandrole-playingsimulations. Acommonpractice,Prompt-BasedRolePlaying(PBRP), instructsmodelstoadoptdifferentclinicalroles(e.g.,medicalstudents,residents,attendingphysicians)tosimulatevaried professionalbehaviors. However, theimpactofsuchrolepromptsonmodelreasoningcapabilitiesremainsunclear. This studyintroducestheRP-Neuron-ActivatedEvaluationFramework(RPNA)toevaluatewhetherrolepromptsinducedistinct, role-specific cognitive processes in LLMs or merely modify linguistic style. We test this framework on three medical QA datasets,employingneuronablationandrepresentationanalysistechniquestoassesschangesinreasoningpathways. Our resultsdemonstratethatrolepromptsdonotsignificantlyenhancethemedicalreasoningabilitiesofLLMs. Instead, they primarilyaffectsurface-levellinguisticfeatures,withnoevidenceofdistinctreasoningpathwaysorcognitivedifferentiation acrossclinicalroles. Despitesuperficialstylisticchanges,thecoredecision-makingmechanismsofLLMsremainuniform across roles, indicating that current PBRP",
  "methods": "Methods 1.1 DatasetSelection Tocomprehensivelyassessthecognitivemodelingcapabilitiesoflargelanguagemodels(LLMs)inmedicalrole-playing,we selectedthreerepresentativeandcomplementarymedicalquestion-answeringdatasets,coveringbasicknowledge,clinical reasoning,andinterdisciplinaryscenarios. Thisselectionensuresabalancedassessmentoftasksintermsofhierarchyand cognitivecomplexity,ascategorizedusingBloom\u2019sTaxonomy(AsshowninFigure3.B).Thedatasetsspanarangeofcognitive levels,fromfundamentalrecall-basedtaskstomorecomplexclinicalreasoningandinterdisciplinaryintegration(Asshownin Figure3.A). \u2022 MedQA25:ThisdatasetisderivedfromexaminationpapersofthemedicalboardsintheUnitedStates,mainlandChina, andTaiwan. Itisdesignedtoassessdoctors\u2019professionalknowledgeandclinicaldecision-makingabilities. Thedataset containsnumerousreal-worldclinicalquestionsacrossfieldssuchasinternalmedicine,surgery,pediatrics,gynecology, andradiology. Thequestiondesignemphasizesmulti-stepreasoningandknowledgeintegration,makingitcrucialfor evaluating the model\u2019s higher-order reasoning capabilities. From MedQA, we selected the USMLE sub-dataset for testing,containing1,273multiple-choicequestionsinthetestset. AsshowninFigure3,themajorityofthequestionsin MedQAarecategorizedunder\"Remembering\"and\"Understanding\"inBloom\u2019sTaxonomy,withasmallerproportion requiringhighercognitivelevelssuchas\"Evaluating\"and\"Creating\". \u2022 MedMCQA26:DerivedfromtheIndianNEETandAIIMSmedicalexamquestionbanks,thisdatasetfocusesonbasic medicalcoursessuchasanatomy,physiology,andbiochemistry. Thequestionsarestructuredinaclear,standardformat, makingitsuitablefortestingthemodel\u2019sabilitytounderstandmedicalterminologyandtextbook-levelknowledge. We usedthetestsetofthisdataset,whichcontains4,183multiple-choicequestions. AsdepictedinFigure3,MedMCQA questionspredominantlyfallunder\"Remembering\"and\"Understanding\",withonlyafewquestionsinthe\"Applying\" and\"Analyzing\"categories,reflectingthefocusonfoundationalknowledge. \u2022 MMLU-Med27:Focusedoninterdisciplinaryknowledgeintegration,MMLU-Medtestsmodelsoncommon-sensefusion and conceptual reasoning abilities. We selected the medical-related sub-datasets from MMLU, covering topics like anatomy,clinicalknowledge,professionalmedicine,medicalgenetics,collegemedicine,andcollegebiology,totaling 1,083multiple-choicequestions. Thesesub-datasetsincludeawiderangeofcognitivelevels,withasignificantproportion ofquestionsinthehigher-ordercategoriesof\"Analyzing\",\"Evaluating\",and\"Creating\",asshowninFigure3,aligning withtheneedformorecomplexreasoningininterdisciplinarymedicalcontexts. 3/15 --- Page 4 --- Figure3. Taskclassificationofthreemedicalquestion-answeringdatasets(basedonGPT-4o). FigureAshowsthe classificationresultsbasedonBloom\u2019staxonomy,andFigureBshowsthesixlevelsofBloom\u2019staxonomyfromhightolow. MedQA and MMLU-Med use the standard four-option multiple-choice question format, while MedMCQA utilizes a five-optionformat. Weselectedthetestsetportionfromeachdatasettoensuretheperformanceresultsareasaccurateand consistentaspossible. ThedistributionofquestionsacrossdifferentlevelsofBloom\u2019sTaxonomyensuresthatthedatasets provideacomprehensivechallengeforassessingLLMs\u2019cognitivereasoninginmedicalcontexts. 1.2 PromptConfiguration TosystematicallyevaluatetheimpactofdifferentdoctorrolesettingsonthebehaviorandinternalrepresentationsofLLMs, as shown in Figure2, we constructed a prompt set containing multiple role contexts, divided into three major categories: Role-PlayingGroup,BaselineGroup,andControlGroup. TheQAexampleofusingtheroleplayingpromptcanbeseeninthe coderepository. Role-PlayingGroup(Role-PlayingPrompts) Role-playingpromptssimulatethedifferencesinknowledge,experience,and decision-makingstylesacrossmedicalprofessionals. Thesepromptsaredesignedtotestifthemodelcanreflectrole-specific reasoning.Wecreatedtenrepresentativedoctorrolesbasedonmedicaleducationandclinicalroledivisionstandards,generating thepromptsusingGPT4o(Figure2.A).Thepromptsinclude\u201c[Background/BehavioralGuidance+RoleName]+Please answerthequestion,\u201dguidingthemodeltoanswerasaspecificrole. Figure2.Bshowshowtherolepromptiscombinedwith theclinicalQ&Ataskandoutputconstraintstoguidethemodel\u2019sreasoning. BaselineGroup(BaselinePrompts) Toestablishabaseline,weusedaunifiedprompt: \u201cPleaseprovidethemostappropriate answertothefollowingmedicalquestion.\u201dThispromptlacksrole-specificinformation,allowingthemodeltorespondbased onitsdefaultknowledge. ControlGroup(RandomPrompts) Totestthemodel\u2019ssensitivitytomedicalcontexts,weincludedrandom,non-medical prompts(e.g.,\u201cThisisasentence.\u201d). Thesepromptsarenotrelatedtothetaskandareexpectedtohavenoimpactonthe model\u2019sanswers,servingasameasureofthemodel\u2019srobustnessandtheselectivityoftheinductionmechanism. 1.3 ModelSelectionandSetup Tosystematicallyevaluatetheresponsebehaviorandinternalmechanismchangesoflargelanguagemodels(LLMs)under differentpromptsettingsinmedicaltasks,weselectedtheQwenseriesofLLMsasthebackboneforourexperiments,covering variousparameterscales. Specifically,wedeployedfourversionsofinstruction-tunedmodelslocally: Qwen2.5-7B-Instruct, Qwen2.5-14B-Instruct,Qwen2.5-32B-Instruct,andQwen2.5-72B-Instruct,representingtheperformanceboundariesofmedium, large,andextra-largemodelswithinthecurrentopenarchitecture. Additionally,weselectedGPT-4o9andDeepseek-R128,two closed-sourcemodelsbasedonreasoning-centricarchitecturesthathaveachievedstate-of-the-art(SOTA)resultsinmultiple evaluationlists. Thesemodelswereusedtofurtherexploretheimpactofdifferentmodelarchitecturesonrole-playingreasoning paths. ThebasemodelsusedinthisstudyaretheQwenseriesofLLMs(Qwen2.5-7B/14B/32B/72B-Instruct), developedby AlibabaDAMOAcademy. Qwen29,asoneoftheleadingChineseopen-sourcemodelswiththehighestglobaldownloadrate, hassubstantialinternationalinfluenceontheHuggingFaceplatformandiswidelyusedbybothdomesticandinternational researchteamsinmedicalquestionansweringsystems,virtualdoctorassistants,andotherscenarios30\u201332. Ithasbecomea corefoundationalmodelinthemedicalLLMecosystem. TheQwenseriesisknownforitsstrongmulti-turnconversation capabilities,instruction-followingability,andperformanceincomplexcontextualunderstandingandreasoninginmedical scenarios33,makingitasuitableresearchplatformforrole-playingtasks. 4/15 --- Page 5 --- Figure4. Themethodsofneuronsselectionandablation. ItshowstheCharacterNeuronlayerselectionMethod(Step1), NeuronablationMethod(Step2)andBaselineAblationMethod(baselinemethod). GPT-4o9, aclosed-sourcemultimodalmodeldevelopedbyOpenAI,integratesvision, audio, andtextwithinaunified architecture. Althoughonlyitstextcapabilitieswereevaluatedinthisstudy,itsadvancedalignmenttechniquesandefficient memorymanagementcontributetoitsstronginstruction-followingperformance,makingitareliablebenchmarkforcommercial models. Deepseek-R128, built on a reasoning-centric architecture with Mixture-of-Experts (MoE), is optimized for retrieval- augmentedgenerationandlong-contextprocessing. ItshybriddesignreflectsthelatesttrendsinscalableLLMs,focusingon high-efficiencyreasoningtasks. To ensure the reproducibility of the",
  "introduction": "1 Introduction Driven by the rapid advancement of large language models(LLMs)1\u20134, LLMs are increasingly used for medical question answeringandclinicaldecisionsupport5\u20138. MainstreamarchitecturesincludeautoregressivegeneratorssuchastheGPTseries9 andencoder\u2013decodermodelssuchastheT5family10,11. ThesemodelsperformwellonmedicalQA12,casesummarization13, andpatient-facingdialogue14. AprevalentpracticeintheseapplicationsisPrompt-BasedRolePlaying(PBRP)15,16,which instructsamodeltorespond\u201cas\u201daparticularclinician(e.g.,intern,resident,attending,orspecialist)withthegoalofincreasing realism and credibility of generated outputs. Building on PBRP, recent systems adopt multi-agent designs where prompt- conditionedagentscoordinateviatooluseanddeliberationtoimprovedecisions17,18. Despitetheirappeal,thevalidityof theseagentconfigurations(roleprompts,divisionoflabor,andinteractionprotocols)andtheiractualcontributiontoreasoning qualityremaininsufficientlytested. WeintroducetheRP-Neuron-ActivatedEvaluationFramework(RPNA)totestwhetherrole promptsinducecomplementary,role-specificcomputationormerelystylisticmodulation. Inclinicalmedicine,rolestratificationismorethananallocationofauthorityorlabor;itencodesgradedexpertisewith heterogeneouscognitivemechanisms,reasoningstrategies,andknowledgestructuresacrosslevels19,20. Fromnoviceinternsto frontlineattendingsandseniorspecialists,cliniciansdeploydifferentdiagnosticheuristics,evidence-integrationroutines,and risk-calibrationpolicieswhenfacingthesamecase. Empiricalworkincognitivepsychologyandstatisticaldecisiontheory hasdocumentedsystematicdifferencesinneuralactivationandinformation-processingpoliciesacrossexpertiselevelsduring historytaking,symptominterpretation,andtheconstructionofdiagnostic\u2013therapeuticpathways21\u201324. Thisstratifiedcognition underpinsmedicaleducation\u2019sroleprogressionandenablesmulti-level,collaborativedecisionmakinginpractice. Therefore,if LLMs\u201cplay\u201dclinicalroles,atestableexpectationisrole-dependentdifferencesinlatentcomputationandbehavior,beyond 5202 tcO 82 ]LC.sc[ 1v77642.0152:viXra --- Page 2 --- Figure1. OverviewoftheRPNAevaluationframework. surfacestyle. Acentral,under-testedquestioniswhetherprompt-basedroleplayingactuallyinducesrole-specificreasoninginLLMsor merelyproducesstylisticshiftswhileleavinglatentcomputationslargelyunchanged. WeaddressthiswiththeRP-Neuron- ActivatedEvaluationFramework(RPNA)(AsshowninFigure1). Weidentifyrole-salientunitsusinganactivation/gradient- basedsaliencescoreundereachroleprompt,thenablatethetop-r%unitsinthetop-Klayersduringinference. Ifroleprompts instantiate distinct circuits, within-role masking should degrade performance more than cross-role masking; symmetry or uniformlysmalldropsarguesagainstrole-specificpathways. Aroundthisprobe,RPRFbenchmarkspre/post-promptaccuracy, assessesrepresentationstructure(CKA/PCAandclustering),andprofileslayer-wisedivergenceviaJSDacrossdepth. WeapplyRPNAon3medicalQAdatasetson3kindsofopen-sourceLLMswithdifferentmodelsize. Todisentanglestyle fromcomputation,wefixdecoding,computepairedaccuracydeltaswith95%confidenceintervals,andsweepmaskingratios. RPRFthenasksfourtestablequestions: Dorolepromptsyieldconsistentaccuracygains? Doroleeffectspersistindeeplayers ratherthanfadingwithdepth? Doroleconditionsformseparableclustersinrepresentationspace(CKA/PCAandclustering)? andiswithin-roleneuronmaskingmoredamagingthancross-rolemasking? Failureontheseindicatesthatrolepromptsmainly coordinatelanguagestyleratherthanreconfigurereasoning. Ourfindingsindicatethatrolepromptsdonotinducesignificantchangesinlatentreasoningpathwaysacrossclinicalroles, andanyobservedaccuracyimprovementsareunstable. Neuronmaskingforaspecificroleresultsinperformancedegradation comparabletothatobservedforotherroles,andcross-rolemaskingproduceseffectssimilartowithin-rolemasking,providing noevidencefortheexistenceofrole-specificcircuits. Theseresultssuggestsubstantialhomogeneityinlatentcomputation acrossclinicalrolesunderPBRP,withpromptsprimarilyinfluencingsurfacelanguageratherthaninducingdistinctreasoning pathways. Activationdifferencesareconcentratedinearlytomiddlelayersandattenuatewithdepth;highCKAvaluesand overlappingPCAclustersindicateconvergentdeeprepresentations. Collectively,thesefindingshighlightthatroleplaying in PBRP mainly tunes linguistic style rather than contributing to genuine improvements in reasoning. Consequently, the Role-PromptedNeuron-ActivatedEvaluationFramework(RPNA)providesaclearandpracticalfoundationforassessingwhen role-playingagentpipelinesarelikelytodelivertrueadvancementsinclinicaldecisionsupport,asopposedtomerelyenhancing stylisticrealism. AsshowninthepipelineinFigure1,steps1to5outlinetheworkflowoftheRPNAframework. InStep1,PBRPintegrates LLMswithspecificbehavioralguidelinesandcareerbackgroundstosimulatereasoningprocessesacrossclinicalroles. Step2 evaluatesthemodel\u2019sperformancethroughmultiple-choiceQAtests,posingquestionsandreasoningoverdifferentoptions. InStep3,alightweight,model-agnosticneuron-maskingablationmethodisappliedtoidentifyrole-salientneuralunitsand comparetheeffectsofwithin-roleversuscross-rolemasking,revealingnoevidenceofrole-specificcircuits. Thissuggeststhat 2/15 --- Page 3 --- Figure2. Thefigureshowstheoverallprocessofconstructingrole-playingprompts(RolePrompts)intheQ&Atask.FigureA showsthestepofcreatingastandardpromptforaMedicalStudent,FigureBsimulatesthereasoningbehaviorofrealmedical professionalsunderdifferentknowledgebackgroundsandthinkingstyles. rolepromptsmainlytunelinguisticstyleratherthanalterreasoningpaths. InStep4,representationstructuresareexamined usingCKA/PCAanalysisandclustering,revealingconvergentdeeprepresentationsacrossrolesratherthanformingseparable, hierarchy-alignedgroups. Finally,Step5profilesdepth-wisedivergenceusinglayer-wiseJensen-ShannonDivergence(JSD), showing that any role effects are concentrated in early to middle layers and attenuate with depth. These",
  "results": "results reveal that while role-playing prompts significantly alter the language style of the models, they do not induce meaningful differences in the cognitive reasoning pathways expected from different medical professionals. Specifically,despiterole-playingpromptssimulatingvariousdoctorroles,suchasmedicalstudent,resident, andattendingphysician,themodel\u2019sunderlyingdecision-makingprocessesremainedstrikinglysimilaracrossallroles. This findingchallengesthecommonassumptionthat\"languageequalscognition,\"particularlyinthecontextofmedicalAI,where thecognitivedifferencesbetweenmedicalprofessionalsarecrucialforaccuratediagnosisandtreatment. 11/15 --- Page 12 --- Figure9. ExperimentresultsofvisualizingtheJSdivergenceofdifferentkindsofRPLLMs,figureA-CshowtheJSD betweendifferentlayers Acentralquestiondrivingthisresearchwaswhetherrole-playingcouldinducerole-specificreasoningpathwaysinLLMs, analogoustothecognitivestrategiesusedbyhumandoctorsofdifferentexpertiselevels. However,ourfindingsindicatethat role-playingprimarilyimpactsthemodel\u2019ssurface-levellanguageoutput,withouttriggeringtheactivationofdistinctreasoning circuits. This is evident from our",
  "experiments": "experiments,includingtherolepromptconstruction,accuracyevaluation,andneuralrepresentationanalyses. W.Z.andL.Z. implementedtheneuronablationframeworkandconductedtherole-specificmaskingexperiments. Y.C.curatedandprocessed themedicalQAdatasetsandcontributedtothedesignofthecognitivestratificationassessment. F.X.,H.L.,X.L.,H.W.,and W.Z.jointlyanalyzedtheresultsanddraftedthemanuscript. Z.L.andY.C.providedcriticalfeedbackontheexperimental methodologyandclinicalimplications. Allauthorscontributedtotherevisionofthemanuscriptandapprovedthefinalversion. Competing interests Theauthorsdeclarenocompetinginterests. 15/15",
  "discussion": "Discussion This study systematically evaluated the impact of role-playing prompts on the reasoning capabilities of LLMs in medical question answering tasks. Our",
  "conclusion": "Conclusion Thisstudysystematicallyevaluatedtheimpactofrole-playingpromptsonthereasoningcapabilitiesoflargelanguagemodels inmedicalquestionansweringtasks. Theresultsrevealthat,whilerole-playingpromptscansignificantlyalterthemodel\u2019s languagestyle,theydonotinducereasoningpathwaysthatcorrespondtotheprofessionalrolesofdoctors. Despitetesting acrossmultipledatasets,role-playingfailedtoimprovethemodel\u2019saccuracy,particularlyinhigh-complexitytasks. Instead,the effectofrole-playingwaslimitedtosuperficiallanguagechanges,withnoactivationofnewknowledgestructuresorreasoning strategies. Furthermore,neuronablationandhierarchicalmodelingtestsdemonstratedthatthereasoningpathwaysacross differentdoctorroleswerenearlyidentical,indicatingalackofrole-specificcognitivedifferentiation. Thesefindingshighlight thelimitationsofcurrentrole-playingmethodsinclinicalAI,astheyprimarilyalterlanguagebehaviorratherthanenabling modelstoreplicatethecognitiveprocessesofrealdoctors. Consequently,relyingonlanguage-basedrole-playingaloneis insufficientforbuildingreliablecognitiveagentsinmedicalapplications,signalingtheneedforashifttowardsmoreadvanced cognitivemodelinginthedevelopmentofmedicalAIsystems.",
  "references": "References 1. Dillion,D.,Mondal,D.,Tandon,N.&Gray,K. Ailanguagemodelrivalsexpertethicistinperceivedmoralexpertise. Sci. Reports15,4084(2025). 2. Lo,J.-H.,Huang,H.-P.&Lo,J.-S. Llm-basedrobotpersonalitysimulationandcognitivesystem. Sci.Reports15,16993 (2025). 3. Massenon, R., Gambo, I., Khan, J. A., Agbonkhese, C. & Alwadain, A. \u201d my ai is lying to me\u201d: User-reported llm hallucinationsinaimobileappsreviews. Sci.Reports15,30397(2025). 4. Jiao, J. et al. Llm ethics benchmark: a three-dimensional assessment system for evaluating moral reasoning in large languagemodels. Sci.Reports15,34642(2025). 5. Clusmann,J.etal. Thefuturelandscapeoflargelanguagemodelsinmedicine. Commun.medicine3,141(2023). 6. Safranek, C. W., Sidamon-Eristoff, A. E., Gilson, A. & Chartash, D. The role of large language models in medical education: applicationsandimplications(2023). 7. Huang,J.etal. Acriticalassessmentofusingchatgptforextractingstructureddatafromclinicalnotes. npjDigit.Medicine 7,106(2024). 8. Wu,L.etal. Asurveyonlargelanguagemodelsforrecommendation. WorldWideWeb27,60(2024). 9. Waisberg,E.etal. Gpt-4: aneweraofartificialintelligenceinmedicine. Ir.J.Med.Sci.(1971-)192,3197\u20133200(2023). 10. Lehman,E.&Johnson,A. Clinical-t5: Largelanguagemodelsbuiltusingmimicclinicaltext. PhysioNet(2023). 11. Vaswani,A.etal. Attentionisallyouneed. Adv.neuralinformationprocessingsystems30(2017). 12. Health,T.L.D. Largelanguagemodels: anewchapterindigitalhealth(2024). 13. VanVeen,D.etal. Adaptedlargelanguagemodelscanoutperformmedicalexpertsinclinicaltextsummarization. Nat. medicine30,1134\u20131142(2024). 14. Johri,S.etal. Anevaluationframeworkforclinicaluseoflargelanguagemodelsinpatientinteractiontasks. Nat.Medicine 1\u201310(2025). 15. Shanahan,M.,McDonell,K.&Reynolds,L. Roleplaywithlargelanguagemodels. Nature623,493\u2013498(2023). 16. VanVeen,D.etal. Adaptedlargelanguagemodelscanoutperformmedicalexpertsinclinicaltextsummarization. Nat. medicine30,1134\u20131142(2024). 17. Li,J.etal. Agenthospital: Asimulacrumofhospitalwithevolvablemedicalagents. arXivpreprintarXiv:2405.02957 (2024). 18. Qian,H.&Liu,Z. Metaagent: Towardself-evolvingagentviatoolmeta-learning(2025). 2508.00271. 19. Elstein,A.S.,Shulman,L.S.&Sprafka,S.A. Medicalproblemsolving: Ananalysisofclinicalreasoning(Harvard UniversityPress,1978). 13/15 --- Page 14 --- 20. Schmidt,H.G.,Norman,G.R.&Boshuizen,H.P. Acognitiveperspectiveonmedicalexpertise: theoryandimplication [publishederratumappearsinacadmed1992apr;67(4): 287]. Acad.medicine65,611\u201321(1990). 21. Hicks,E.P.&Kluemper,G.T. Heuristicreasoningandcognitivebiases: Aretheyhindrancestojudgmentsanddecision makinginorthodontics? Am.journalorthodonticsdentofacialorthopedics139,297\u2013304(2011). 22. Elstein,A.S. Heuristicsandbiases: selectederrorsinclinicalreasoning. Acad.Medicine74,791\u20134(1999). 23. Shin,H.S. Reasoningprocessesinclinicalreasoning: fromtheperspectiveofcognitivepsychology. Koreanjournal medicaleducation31,299(2019). 24. Bach,R.M. Heuristicreasoningandcognitivebiases. Am.J.Orthod.Dentofac.Orthop.140,2(2011). 25. Jin,D.etal. Whatdiseasedoesthispatienthave? alarge-scaleopendomainquestionansweringdatasetfrommedical exams. Appl.Sci.11,6421(2021). 26. Pal,A.,Umapathi,L.K.&Sankarasubbu,M. Medmcqa: Alarge-scalemulti-subjectmulti-choicedatasetformedical domainquestionanswering. InConferenceonhealth,inference,andlearning,248\u2013260(PMLR,2022). 27. Wang, Y. et al. Mmlu-pro: A more robust and challenging multi-task language understanding benchmark. In The Thirty-eightConferenceonNeuralInformationProcessingSystemsDatasetsandBenchmarksTrack(2024). 28. Gibney,E. Scientistsflocktodeepseek: howthey\u2019reusingtheblockbusteraimodel. Nature12(2025). 29. Ahmed,I.etal. Qwen2.5: Acomprehensivereviewoftheleadingresource-efficientllmwithpotentioaltosurpassall competitors. AuthoreaPrepr.. 30. Lin, K.-H. et al. Benchmarking large language models gpt-4o, llama 3.1, and qwen 2.5 for cancer genetic variant classification. NPJPrecis.Oncol.9,1\u201310(2025). 31. Wu,J.etal. Arch-evalbenchmarkforassessingchinesearchitecturaldomainknowledgeinlargelanguagemodels. Sci. Reports15,13485(2025). 32. Fang,K.,Tang,C.&Wang,J. Evaluatingsimulatedteachingaudioforteachertraineesusingragandlocalllms. Sci. Reports15,3633(2025). 33. Joshi,S. Acomprehensivereviewofqwenanddeepseekllms: Architecture,performanceandapplications. Perform.Appl. (May15,2025)(2025). 34. Lin,J. Divergencemeasuresbasedontheshannonentropy. IEEETransactionsonInf.theory37,145\u2013151(1991). 35. Kornblith,S.,Norouzi,M.,Lee,H.&Hinton,G. Similarityofneuralnetworkrepresentationsrevisited. InInternational conferenceonmachinelearning,3519\u20133529(PMLR,2019). 2 Data availability Thedatasetsusedinthisstudyarepubliclyavailable. TheMedQAdataset(USMLEsubset)canbeaccessedat  evaluation. TheMedMCQAdatasetissourcedfromIndianmedicalexamsandisavailableat medmcqa/medmcqa. The MMLU-Med subset, comprising interdisciplinary medical knowledge tasks, can be found at  Allcodeforreproducingouranalysisisavailableinthefollowingrepository: RolePlay_LLMDoctor# Inclusion & Ethics Statement Thisstudywasconductedwithastrongcommitmenttoethicalresearchpracticesandinclusivescientificinquiry. Ourresearch focusesonthecognitivemodelingcapabilitiesoflargelanguagemodels(LLMs)inthecontextofmedicalrolesimulation. Nohumansubjectsorprivatehealthdatawereusedorinvolvedatanystageofthestudy. Alldatasetsemployed\u2014MedQA, MedMCQA,andMMLU-Med\u2014arepubliclyavailableandaccessedundertheirrespectiveopenlicenses,ensuringtransparency andreproducibility. Theauthorsaffirmthatnodiscriminatory,exclusionary,orharmfulcontentispresentinthedatasets,prompts,orexperimen- taldesign. Therolesdesignedinthisstudyspandiversemedicalbackgroundsandgeographies(e.g.,doctorsfromChina,the U.S.,andvariousmedicalranks),reflectingourintenttoensureinclusivityinprofessionalrepresentation. 14/15 --- Page 15 --- Acknowledgements ThisworkissupportedbytheNationalNaturalScienceFoundationofChinaundergrant62072463,theScientificResearch FundofRenminUniversityofChina(CentralUniversitiesBasicScientificResearchFunds)underproject24XNKJ31,andthe OpenFundoftheNationalKeyLaboratoryofDigitalPublishingTechnology,FounderGroup. Thecorrespondingauthorsof thispaperareYanfangChenandZhiyuLi. Author contributions statement X,L.Z.L.andH.L.conceivedthestudyandsupervisedtheoverallproject. H.L.andH.W.designedandexecutedthecore"
}