{
  "abstract": "Abstract LargeLanguageModel(LLM)-basedagentshaveemergedasatransformative approachforopen-endedproblemsolving,withinformationseeking(IS)being a core capability that enables autonomous reasoning and decision-making. While prior research has largely focused on improving retrieval depth, we observethatcurrentISagentsoftensufferfromlowsearchefficiency,whichin turnconstrainsoverallperformance. Akeyfactorunderlyingthisinefficiency isthesparsityoftargetentitiesintrainingtasks,whichlimitsopportunitiesfor agentstolearnandgeneralizeefficientsearchbehaviors. Toaddressthesechal- lenges,weproposeWebLeaper,aframeworkforconstructinghigh-coverage IS tasks and generating efficient solution trajectories. We formulate IS as a tree-structuredreasoningproblem,enablingasubstantiallylargersetoftarget entities to be embedded within a constrained context. Leveraging curated Wikipediatables,weproposethreevariantsforsynthesizingIStasks\u2014Basic, Union,andReverse-Union\u2014tosystematicallyincreasebothISefficiencyand efficacy. Finally,wecuratetrainingtrajectoriesbyretainingonlythosethatare simultaneouslyaccurateandefficient,ensuringthatthemodelisoptimizedfor bothcorrectnessandsearchperformance. Extensiveexperimentsonbothbasic andcomprehensivesettings,conductedonfiveISbenchmarks\u2014BrowserComp, GAIA, xbench-DeepSearch, WideSearch, and Seal-0\u2014demonstrate that our method consistently achieves improvements in both effectiveness and effi- ciencyoverstrongbaselines. GAIA BrowseComp xbench-DeepResearch WideSearch 73.2 38.8 SR Item-F1 72.0 68.3 67.4 66.0 63.1 30.0 28.3 26.4 71.0 70.0 69.0 67.0 3.0 2.357.9 2.6 57.7 65.0 48.5 48.3 41.3 14.1 12.2 0.4 WebLeaper Cla -u Sd oe n D- n e4 e et pRO ep se en arAI ch GL -4M . D5 eepS -e Ve 3k .1 Kim -i K2 WebLeape Dr eepS -e Ve 3k . O1 penAI -- mo i4 ni GL -4M .5 Kim -i K2 Cla -u Sd oe n- n4 et WebLeape Dr eepS -e Ve 3k .1 GL -4M .5 ReseaK ri cm hi er Open -AI o3 Cla -u Sd oe n- n4 et WebLeaper Cla -u Sd oe n- n4 et Doubao-1.6 DeepSee -k R1 Figure1: Resultsoncomprehensivetrainingsetting. AllWebLeaperscoresareaveragedoverthreeruns. Themetricofthefirstthreefiguresareaccuracy. \u201cSR\u201ddenotesSuccessRateonWideSearch. *Equalcontribution. (cid:0)   1 5202 tcO 82 ]LC.sc[ 1v79642.0152:viXra --- Page 2 ---",
  "introduction": "1 Introduction TheLLM-basedagentsmarkaparadigmshiftinAI,deliveringtransformativesolutionstochallenges once deemed intractable across diverse domains (Guo et al., 2024; Ye et al., 2023). Among their core capabilities,informationseeking(IS)playsacrucialroleinenablingthecognitiveautonomyofthese agents. This ability not only drives their adaptability in open-ended tasks but also underpins a new generationofpowerfulcommercialsystems,includingOpenAIDeepResearch(OpenAI,2025b),Google\u2019s Gemini(Gemini,2025),andPerplexityAI(Perplexity,2025),Kimi-Researcher(Team,2025). While numerous studies have sought to enhance the IS capabilities of agents through complex ques- tion\u2013answeringpipelinesandadvancedfine-tuningstrategies(Wuetal.,2025a;Lietal.,2025c;b;Tao etal.,2025;Qiaoetal.,2025;Luetal.,2025),mostexistingapproachesprimarilyconcentrateonimproving thesearchdepth,givingcomparativelylittleattentiontosearchefficiency. Ourpreliminaryexperiments indicatethatcurrentLLM-basedagentssearchinefficiently.AsshowninFigure2,thedistributionofvalid actionsforacompetitiveISagentpeaksaround0.04,meaningthatinmostcases,onlyasmallfractionof actionsareeffective(Wongetal.,2025;Xueetal.,2025). Thislowvalid-actionratereflectssuboptimal searchbehaviors,includingredundantqueryreformulations,retrievalofirrelevantinformation,and unnecessarilylongsearchchains. Suchinefficienciesnotonlyincreasecomputationalandtimecostsbut alsolimittheagent\u2019soverallISperformance. 5 4 3 2 1 0 0.0 0.2 0.4 0.6 0.8 1.0 Valid Action Rate ytisneD ecnerruccO evitaleR Thedesignofsynthetictrainingtasksincursthis inefficiency. IntypicalISagentsetups,theagent beginswithasetofknownentitiesandincremen- tally gathers information to infer all target enti- ties. However,priorworkoftenconstructstasks inwhichthetargetentitiesareoverlysparse(Wu etal.,2025a;Lietal.,2025c;b). Suchsparsitylimits 0.04 theagent\u2019sexposuretoinformativecues,reducing opportunitiestolearntolocaterelevantinforma- tionwithina constrainedcontextwindow. As a Figure 2: The distribution of valid actions of the",
  "results": "results demonstratethatourapproachgeneralizeswellandremainseffectiveevenwhenevaluatedunderthe comprehensiveandrealistictrainingsetting. 4.3 Capability Gains Induced by Entity-Intensive Task Synthesis Toinvestigatetheeffectivenessofourentity-intensivetasksynthesismethod,weconductacomparative analysisagainsttrainingsolelyontheWebSailor-V2dataset(using5,000and1,000samples,respectively), asyntheticcorpusspecificallydesignedtostimulatetheagent\u2019sdeepsearchcapability. As shown in Table 2, we investigate the impact of different entity-intensive task synthesis strategies throughanablationstudyonallthesebenchmarks. TheBasicsettingexhibitssubstantialdropsacross allthreedatasetscomparedtoWebSailor-V2-5k. Thispoorperformancecanbeattributedtotheinherent limitationsoftheBasicdataconstructionmethod: tasksgeneratedunderthissettingtendtobeoverly simple,allowingthemodeltoinfercompleteanswersfromonlyafewinformationsources. Suchshortcut patterns encourage the model to overfit to superficial cues rather than learning to integrate diverse information,ultimatelyimpairinggeneralization. 11 --- Page 12 --- 42.5 40.0 37.5 35.0 32.5 30.0 27.5 25.0 54 56 58 60 62 64 66 68 70 Average Action Rounds ecnamrofreP WebSailor-V2 70 WebSailor-V2 WideSearch WebLeaper WebLeaper 68 GAIA 66 64 xbench-DS BrowseComp 62 60 20 22 24 26 Average Action Rounds Figure5: EffectivenessandefficiencycomparisonbetweenWebLeaperandWebSailor-V2. In contrast, the Union strategy consistently outperforms WebSailor-V2-5k, achieving an average im- provementof+3.26. Bycombiningheterogeneousinformationsourcesandincreasingthecomplexityof taskconstruction,UnionmitigatestheshortcutprobleminherentinBasic,forcingthemodeltoreason overdispersedandcomplementaryevidence. Thisleadstomorerobustperformanceacrossdatasetsand demonstratestheeffectivenessoftheproposeddataconstructionapproach. Furthermore,comparedtoUnion,Reverse-Unionintroducesacertaindegreeofreasoningcomplexity intotheinformation-seekingprocess,makingitmorechallengingforthemodeltoreadilyidentifywhere tobeginentityretrieval. Thisdesignparticularlyenhancesthemodel\u2019splanninganddecision-making capabilities in information-seeking tasks. The improvement in these abilities is clearly reflected in performance,leadingtosubstantialandwidespreadgainsacrossallbenchmarks. 4.4 Impact of Information-Guided Trajectory Construction Wecomparetheproposedinformation-guidedtrajectoryconstructionstrategiesacrossISR-Only,ISE-Only, andISR+ISEonthreerepresentativebenchmarks\u2014GAIA,BrowseComp,andWideSearch\u2014toexamine theindependentandcombinedeffectsofISEandISR. OnGAIAandBrowseComp,ISR+ISEachievesthebestperformance,suggestingthatintegratingprecision andefficiencyconstraintsproducestrajectoriesthatarebothgoal-directedandconcise,therebyreducing redundantexploration. Thisindicatesthatinmorecomplexbrowsingtasks,relevanceandefficiency constraintscomplementeachothertogeneratehigher-qualitytrajectories. Incontrast,onWideSearch,thethreestrategiesdelivercomparableresults,withperformancedifferences fallingwithinthemarginofvariance. Thissuggeststhatforbroadsearchtasks,thespecificchoiceof trajectoryfilteringplaysalesscriticalrole\u2014likelybecausetrainingonentity-intensivesynthesizeddata alreadyprovidesstrongbroadsearchcapabilities. 4.5 Joint Gains in Efficiency and Effectiveness AsillustratedinFigure5,WebLeaperconsistentlyoutperformsthebaselineintermsofbotheffectiveness andefficiency. IntheWideSearchandBrowseCompbenchmarks,ourapproachachievesmarkedlyhigher performance scores while requiring fewer average action rounds, indicating that the search process is not only more accurate but also more efficient. Similarly, in the GAIA and xbench-DS tasks, our methodimproveseffectivenesswhilesimultaneouslyreducingtheoperationalcost. Thisdemonstrates thatourdesignenablesamoretargetedsearchstrategy,resultinginreducedinteractionstepswithout sacrificing\u2014andinfactenhancing\u2014thequalityoftheresults. Overall,theseresultsvalidatethatourproposedmethodachievessuperiorjointoptimizationofinformation- seekingefficiencyandtaskperformancecomparedtothebaseline. Thisreflectsourkeyinsight: anagent shouldnotmerelylearntosearch,butratherlearntosearchefficientlyandwisely,therebyachievinga betterbalancebetweenefficiencyandeffectiveness. 12 --- Page 13 --- 0.65 0.60 0.55 0.50 0.45 0.40 0.35 20 40 60 80 100 120 140 Step draweR Reward Curve Raw Reward Smoothed Reward Figure 6: Figure shows the training curve of the hybrid reward system, indicating that using the WebLeaperdataleadstoastableincreaseinreward. Weterminatedtheexperimentat135stepswhen webaccessresourceswereexhaustedandevaluatedtheresultsatthispoint. 4.6 Reinforcement Learning using WebLeaper Table3: RLResultsoncomprehensivesetting.  from3rollouts. WideSearchreportsSuccessRate(SR),Row F1,andItem F1. WideSearch BrowseComp GAIA xbench-DS SR Row F1 Item F1 SFT 37.80 69.9 69.0 1.5 23.0 45.4 SFT+RL 38.8 (+1.0) 73.2 (+3.3) 72.0 (+3.0) 4.0 (+2.5) 31.0 (+8.0) 48.5 (+3.1) Wefurtherevaluateourapproachthroughreinforcementlearning,adoptingtheAdditionalSettingsfor MoreComprehensiveandRealisticTraining(seeSection4.1)whereWebLeaperdataismixedintoalarger trainingcorpusforbothSFTandsubsequentRLstages. AsdemonstratedbytheresultsinTable3and Figure6,usingWebLeaperdataforRLyieldsconsistentandsignificantimprovements. Theresultstable showsthatafterRLfine-tuning,themodelcomprehensivelysurpassestheSFT-onlybaselineacrossall benchmarks. This positive performance trend is echoed by the reward curve in Figure 6, which exhibits a stable and continuous upward trajectory throughout the training process. This indicates that the model is effectivelylearningfromtherewardsignalsderivedfromtheWebLeaperdata,progressivelyrefining its information-seeking strategy towards greater efficiency and accuracy. Even with the",
  "experiments": "Experiments sectionofthispaper. NootherrelianceonLLMsisinvolvedinthiswork. A.2 Proof of Proposition 1 ThisappendixprovidesthedetailedmathematicalderivationforProposition1,aspresentedinSection2.3. ThepurposeofthisproofistoformallyestablishthatthevarianceoftheInformation-SeekingEfficiency (ISE)metricisinverselyproportionalton,thenumberofrequiredentities. Thisproperty,Var(ISE) = O(1/n),demonstratesthatISEbecomesanincreasinglystableandreliableperformancemeasureasthe complexityofthetask(i.e.,thesizeofn)grows. Proof. LetX bethenumberofstepstheagenttakestodiscoverthei-thnewentityintherequiredset i R. Weassume{X}n areindependentandidenticallydistributed(i.i.d.) randomvariableswithmean i i=1 E[X] = \u00b5andvarianceVar(X) = \u03c32. i i Thetotalnumberofstepsis T = \u2211n X. Let X betheaveragenumberofstepstofindonerequired i=1 i entity,definedasX = 1 \u2211n X = T. Bydefinition,ISE= n/T =1/X. n i=1 i n Fromthepropertiesofi.i.d. randomvariables,themeanandvarianceofXare: E[X] = \u00b5, (13) \u03c32 Var(X) = . (14) n WeareinterestedinthevarianceofISE,whichisafunctionoftherandomvariableX. Letthisfunction be f(X) =1/X. WecanapproximatethevarianceofISEusingtheDeltamethod,whichstatesthatfora function f withanon-zeroderivativeat\u00b5: Var(f(X)) \u2248 (cid:0) f\u2032(E[X])(cid:1)2 Var(X). First,wecomputethederivativeof f(x) =1/x,whichis f\u2032(x) = \u2212x\u22122. Evaluatingthisderivativeatthe mean\u00b5: f\u2032(\u00b5) = \u2212\u00b5\u22122. Now,substitutingthisandthevarianceofXfromEquation(14)intotheDeltamethodformula: (cid:16) (cid:17)2 \u03c32 1 \u03c32 (cid:18) 1(cid:19) Var(ISE) \u2248 \u2212\u00b5\u22122 \u00b7 = \u00b7 = O . n \u00b54 n n Thiscompletestheproof. A.3 Data Statistics Figure7illustratesthedistributionofourtrainingdata. Figure8displaystheentitycountdistributionofourtrainingdata. Asignificantportionofoursamples containatleast100entities,underscoringtheinherentdifficultyofourdataset. AsformalizedinEquation 6,thiscomplexityiscrucialforrobustlymeasuringefficiency,whichinturnleadstoimprovedoverall performance. 19 --- Page 20 --- Figure7: Thedistributionofourtrainingdata. A.4 Data Cleaning and Basic Task Construction ThissectionelaboratesonthedataprocessingandconstructionmethodologyfortheBasicversiontasks introducedinSection3.1.1. RationaleforTreeStructure Ininformation-seekingtasks,thereasoningstructureisparamount. We choseatreestructureforourbasictasksbecauseitoffersacompactandhierarchicalorganizationof entities. Thisstructureishighlyefficientforrepresentingalargenumberofinterconnectedentitiesthat stemfromacommonqueryconcept,mirroringmanyreal-worldinformation-gatheringscenarios. A reasoningtreeiscomposedofaroot(questionentity)andasetofsubtrees,whereeachsubtreerepresents acohesiveunitofinformation. Multi-StageTableCleaning Toensurethequalityandsuitabilityofthedatausedfortasksynthesis, wecrawledapproximately2milliontablesfromWikipediaandsubjectedthemtoarigorousmulti-stage cleaningprocedure. Thiswasessentialbecauserawwebtablesareoftennoisyandinconsistent. The stageswereasfollows: \u2022 SizeFiltering: Wefirstdiscardedtablesthatwereeithertoosmall(fewerthan10rowsor3columns) tocapturemeaningfulrelationalinformation,ortoolarge(morethan200rowsor20columns)tobe processedefficientlyandformacoherenttask. \u2022 SemanticandStructuralFiltering: Wethenremovedsemanticallyirrelevantcolumnsthatfrequently appear in web tables, such as those containing serial numbers, notes, or",
  "related_work": "Related Work 5.1 Information Seeking Agent LLM-powered information-seeking agents can be broadly categorized into 3 streams: (1) enhancing coremodelsviasupervisedfine-tuning(Zengetal.,2023;Wuetal.,2025a;Lietal.,2025c;b;Taoetal., 13 --- Page 14 --- 2025; Su et al., 2025; Fang et al., 2025a); (2) advancing agent architecture for improved planning and robustness(Qiaoetal.,2025;Xuetal.,2025a;Lietal.,2025a);and(3)developingmulti-agentsystemsfor collaborativeproblem-solving(Wuetal.,2023;Hongetal.,2024). Ourworkalignswiththefirstcategory butaddressesakeylimitation. Priormethodsoftentrainontasksfocusedoncorrectnesswithsingle-fact answers,whichisinsufficientforlarge-scaleinformationgathering. Wepositthatthenumberofentities inananswer\u2014itsentityrichness\u2014isacriticaldimensionforevaluatinganagent\u2019scompletenessand efficiency. Thispaperaimstobridgethisgapbycreatingandutilizingentity-richQAdatatoenhance agentcapabilitiesforcomprehensiveinformationacquisition. 5.2 Agent Data Synthesis Syntheticdatagenerationispivotalforagenttraining,withprimaryapplicationsintooluse(Wuetal., 2025a;Taoetal.,2025;Shenetal.,2025;Fangetal.,2025b),codegeneration(Jimenezetal.,2024;SHEN etal.,2025;Xuetal.,2025c;Shaoetal.,2025),andGUIautomation(Xuetal.,2025b;Sunetal.,2025;Pahuja etal.,2025).Theseeffortsprimarilycombatdatascarcity.Withintheinformation-seekingdomain,existing datasynthesisapproachesincreasetaskdifficultythroughmulti-stepreasoning(Wuetal.,2025b;a;Tao etal.,2025)orlong-horizonplanning(Qiaoetal.,2025). Wecontendthatsuchmethodsoftenoverlook thesemanticrichnessofthetrainingdataitself. Incontrast,ourapproachcentersonsynthesizingQA datawithhighentity-levelcomplexity. Wehypothesizethatthisfocusondatasemanticsisacrucialand complementarypathtoimprovingagentreasoningandworldknowledgealignment. 6",
  "conclusion": "Conclusion Inthispaper,weaddressedthecriticalchallengeoflowsearchefficiencyinLLM-basedinformation- seekingagents,abottleneckthatconstrainstheiroverallperformance. Wearguedthatthesparsityof targetentitiesinconventionaltrainingtasksisaprimarycontributortothisinefficiency. Toovercomethis, weintroducedWebLeaper,anovelframeworkforconstructingentity-intensiveIStasksandgenerating efficientsolutiontrajectories. ByformulatingISasatree-structuredreasoningproblemandsystematically increasingtaskcomplexitythroughourBasic,Union,andReverse-Uniontasksynthesisvariants,we createdarichtrainingenvironment. Furthermore,ourinformation-guidedtrajectorycuration,using ISRandISEmetrics, ensuresthattheagentlearnsfromsolutionsthatarebothaccurateandefficient. OurextensiveexperimentsdemonstratedthatWebLeaperconsistentlyimprovesperformanceacrossfive challengingbenchmarks,validatingthatenhancingsearchefficiencyisapowerfulleverforboostingthe overallcapabilitiesofISagents. 14 --- Page 15 ---",
  "references": "references. Tables with significantformattingerrors(e.g.,numerousmergedcellsthatdisrupttherelationalstructure)were alsoexcluded. \u2022 Isomorphism and Homogeneity: Finally, we retained only groups of isomorphic tables (tables sharing the same column headers and structure). This step was crucial for ensuring structural homogeneityacrossourdataset,whichisaprerequisiteforidentifyingcommonsubtreestructures neededfortheUnionoperationdescribedlater. Theresultingcollectioncontainsclean,well-structuredtableswithasetofmeaningfulfieldsascolumns andmultiplerows,whereeachrowcanbetransformedintoasubtree. ReasoningTreePopulation Toconstructthethree-layerreasoningtreefromasingletable,wepopulate thelayersasfollows: \u2022 FirstLayer(QuestionEntities): Entitiesmentionedinthetable\u2019stitleorcaptionareextractedto formtherootofthetree. \u2022 SecondLayer(RootsofSubtrees): WeemployanLLMtoanalyzethetable\u2019scolumnsandselect onethatcontainsnoduplicateentries. Thiscolumnistreatedasthekey,anditsvaluesbecomethe 20 --- Page 21 --- Figure8: EntityCountDistributioninTrainingData. Asignificantportionofoursamplescontainsat least100entities,underscoringtheinherentdifficultyofourdataset. Thiscomplexity,asformalizedin Equationequation6,iscrucialforrobustlymeasuringefficiency,whichinturncontributestoimproved overallperformance. second-layerentitiesofthetree. Eachoftheseentitiesservesastherootofasubtree. TheLLMis effectiveatidentifyingcolumnslike\u2018Name\u2019or\u2018Title\u2019thatservethisuniqueidentificationpurpose. \u2022 ThirdLayer(LeavesofSubtrees): Thevaluesintheremainingcolumnsofthetableconstitutethe thirdlayer,representingtheleafentitiesassociatedwitheachsecond-layerentity. A.5 Maximal Union Algorithm for Task Synthesis Thissectionprovidestheformaldefinitionandalgorithmicimplementationfordiscoveringmaximal uniongroups,asintroducedinSection3.1.2. Thecoreofourapproachistoreformulatethesearchfor compatiblereasoningtreesasaMaximalBicliqueEnumeration(referto 1problemonabipartitegraph. ProblemFormulation LetT = {T ,T ,...,T }beourcollectionofbasicreasoningtrees. Wefirstconstructabipartitegraph base 1 2 N G = (U,V,E),whereU = T isthesetofalltrees,andV isthesetofalluniquerelationnamesfound base withinthesubtreesacrossalltreesinT . Anedge(T,v ) \u2208 Eexistsiftherelationv ispresentinany base i j j subtreeoftreeT (i.e.,v \u2208Rel(T),whereRel(T) = (cid:83) Rel(S )). i j i i k i,k Inthisconstruction,amaximaluniondirectlycorrespondstoamaximalbiclique(U,V),whereU \u2286Uisa setoftreesandV \u2286V isasetoftheircommonrelations. Ourgoalistofindallsuchmaximalbicliques thatsatisfycertainsizeandsemanticconstraints. Formally,weseektofindallmaximalpairs(U,V)that satisfy: findmaximal (U,V) subjectto \u2200T \u2208 U,V \u2286Rel(T), (15) i i |U| \u2265 k ,|V| \u2265 m . min min Here,maximalitymeansthatnoothertreecanbeaddedtoU andnootherrelationcanbeaddedtoV withoutviolatingthebicliqueproperty. Solvingthisbyreformulatingitasastandardmaximalbiclique enumerationproblemiscomputationallyefficientcomparedtoanexhaustivesearch. AlgorithmandImplementationDetails \u2022 Input: AcollectionofbasereasoningtreesT ;aminimumnumberoftreesforavalidunion,k ; base min 21 --- Page 22 --- aminimumnumberofcommonrelations,m . min \u2022 Goal: Tofindallmaximaluniongroups,whicharethesolutions(U,V)toEq.(15)thatalsosatisfythe semanticmatchingcriteriabelow. \u2022 SubtreeRelationMatchingCriteria: Toensurethesemanticcoherenceofunions,weimposestrict matchingcriteria. Forrelationsconnectingthesecondandthirdlayers,werequiretheysharethe samestandardizedname,datatype,anddomain. Forthesecond-layerentitiesthemselves(theroots ofthesubtrees), werelaxthisconstraint, requiringonlyamatchindatatypeanddomain. This flexibilityallowsfortheunionoftreeswithconceptuallysimilarbutdifferentlynamedsecond-layer entities(e.g.,fusingatreewhereentitiesare\u2019Authors\u2019withanotherwheretheyare\u2019Writers\u2019). \u2022 Output: AsetofmaximaluniongroupsF,whereeachelementisatuple\u27e8U\u2032,V\u2032\u27e9thatmeetsthe specifiedcriteria. TheprocessisdetailedinAlgorithm1. Algorithm1:MaximalUnionIdentificationAlgorithm Input: AcollectionofbasereasoningtreesT ,minimumtreesk ,minimumcommonrelations base min m . min Output: AsetofmaximaluniongroupsF. 1 F \u2190 \u2205; // 1. Construct the bipartite graph from trees and subtree relations 2 LetUbethesetoftreesfromT baseandV bethesetofuniquestandardizedrelationnamesfound withinthesubtreesofalltreesinT ; base 3 ConstructthegraphG = (U,V,E)whereanedge(u,v) \u2208 Eexistsiftreeucontainstherelationvin itssubtrees(i.e.,v \u2208Rel(u)); // 2. Enumerate maximal bicliques from the graph 4 B \u2190EnumerateMaximalBicliques(G); ; // Leverages standard algorithms like MICA or Eclat // 3. Filter and validate bicliques to form final union groups 5 foreachmaximalbiclique(U\u2032,V\u2032)inBdo // Check size constraints from Eq. (1) 6 if|U\u2032| < k minor|V\u2032| < m minthen 7 continue; // Validate semantic compatibility of second-layer entities 8 LetT id,D idbethetypeanddomainofthesecond-layerentitiesofthefirsttreeinU\u2032; 9 is_compatible\u2190true; 10 foreachtreeu \u2208U\u2032 do 11 ifu\u2019ssecond-layerentitytype\u0338= T idordomain\u0338= D idthen 12 is_compatible\u2190false; 13 break; // If all checks pass, add to the set of valid union groups 14 ifis_compatiblethen 15 F \u2190 F \u222a{\u27e8U\u2032,V\u2032\u27e9}; 16 returnF; A.6 Detailed Examples of Task Synthesis Thissectionprovidesdetailedexplanationsandreasoningwalkthroughsfortheexamplesofthethree tasksynthesisversionspresentedinSection3andFigure3. 22 --- Page 23 --- A.6.1 Version-I:Basic Thegoalofthebasicversionistocreateataskwithaclear,hierarchicalreasoningstructurederivedfrom asingle,self-containedsetofentities. ExampleQuestion: WhoweretheNobelPrizewinnersinLiteraturebetween1980and1990? Pleaseinclude theirname,country,awardyear,andgender. ConstructionProcess: ThetaskisconstructedfromasingleWikipediatable,formingareasoningtree. ThelayersshowninFigure3(a)arepopulatedasfollows: \u2022 FirstLayer(questionentities): Derivedfromthetable\u2019stitleandaspecifiedconstraint,formingthe query\u2019sscope: LiteratureNobelPrize,year1980\u20131990. \u2022 SecondLayer(subtreeroots): Populatedfromthetable\u2019skeycolumn(e.g.,authornames): Czes\u0142aw Mi\u0142osz,WilliamGolding,.... \u2022 Third Layer (subtree leaves): Consists of values from the remaining columns, representing at- tributes for each second-layer entity. For example: man, Poland, 1980 for Czes\u0142aw Mi\u0142osz. The edgesconnectingthesecondtothethirdlayerrepresentrelationslike\u2018has_gender\u2019,\u2018has_country\u2019, \u2018has_award_year\u2019. ReasoningPath: Anagentisexpectedtofollowthishierarchicalstructure: \u2022 Identify Scope: Recognize the \u201cQuestion Entities\u201d from the query: Nobel Prize in Literature, 1980\u20131990. \u2022 RetrieveSecond-LayerEntities: Retrievethesecond-layerentities,whicharetheauthors: Czes\u0142aw Mi\u0142osz,WilliamGolding,.... \u2022 GatherAttributes: Foreachsecond-layerentity, followtherelationstoretrievetheirassociated third-layerentities,suchasPoland,1980,manforCzes\u0142awMi\u0142osz. A.6.2 Version-II:Union This version increases structural complexity by requiring the agent to perform relational operations acrossdistinctreasoningtrees. ExampleQuestion: WhichauthorshavewonboththeNobelPrizeinLiteratureandtheBookerPrize? Foreach, providetheirname,nationalityandtheyeartheywontheNobel. ConstructionProcess: Onceamaximalunionisidentified(e.g.,betweenthereasoningtreesfor\u201cNobel Prizelaureates\u201dand\u201cBookerPrizewinners,\u201dwhichsharecommonrelationslike\u201chas_nationality\u201dwithin theirsubtrees),anLLMgeneratesataskrequiringinformationintegration. TheLLMispromptedtofind aninterestingrelationship,suchastheintersectionofthetwosetsofsecond-layerentities(authors),and thenweavethislogicintoanaturallanguagequestion. ReasoningPath: Thetaskisconstructedfromamaximalunionoftwodistinctreasoningtrees. Tosolve this,anagentmust: \u2022 RetrieveFirstEntitySet: Identifythefirstconcept,\u201cNobelPrizeinLiterature,\u201dandretrievethefull setofcorrespondingsecond-layerentitiesfromthefirsttree,R . Nobel(T1) \u2022 RetrieveSecondEntitySet: Identifythesecondconcept,\u201cBookerPrize,\u201dandretrieveitsfullsetof second-layerentitiesfromthesecondtree,R . Booker(T2) \u2022 FindIntersection: Performarelationaljointofindtheintersectionofthetwosetsofsecond-layer entities based on name. The final \u201cTarget Entities\u201d are the entities present in both sets, such as {WilliamGolding,J.M.Coetzee,...},alongwiththeirrequestedthird-layerattributes. 23 --- Page 24 --- 0.0200 0.0175 0.0150 0.0125 0.0100 0.0075 0.0050 0.0025 0.0000 0 20 40 60 80 100 Toolcall Count ytisneD Toolcall Count Density 0.040 0.035 0.030 0.025 0.020 0.015 0.010 0.005 0.000 0 20 40 60 80 Search Count ytisneD Search Count Density 0.035 0.030 0.025 0.020 0.015 0.010 0.005 0.000 0 20 40 60 80 Visit Count ytisneD Visit Count Density Figure9: DistributionofSearch,Visit,andtotaltoolcall. A.6.3 Version-III:Reverse-Union Thisversionintroducesachallengingcognitiveworkflowbyintentionallyobfuscatingthequery\u2019sentry points. Motivation and Design: The Union method, while creating multi-source tasks, has a vulnerability: an agent could solve it with simple keyword searches for each source, bypassing deeper reasoning. Reverse-Unioninvertstheinformationflow,forcinganagenttofirstdeduceacore\u2018anchor\u2019entity(a second-layerentity)fromdescriptivecluesandthenusethatentityasapivottoexpanditssearch. ExampleQuestion: Whoaretheauthorsfromthesamecountryasthe1980sprize-winnerthatwroteanovel aboutagroupofBritishboysstrandedonanuninhabitedisland,andwhohavealsowonboththisrewardandthe BookerPrize? Foreachofthem,whatistheirname,country,andtherespectiveyearstheywoneachaward? ConstructionProcess: TheconstructionbuildsupontheunifiedspacefromVersion-IIwitha\u201creverse\u201d logic: \u2022 Source: WeusetheunifiedinformationspacefromtheNobelandBookerprizeunion. \u2022 SelectAnchor: Anentityattheintersectionofthesecondlayersischosenasthe\u201canchor,\u201d e.g., WilliamGolding. \u2022 ObfuscateAnchor: Insteadofnamingtheanchor,uniquedescriptivecluesbasedonitsthird-layer attributesaregenerated: \u201cthe1980sprize-winner\u201dand\u201cwroteanovelabout... Britishboys...\u201d These cluesbecomethe\u2018QuestionEntities\u2019. \u2022 CreateUnionTrigger: Athird-layerattributeoftheanchor,hisnationality(British),isselectedas thepivotforthenextstageofthequery. RequiredReasoningProcess: Tosolvethistask,anagentmustexecuteatwo-stageprocess: \u2022 DeductionStage:Theagentmustfirstresolvethedescriptiveclues(whicharethird-layerentities)to identifythesecond-layeranchorentity. Theclues\u201c1980sprize-winner\u201dand\u201cnovelaboutstranded Britishboys\u201duniquelypointtoWilliamGolding. Thisinferentialstepiscrucial. \u2022 UnionStage: HavingdeducedWilliamGolding,theagentidentifieshisnationality(athird-layer entityinhissubtree): British. Thisbecomesthepivotforthemainquery. Theagentmustthenfind allsecond-layerentitieswho(1)sharethisthird-layerattribute(British)and(2)havewonboththe NobelPrizeandtheBookerPrize. Thisrequiresfilteringtheunifiedentityspacetofindthefinalset of\u201cTargetEntities\u201d,whichincludesauthorslikeWilliamGolding,KazuoIshiguro,andJ.M.Coetzee. 24 --- Page 25 --- B Tool Call Analysis AsshowninFigure9, ourmethodinvolvesasignificantlylargenumberofactions, includingSearch, Visit,andtotaltoolcalls. Thedensitydistributionsindicatethattoolcallsoftenexceedseveraldozenper instance,withmanycasessurpassing50actions. Thishighfrequencyofactionsreflectstheintensive interaction and comprehensive exploration carried out by our approach, ensuring that the method thoroughlyleveragesavailabletoolstoachieveoptimalperformance. 25"
}