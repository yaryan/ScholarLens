--- Page 1 --- arXivSubmission AGENT DATA PROTOCOL: UNIFYING DATASETS FOR DIVERSE, EFFECTIVE FINE-TUNING OF LLM AGENTS YueqiSong1,KetanRamaneti1,ZaidSheikh1,ZiruChen2,BoyuGou2,TianbaoXie3, YihengXu3,DanyangZhang3,ApurvaGandhi1,FanYang5,JosephLiu1,TianyueOu1, ZhihaoYuan1,FrankXu1,ShuyanZhou4,XingyaoWang6,XiangYue1,TaoYu3, HuanSun2,YuSu2,GrahamNeubig1,6 1CarnegieMellonUniversity,2TheOhioStateUniversity,3UniversityofHongKong, 4DukeUniversity,5FujitsuResearch,6AllHandsAI   ABSTRACT Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique chal- lenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP),alight-weightrepresentationlanguagethatservesasan“interlingua”be- tweenagentdatasetsindiverseformatsandunifiedagenttrainingpipelinesdown- stream.ThedesignofADPisexpressiveenoughtocapturealargevarietyoftasks, includingAPI/tooluse,browsing,coding,softwareengineering,andgeneralagen- ticworkflows, whileremainingsimpletoparseandtrainonwithoutengineering ataper-datasetlevel. Inexperiments,weunifiedabroadcollectionof13existing agenttrainingdatasetsintoADPformat,andconvertedthestandardizedADPdata intotraining-readyformatsformultipleagentframeworks. WeperformedSFTon these data, and demonstrated an average performance gain of ∼20% over corre- spondingbasemodels,anddeliversstate-of-the-artornear-SOTAperformanceon standard coding, browsing, tool use, and research benchmarks, without domain- specifictuning.Allcodeanddataarereleasedpublicly,inthehopethatADPcould helplowerthebarriertostandardized,scalable,andreproducibleagenttraining. 1 INTRODUCTION Pre-traininglargelanguagemodels(LLMs)benefitsfromabundant,readilyavailableInternet-scale data. In contrast, post-training presents a much harder challenge: high-quality task-specific data must be carefully curated. While creative strategies have emerged for collecting data in relatively simple settings, such as single-turn user interactions like code generation (Nijkamp et al., 2023), questionanswering(Rajpurkaretal.,2016),andsentimentanalysis(Maasetal.,2011),manyreal- worldtasksarefarmorecomplex. A particularly difficult case is agent applications, where models must take sequential actions and interactwiththeworlditeratively. Buildingdatasetsforsuchscenariosrequiresrecordingandstruc- turingtrajectoriesofagentbehavior,muchmorechallengingthancollectingstaticinput-outputpairs. Despite these difficulties, a growing body of work has explored different approaches for creating agentdatasets. Theseeffortsvaryinmethodology, frommanualcuration(Rawlesetal.,2023;Xu etal.,2024a),tosyntheticdatageneration(Ouetal.,2024;Zhengetal.,2024a),torecordedagent rollouts (Pan et al., 2025; Yang et al., 2025b). The resulting datasets span a wide range of tasks, including web navigation (Deng et al., 2023; Lu` et al., 2024), software development (Yang et al., 2025b; Pan et al., 2025), visual interface control (Rawles et al., 2023; Kapoor et al., 2024), and generaltooluse(Zengetal.,2023;Liuetal.,2024a)(anoverviewofthesedatasetsin§2.1). 1 5202 tcO 82 ]LC.sc[ 1v20742.0152:viXra --- Page 2 --- arXivSubmission Raw Data Agent Data Protocol OpenHands SFT ❖ AgentInstruct Action Observation ❖ CodeActInstruct SWE Agent SFT ❖ SWE-Gym ➢ API Action ➢ Text Observation ❖ Mind2Web ➢ Code Action ➢ Web Observation AgentLab SFT ❖ …… ➢ Message Action APIAction ( goto(url=google.com) function=goto, WebObservation ( kwargs={url: google.com} url=google.com, <!doctype html> ) html=<html>..., <html itemscope axtree=RootWebArena … <title> Google </title> … </html> 'Google', focused … Trajectory ( CodeAction ( ) id=example_id, ```python language=python, content=[...] print("Hello World") content=print("Hello World") TextObservation ( ) ) ``` content=Hello World, Execution result: source=environment Hello World ) MessageAction ( How can I help you? content=How can I help you? ) Figure 1: Overview of the Agent Data Protocol (ADP). Raw data from diverse sources such as AgentInstruct,CodeActInstruct,SWE-Gym,andMind2WebareconvertedintoastandardizedADP format.ADPunifiesdataintoTrajectoryobjects,whichincludetwocorecomponents:Actions(API action, code action, message action) and Observations (text observation, web observation). This standardizedrepresentationenablesseamlessintegrationwithvariousagentSFTpipelines.Example transformationsdemonstratehowheterogeneousrawdataisnormalizedfortrainingagenticmodels. However, despite the availability of such data, large-scale supervised fine-tuning (SFT) of agents remains rare in academic research. A few notable projects, such as Zeng et al. (2023) and Mitra et al. (2024), have demonstrated their potential, but remain exceptions rather than the norm. Why hasthisnotbecomestandardpractice?Wearguethattheissueisnotalackofdata,butratheralack ofstandardization. Existingdatasetsarefragmented,withinconsistentformatsandrepresentations, makingitdifficulttocombine,share,andleveragethemeffectively,thustheyremainunderutilized. Toaddressthisgap,weintroducetheAgentDataProtocol(ADP),astandardizedexpressiverepre- sentationlanguageforagentdata.ByconvertingheterogeneousdatasetsintoADP,itmakesitsimple to generate large-scale and diverse data for a variety of downstream training pipelines (Figure 1). Technically,ADPisimplementedasPydantic1schemasthatexpressactionsandobservationscorre- spondingtocommonagentusecasessuchascommunicating,browsing,coding,andmiscellaneous toolcalling,coupledwithstrictautomatedvalidationtomaintainhighdataquality. As a first step to demonstrate the practical utility of ADP, we implement converters from 13 pre- existingdatasetsintoADP,andconvertersfromADPto3differentagentarchitectures,demonstrat- ingitsgenerality.Basedonthis,wecreateandreleasethelargestpubliclyavailabledatasetforagent training,consistingof1.3Mtrainingtrajectories,dubbedtheADPDatasetV1. Our experiments show training agents using ADP leads to significant performance improvements across diverse domains, including coding (SWE-Bench Verified), web browsing (WebArena), re- search(GAIA),andagentictooluse(AgentBench),asshownin§6. Notably,theseresultsimprove byanaverageof20%overbasemodels,andarecompetitivewithorsuperiortootherstate-of-the-art results from similarly-sized models. We also identify significant benefits from cross-task transfer, with training on the ADP data improving significantly over training on individual datasets. Be- yond performance, ADP enables systematic cross-dataset analysis, revealing trends and areas for improvementinpubliclyavailabledata. Finally,wereleaseallcodeanddatasetsinopensourcetofostercommunityadoptionandencourage contributionsofnewdatasets.WebelieveADPwillunlockanewwaveofprogressinagenticmodel 1 2 --- Page 3 --- arXivSubmission fine-tuning by providing the standardization needed to make large-scale supervised agent training practicalandscalable. 2 RELATED WORK The development of effective LLM-based agents critically depends on high-quality training data thatcapturesthecomplexityofmulti-stepreasoning,toolusage,andenvironmentalinteraction(Yao etal.,2022b;Schicketal.,2023;Dengetal.,2023;Mastermanetal.,2024). Thissectionreviews existingmethodsforagentdatacollectionandthechallengesthatmotivateouragentdataprotocol. 2.1 AGENTDATACOLLECTIONMETHODS Existingapproachesspanmanualcreation(humanexpertscreatingstep-by-stepdemonstrationsof desired agent behaviors) (Nakano et al., 2021; Yao et al., 2022a), synthetic generation (leverages existingLLMstocreateagenttrajectoriesthroughpromptingorstructuredgeneration)(Luoetal., 2023;Xuetal.,2024b),andrecordedagentrollouts(capturestrajectoriesfromexistingagentsys- temsduringtaskexecution)(Wangetal.,2024a;Panetal.,2025),etc,resultinginabundantagent trainingdata,arepresentativesetofwhichlistedinTable1. Table 1: Overview of Existing Agent Training Datasets. C=Coding, S=Software Engineering, T=API/ToolUse,W=WebBrowsing. Dataset Variety Count Source Note AgentInstruct(Zengetal.,2023) CTW 1.9K synthetic MixtureofBrowsing,Database,OS,etc. Code-Feedback(Zhengetal.,2024a) C 66.4K manual Codegenerationwithruntimefeedbackloops CodeActInstruct(Wangetal.,2024b) C 7.1K synthetic Codegenerationandtoolusewithexecution Go-Browse(Gandhi&Neubig,2025) W 9.5K rollout Structuredexplorationwebrollouts Mind2Web(Dengetal.,2023) W 1.0K manual Humanwebdemosonrealwebsites NebiusSWETrajectories S 13.4K rollout SWE-agent trajectories from Nebius relying (Golubevetal.,2024) solelyonopen-weightmodels NNetNav-live(Murtyetal.,2024) W 5.0K rollout Retroactivelylabeledlivewebexploration NNetNav-wa(Murtyetal.,2024) W 4.2K rollout RetroactivelylabeledWebArenaexploration openhands-feedback CTW 0.2K rollout RecordedOpenHandsagenttrajectorieswithhu- (AllHandsAI,2024) manfeedback OrcaAgentinstruct(Mitraetal.,2024) T 1046.1K synthetic Large-scalesynthetictool-useinstructionsdata SWE-Gym(Panetal.,2025) S 0.5K rollout AgenttrajectoriessolvingrealGitHubrepotasks SWE-smith(Yangetal.,2025b) S 5.0K manual Trajectoriesofagentsonsynthesizedbug-fixtasks Synatra(Ouetal.,2024) W 99.9K rollout Syntheticallycreatedwebdemosoftutorials Wealsogroupeachdatasetintoacoarsetaskcategory. • Coding: generallyincludesfundamentalprogrammingtasks,suchascommandlinecodegenera- tion,algorithmimplementation,codecompletion,codetranslation,andcoderepair,etc. • SoftwareEngineering: oftenconsistsofrepository-levelsoftwareengineeringtasks,suchasbug fixing,featureimplementation,coderefactoring,anddependencymanagement,etc. • API/ToolUse: usuallyrequiresagentstouseexternalAPIs/toolseffectivelytosolvetasks. Com- montoolsincludefilemanipulation,databasequeries,andcustomizedAPIs,etc. • Web Browsing: commonly encompasses tasks including web navigation, online shopping, and socialmediainteractions,etc,requiringagentstounderstandGUIs. 2.2 CHALLENGESANDLIMITATIONS Despiteabundantexistingagenttrainingdatasets,severalfundamentalchallengespreventeffective large-scaleutilizationoftheseresources: • ComplexityofDataCuration: Creationofhigh-qualityagenttrainingdatarequiressignificant resources and expertise (Paullada et al., 2021; Bhardwaj et al., 2024; Zha et al., 2025). Manual curation is expensive and requires domain knowledge; synthetic generation faces challenges in verifying data quality; recorded agent rollouts are fundamentally constrained by the capabilities of existing baseline agents, limiting the diversity and complexity of trajectories. Each approach requires significant time and investment. While recent efforts have scaled trajectory collection 3 --- Page 4 --- arXivSubmission (Songetal.,2024;Mitraetal.,2024), thefundamentalchallengeofbalancingquality, diversity, andscaleacrossdifferentcurationapproachesremains. • HeterogeneityofDatasetformat:Existingagenttrainingdatasetseachemployitsownrepresen- tationformat,actionspaces,andobservationstructures(Ningetal.,2025;Luoetal.,2025). For example,somewebdatasetsuseHTMLwhilesomeuseaccessibilitytreestructures(deChezelles etal.,2025). Existingeffortshavenotedandbegunaddressingdatastandardization(Zhangetal., 2024; Chen et al., 2024; Mohammadi et al., 2025; Xi et al., 2025; Zhang et al., 2025), but they mostly focused on proposing task-specific or agent-specific unification rather than community- widestandardizationofdatarepresentation,limitingplug-and-playwithotherdatasetsoragents, wheresignificantengineeringeffortisstillrequiredtoutilizemultipledatasetstogether,hindering integrationacrossdifferentdatasources. • DifficultyofAnalysisandComparison: Thediversestructuresofexistingdatasetsalsomakesit difficulttoperformsystematiccomparisonsorquantitativeanalysisacrossdifferentdatasources (Putrama & Martinek, 2024), limiting researchers’ ability to understand the relative usefulness, coverage,andqualityofdifferentdatasets,hinderingdata-drivenselectionorimprovements. 3 THE AGENT DATA PROTOCOL To overcome these challenges and limitations, and to make good use of existing data resources, weproposetheagentdataprotocol(ADP).ADPestablishesaunifiedschemathatbridgesthegap betweenexistingheterogeneousagenttrainingdatasetsandlarge-scalesupervisedagentfine-tuning. 3.1 DESIGNPRINCIPLES WedesignADParoundthefollowingcoreprinciples: • Simplicity:ADPmaintainsasimpleandintuitivestructure.Thisdirectlyaddressesthecomplexity of data curation challenge by providing a straightforward framework that eliminates the need for specialized per-dataset engineering, making large-scale agent data utilization accessible to researcherswithoutextensiveadaptationeffort. • Standardization: ADPisdesignedtoprovideaunifiedrepresentationthatunifiesexistingagent trainingdatasetsofvariousdifferentformatstoastandardizedformat,addressingthechallengeof heterogeneousdatasetformats. • Expressiveness: ADPisdesignedtoensurethatcomplexagentictrajectoriescouldbeaccurately expressedwithnolossofcriticalinformation.Thisdirectlyaddressesthedifficultyofanalysisand comparison challenge because ADP is expressive enough to cover the broad variety of existing agent datasets across different domains, enabling researchers to put these diverse datasets under thesameconditionsandcontext. Byaddressingthefundamentalchallengesinutilizationagentdata,ADPaimstopushtheprogress inagenttraining,makinglarge-scaleagentSFTmoreaccessibletothebroaderresearchcommunity. 3.2 ARCHITECTURE TheADPschemaisimplementedasPydanticschemas,andissimpleyetexpressiveindesign. Each ADPstandardizedagenttrajectoryisrepresentedasaTrajectoryobject. Trajectory consists of (1) id: trajectory id, (2) content: an alternating sequence of actions andobservationsrepresentingtheagent’sinteractionwiththeuser/environment, (3)details: A flexiblemetadatadictionaryfordataset-specificinformation(e.g.,datasetsourceURLs). Actionsrepresentagents’decisionsandbehaviors. Wecategorizeactionsintothreetypes: • APIActions: Functioncallswithstructuredparametersandoutputscapturingtooluse. EachAPI actionincludes: (1)function: nameoftoolcall, (2)kwargs: adictionaryoffunctionargu- ments, and (3) description: optional reasoning or explanation for the action. For example, withADP,awebnavigationcallgoto(url= APIAction(function=goto, kwargs=url: 4 --- Page 5 --- arXivSubmission • CodeActions: Codegenerationandexecutionacrossprogramminglanguages. Eachcodeaction specifies: (1)language: theprogramminglanguage(e.g.,python),(2)content: thecodeto execute,and(3)description: optionalreasoningorexplanationfortheaction. Forexample, theADPrepresentationofapythoncodeblock‘‘‘python print("Hello World")‘‘‘ isCodeAction(language=python,content=print("Hello World"). • MessageActions: Naturallanguagecommunicationsbetweenagentsandusers,eachcontaining acontentfield,documentingagents’explanations,clarifications,andresponses. Forexample, MessageAction(content=How can I help you?). Observationsrepresentagents’perceptionsfromtheenvironment,categorizedintotwotypes: • Text Observations: Captures the text information from various sources, including user instruc- tions and environmental feedback. Each text observation includes: (1) source: the origin of theobservation(“user”or“environment”),and(2)content: theobservedtext. Forexample,a pythonexecutionoutputExecution result: Hello World,willbeconvertedtoADP formatTextObservation(content=Hellow World, source=environment). • WebObservations: Representthestateandcontentofwebpages. Eachobservationincludes: (1) html:rawHTMLcontent,(2)axtree:accessibilitytreeofthewebpage,(3)url:currentpage URL, (4) viewport size: browser viewport dimensions, and (5) image observation: optionalscreenshotdata. WebobservationsenableADPtosupportcomplexbrowsingscenarios. ThecoreinsightbehindADPisthatdespitethesurface-leveldiversityinagentdatasets,mostagen- ticinteractionscanbedecomposedintoasequenceofactionstakenbytheagentandobservations receivedfromtheenvironment. Bystandardizingthesefundamentalcomponents,ADPdirectlyad- dresses each challenge identified in § 2.2 while preserving the rich semantics of the original data. Thisunifiedrepresentationenablesresearcherstocombinedatasetsthatwerepreviouslyincompati- ble,facilitatinglarge-scaletrainingacrossdiversedomains. 3.3 CONVERSIONPIPELINE AsshowninFigure1,weimplementedathree-stageconversionpipelinewithADPthattransforms heterogeneousdatasetsintotraining-readyagenticformats. 1. Raw to Standardized: This stage unifies original dataset formats into the ADP standardized schema. Eachdatasetisextractedinitsrawformat, andthenconvertedtotheADPschemaby mapping each dataset-specific actions and observations to the ADP’s standardized action and observationspace. Forexample, awebbrowsingtaskwithHTMLrepresentationsisconverted toapairsofAPIActionandWebObservation, whileacodingtaskwithexecutionoutput ismappedtoCodeActionandTextObservationpairs. 2. Standardized to SFT: This stage converts ADP standardized trajectories into supervised fine- tuning (SFT) format suitable for training language models. Different agent frameworks oper- ate with distinct actions spaces, observations formats, etc. For example, OpenHands employs IPythonexecutionwithwebbrowsingcapabilities,SWE-Agentusesstructuredbashcommands andfileoperations,whileAgentLabfocusesonDOM-basedwebinteractions. Ratherthantrain- ingonlyonegenericactionmodel,werecognizethateffectiveagenttrainingrequiresadaptation to each framework’s specific scaffolding and interactions formats. For each agent harness, the conversionprocessusesoneagent-specificscriptthattranslateseachtypeofactionandobserva- tion into the target agent’s action and observation space based on the agent’s framework. This stagehandlescontextmanagement,specifiessystemprompts,andformatsconversationstocreate SFT-readyinstruction-responsepairs,optimizedfortheparticularagentarchitecture. 3. QualityAssurance:Thisstageensuresdatacorrectnessandconsistencyinalignmentwithagent format, tool use, and conversation structure through automated validation. Example quality checksincludeverifyingtoolcallformats, ensuringmost2 toolcallsarepairedwithanEnglish thought,andcheckingwhethertheconversationendsproperly,etc. 5 --- Page 6 --- arXivSubmission Without ADP: Quadratic Effort With ADP: Linear Effort AgentInstruct OpenHands SFT AgentInstruct OpenHands SFT Code-Feedback Code-Feedback Go-Browse SWE-Agent SFT Go-Browse SWE-Agent SFT ADP Standardized Mind2Web Mind2Web Data SWE-smith AgentLab SFT SWE-smith AgentLab SFT …… …… Figure2: ADPcollapsesmany-to-manyconversionsintoahub-and-spokepipeline. Left: With- outADP,eachofD-manydatasetsneedsacustomRaw→SFTconverterforeachofA-manyagentic formats(quadraticO(D×A)effort),causingduplicatedcodeandefforts. Right: WithADP,each dataset is converted once (Raw→ADP) and each agent only requires one converter (ADP→SFT), yieldinglinearO(D+A)effort. NewdatasetsoragentspluginimmediatelytotherestofADP. 3.4 PRACTICALIMPACTOFADPONAGENTTRAININGRESEARCH The two-direction pipeline (Raw→ADP and ADP→SFT) cleanly separates responsibilities and eliminatesredundantengineering(Figure2). Inpractice: • Datasetconversion(onceperdataset).ContributorsconverteachrawdatasettotheADPschema exactlyonce. Fromthenon,thedatasetisastandardizedresourceusablebyanyagentharness. • Agent-specificconversion(onceperagent).EachagentmaintainsasinglescriptforADP→SFT; noper-datasetengineeringneeded. Addingnewdatasetsrequiresnochangetoagent-sidescripts. • WithoutADP.ResearchersmustwriteaRaw→SFT converterforeachdataset–agentpair,dupli- catingeffortacrossgroupsandmakinglarge-scaledataintegrationbrittleandslow. ADP amortizes conversion cost across the community, accelerates adoption of new datasets, and ensuresthatasingleADP→SFTscriptinstantlyunlockstheentirepoolofADP-standardizeddata toanagentframework. Morediscussioncouldbefoundin§6.3. 4 CROSS DATASET ANALYSIS Table2: DatasetStatisticsandTrajectoryAnalysis. AVG. %Actions %Func Dataset Table 2 shows analysis on 13 ADP Rounds (A/C/M) Thought standardized datasets, revealing signif- AgentInstruct 8.2 64/10/26 100.0 icantdiversityintrajectorylengths,ac- Code-Feedback 4.0 0/58/42 82.8 tion distributions, and reasoning pat- CodeActInstruct 4.0 0/65/35 98.6 ternsacrossdifferenttaskdomains. Go-Browse 3.9 70/0/30 100.0 Mind2Web 9.7 90/0/10 0.0 TrajectoryLength. Trajectoryrounds NebiusSWE-Agent 16.2 67/27/6 100.0 varydramaticallyacrossdatasets,from NNetNav-live 8.2 80/0/20 99.9 1to26.8turns,withanaverageof10.1 NNetNav-wa 10.1 89/0/11 99.9 turns. SWE datasets consistently ex- OpenHands 18.3 11/73/16 91.7 hibit longer trajectories, reflecting the OrcaAgentInstruct 1.3 0/15/85 84.0 inherentcomplexityofmulti-steprepo- SWE-Gym 19.7 61/25/14 42.0 levelprogrammingtasks. SWE-smith 26.8 56/40/4 90.1 Synatra 1.0 100/0/0 99.9 Action Distribution Patterns. Clear Overall 10.1 53/24/23 83.8 domain-specific preferences emerge fromtheactiondistributionsafterstan- dardizationwithADP.Webdatasets(Mind2Web,NNetNav,Synatra)heavilyfavorAPIactions(80– 100%) with minimal code execution, reflecting their focus on interface interaction. Conversely, coding datasets (Code-Feedback, CodeActInstruct) show high code usage (∼60% code) with no APIusage,emphasizingdirectprogrammingactivities. Softwareengineeringdatasetsdemonstrate 2Wesetthisthresholdtobe80%,butitcanbechangedbasedondemand. 6 --- Page 7 --- arXivSubmission mixed patterns, with SWE-smith, SWE-Gym, and Nebius SWE-Agent Trajectories relies on API actionssuchasfilewriteswhilealsousingcodeactionsforcodegenerationandexecution. FunctionReasoningAnalysis.Astrikingfindingisthehighfunctionthoughtcoverageacrossmost datasets,withmostachieving≥90coverage,indicatingthatthesetrainingdatasetsconsistentlypro- videexplanationsfortheiractions.Thischaracteristicisparticularlyvaluableforinterpretabilityand trainingagentswithreasoningabilities.Importantly,highreasoningcoverageappearsacrossalltask varieties, suggesting that function thoughts represent a general characteristic of well-documented datasetsratherthandomain-specificbehavior. 5 EXPERIMENTAL SETUP 5.1 TRAININGSETUP ToevaluateADP’seffectivenessintrainingacrossdiversedatasources,weutilizeacomprehensive collection of 13 agent training datasets, spanning coding, SWE, API/tool user, and browsing, as documented in Table 1. These datasets represent a broad spectrum of heterogeneity challenges that ADP addresses, including varied data creation methodologies (synthetic generation, manual curation,agentrollouts),differentcomplexity(fromsimpletocomplexmulti-stepworkflows),and diverseenvironments(command-lineinterfaces,webGUIs,JupyterNotebooks,APIcalls). The selected datasets collectively contain over 1.3M instances, ranging from smaller ones like Mind2Web to larger-scale ones like Orca AgentInstruct. To ensure balanced representation across domainsandpreventanysinglelargedatasetfromdominatingthetrainingprocess, wesubsample fromlargerdatasetswhileusingsmallerdatasetsintheirentirety. Fulldetailsofourdatasampling andmixtureweightsareinAppendixB. We use Qwen2.5-7B-Instruct (Qwen Team, 2024) and Qwen3-8B (Yang et al., 2025a) as the base models, with 3 agent frameworks for comprehensive evaluation across multiple benchmarks. We fine-tuned all models using the same SFT pipeline from LLaMA-Factory (Zheng et al., 2024b). These experiments focus on each framework’s specialized domain to demonstrate targeted effec- tiveness. Each agent has unique architectures, tool interfaces, and interaction environments. This diversity allows us to validate that ADP-standardized data can be readily and easily converted to differentagentformats,demonstratingtheprotocol’sutilityacrossvariousagentimplementations. OpenHands(Wangetal.,2025)isanopenplatformforbuildinggeneralistAIagentsthatoperate like software developers: writing code, using command lines, and browsing the web. It provides sandboxedexecutionenvironments,toolcoordination,andbenchmarkevaluation. AgentLab (Drouin et al., 2024; de Chezelles et al., 2025) is an open-source framework for de- veloping, testing, and benchmarking web agents across diverse tasks, emphasizing scalability and reproducibility. ItsupportsasuiteofevaluationbenchmarkslikeWebArenaandWorkArena. SWE-Agent(Yangetal.,2024)introducesacustomAgent-ComputerInterface(ACI)thatenables language model agents to autonomously perform software engineering tasks by navigating code- bases,editingandrunningcode,viewingfiles,andexecutingtests. 5.2 EVALUATIONBENCHMARKS We evaluated these agents across 4 benchmarks (based on the availability of benchmark evalua- tioncodeandspecializationofagents)thatspandifferentdomains. Thiscomprehensiveevaluation demonstratesADP’sexpressivenessinpreservingcriticalinformationacrossdiversetasks. SWE-Bench(Jimenezetal.,2024)evaluatesagentsonreal-worldsoftwareengineeringtasks.Given aGithubcodebaseandabugreport,agentsmustgeneratepatchesthatsatisfyexistingunittests. We usedtheSWE-BenchVerifiedsubsetforevaluation(Chowdhuryetal.,2024). WebArena(Zhouetal.,2024)providesarealistic,self-hostedwebenvironmentcomposedoffully functional websites in domains like e-commerce, forums, and map navigation, requiring agents to interprethigh-levelnaturallanguagecommandsandperformconcretewebinteractions. 7 --- Page 8 --- arXivSubmission AgentBench (Liu et al., 2024b) evaluates agents across different environments, such as operating systems, databases, and web browsing. It emphasizes multi-turn reasoning, decision making, and adaptabilityacrossdomains. GAIA (Mialon et al., 2023) is a benchmark for general AI assistants featuring human-annotated tasksthatcombinereasoning,tooluse,andmulti-stepproblemsolving,oftenwithmultimodalinput. Tasksvaryindifficultybynumberofstepsandrequiredtools. 6 EXPERIMENTAL RESULTS Agent Model TrainingData Accuracy SWE-Bench(Verified)(Jimenezetal.,2024;Chowdhuryetal.,2024) SWE-Agent Qwen-2.5-7B-Coder-Instruct – 0.4% (Yangetal.,2024) Qwen-2.5-7B-Coder-Instruct SWE-smith(Yangetal.,2025b) 15.2%(+14.8%) Claude 3 Opus(AnthropicTeam) – 15.8% Qwen-2.5-7B-Coder-Instruct ADPData 20.2%(+19.8%) OpenHandsCodeActAgent Qwen-2.5-7B-Coder-Instruct – 2.8% (Wangetal.,2025) Qwen-2.5-7B-Coder-Instruct SWE-Gym(Panetal.,2025) 10.6%(+7.8%) Qwen-2.5-7B-Coder-Instruct ADPData 20.4%(+17.6%) WebArena(Zhouetal.,2024) BrowserGym Llama-3.1-8B – 1.0% (deChezellesetal.,2025) Qwen-2.5-7B-Instruct – 8.3% Llama-3.1-8B NNetNav(Murtyetal.,2024) 16.3%(+15.3%) Qwen-2.5-7B-Instruct Go-Browse(Gandhi&Neubig,2025) 21.7%(+13.4%) AgentLab(Drouinetal.,2024) Qwen-2.5-7B-Coder-Instruct – 4.5% (deChezellesetal.,2025) Qwen-2.5-7B-Coder-Instruct ADPData 21.0%(+16.5%) AgentBenchOS(Liuetal.,2024b) AgentLM Llama-2-chat-7B – 8.3% (Liuetal.,2024b) Llama-2-chat-7B AgentInstruct(Zengetal.,2023) 17.4%(+9.1%) OpenHandsCodeActAgent Qwen-2.5-7B-Coder-Instruct – 3.5% (Wangetal.,2025) Qwen-2.5-7B-Coder-Instruct ADPData 27.1%(+23.6%) GAIA(Mialonetal.,2023) OWLAgent(Huetal.,2025) Qwen-2.5-7B-Instruct – 4.8% OpenHandsCodeActAgent Qwen-2.5-7B-Instruct – 7.3% (Wangetal.,2025) Qwen-2.5-7B-Instruct ADPData 9.1%(+1.8%) Table3: ComparisonofSOTAandourBest7–8BADP-trainedagents’resultsacrossbenchmarks. ShadedrowsareourADP-tunedmodels. Agent Model TrainingData Accuracy SWE-Bench(Verified)(Jimenezetal.,2024;Chowdhuryetal.,2024) SWE-Agent Qwen-2.5-14B-Coder-Instruct – 2.0% (Yangetal.,2024) Claude 3.5 Sonnet(AnthropicTeam) – 33.6% Qwen-2.5-14B-Coder-Instruct ADPData 34.4%(+32.4%) OpenHandsCodeActAgent Qwen-2.5-14B-Coder-Instruct – 5.8% (Wangetal.,2025) Qwen-2.5-14B-Coder-Instruct SWE-Gym(Panetal.,2025) 16.4%(+10.6%) Qwen-2.5-14B-Coder-Instruct ADPData 30.6%(+24.8%) WebArena(Zhouetal.,2024) AgentLab(Drouinetal.,2024) Qwen-2.5-14B-Coder-Instruct – 5.5% (deChezellesetal.,2025) Qwen-2.5-14B-Coder-Instruct ADPData 22.2%(+16.7%) AgentBenchOS(Liuetal.,2024b) AgentLM Llama-2-chat-13B – 9.0% (Liuetal.,2024b) Llama-2-chat-13B AgentInstruct(Zengetal.,2023) 18.1%(+9.1%) OpenHandsCodeActAgent Qwen-2.5-14B-Coder-Instruct – 2.8% (Wangetal.,2025) Qwen-2.5-14B-Coder-Instruct ADPData 20.8%(+18.0%) Table4:ComparisonofSOTAandourBest13–14BADP-trainedagents’resultsacrossbenchmarks. ShadedrowsareourADP-tunedmodels. 8 --- Page 9 --- arXivSubmission Agent Model TrainingData Accuracy SWE-Bench(Verified)(Jimenezetal.,2024;Chowdhuryetal.,2024) SWE-Agent Qwen-2.5-32B-Coder-Instruct – 2.2% (Yangetal.,2024) Qwen-2.5-32B-Coder-Instruct SWE-smith(Yangetal.,2025b) 40.2%(+33.7%) Qwen-2.5-32B-Coder-Instruct ADPData 40.3%(+38.1%) OpenHandsCodeActAgent Qwen-2.5-32B-Coder-Instruct – 10.6% (Wangetal.,2025) Qwen-2.5-32B-Coder-Instruct SWE-Gym(Panetal.,2025) 20.6%(+10.0%) Qwen-2.5-32B-Coder-Instruct ADPData 36.8%(+26.2%) WebArena(Zhouetal.,2024) AgentLab(Drouinetal.,2024) Qwen-2.5-32B-Coder-Instruct – 10.9% (deChezellesetal.,2025) Qwen-2.5-32B-Coder-Instruct ADPData 22.9%(+12.0%) AgentBenchOS(Liuetal.,2024b) AgentLM Llama-2-chat-70B – 9.0% (Liuetal.,2024b) Llama-2-chat-70B AgentInstruct(Zengetal.,2023) 21.5%(+12.5%) OpenHandsCodeActAgent Qwen-2.5-32B-Coder-Instruct – 27.8% (Wangetal.,2025) Qwen-2.5-32B-Coder-Instruct ADPData 34.7%(+6.9%) Table 5: Comparison of SOTA and our Best 32B ADP-trained agents’ results across benchmarks. ShadedrowsareourADP-tunedmodels. 6.1 ADPDATARESULTSINHIGHLYEFFECTIVEAGENTSACROSSDIVERSETASKS ADP fine-tuning consistently improves performance across models, benchmarks, and agent harnesses. As shown in Table 3, Table 4, and Table 5, training on standard- ized ADP data yields substantial gains across 7B, 14B, and 32B models on several popu- lar evaluation benchmarks. On SWE-Bench (Verified), ADP training delivers remarkable im- provements: Qwen-2.5-7B-Coder-Instruct improves from 0.4% to 20.2% (+19.8%) with SWE-Agent and from 2.8% to 20.4% (+17.6%) with OpenHands. At 14B scale, Qwen-2.5-14B-Coder-Instruct achieves 34.4% (+32.4%) with SWE-Agent and 30.6% (+24.8%)withOpenHands. The32Bmodelreaches40.3%(+38.1%)withSWE-Agentand36.8% (+26.2%) with OpenHands, matching or exceeding Claude 3.5 Sonnet with SWE-Agent’s 33.6% performance. OnWebArena,ADPtrainingshowsconsistentgainsacrossmodelsizes: 7Bachieves 21.0%(+16.5%),14Breaches22.2%(+16.7%),and32Battains22.9%(+12.0%). OnAgentBench OS,theimprovementsaresubstantial: the7Bmodelimprovesfrom3.5%to27.1%(+23.6%), the 14Bmodelimprovesfrom2.8%to20.8%(+18.0%),and32Bmodelsfrom27.8%to34.7%(+6.9%). Finally,onGAIA,the7Bmodelimprovesfrom7.3%to9.1%(+1.8%). 45 40 35 30 25 20 15 10 5 0 7B 14B 32B Model Size (Billions of Parameters) )%( ecnamrofreP 45 ADP-Trained Models SWE-Agent ADP (SWE-Bench) OpenHands ADP (SWE-Bench) 40.3% 40 AgentLab ADP (WebArena) 36.8% 35 34.4% 30.6% 30 22.2% 22.9% 25 20.4%21.0% 20.2% 20 Base Models 15 SWE-Agent Base (SWE-Bench) 10.9% OpenHands Base (SWE-Bench) AgentLab Base (WebArena) 10.6% 10 5.5% 4.5% 5.8% 5 2.0% 2.2% 2.08.%4% 0 7B 14B 32B Model Size (Billions of Parameters) Figure 3: Performance Scaling Across Agents andBenchmarks(BasevsADPTrained) )%( secnamrofreP deniarT-PDA dna esaB neewteB atleD Models SWE-Agent ADP (SWE-Bench) OpenHands ADP (SWE-Bench) AgentLab ADP (WebArena) 38.1% 32.4% 26.2% 24.8% 17.6%1 19 6. .8 5% % 16.7% 12.0% Figure 4: Performance Gains Across Agents andBenchmarks. These gains, spanning both coding and browsing settings, show that a unified, cross-domain ADP training corpus can deliver SOTA or near-SOTA performance without domain-specific tuning and is effective across models, action spaces, and agent harnesses. Figure 3 and Figure 4 show clear monotonicgainswithmodelsizeandconsistentboostsfromADPtrainingacrossagentsandtasks, withADP-trainedmodelsoutperformingtheirbasecounterpartsateveryscale. 9 --- Page 10 --- arXivSubmission 6.2 DIVERSEDATARESULTSINCROSS-TASKTRANSFER Agent Model TrainingData Accuracy SWE-Bench(Verified)(Jimenezetal.,2024;Chowdhuryetal.,2024) OpenHandsCodeActAgent Qwen-2.5-7B-Instruct SWE-smithOnly 1.0% (Wangetal.,2025) Qwen-2.5-7B-Instruct ADPData 10.4% Qwen-3-8B CodeActInstruct+Code-Feedback 0.2% Qwen-3-8B SWE-smithOnly 11.0% Qwen-3-8B ADPData 16.6% WebArena(Zhouetal.,2024) AgentLab(Drouinetal.,2024) Qwen-2.5-7B-Instruct Go-BrowseOnly 16.0% (deChezellesetal.,2025) Qwen-2.5-7B-Instruct ADPData 20.1% AgentBenchOS(Liuetal.,2024b) OpenHandsCodeActAgent Qwen-3-8B AgentInstructOnly 21.5% (Wangetal.,2025) Qwen-3-8B ADPData 25.7% GAIA(Mialonetal.,2023) OpenHandsCodeActAgent Qwen-2.5-7B-Instruct AgentInstructOnly 0.6% (Wangetal.,2025) Qwen-2.5-7B-Instruct ADPData 9.1% Table 6: Cross-task transfer with diverse vs. task-specific data. For each benchmark, we compare thesameharness+modelundertask-specific“only”tuningandtrainingonADPcorpus. Westudywhetherdatadiversityhelpsagentsgeneralizeacrosstasks. Holdingtheagentsetupand evaluationfixed, wecomparetrainingwithdifferentdatamixtures: (i)Base(notuning), (ii)Task- specific only fine-tuning (e.g., SWE-smith Only, etc.), and (iii) ADP Data (as detailed in § 5), a mixed, cross-domain corpus. As shown in Table 6, ADP consistently outperforms task-specific tuningonthetargettaskand,critically,avoidsthenegativetransferthatsingle-domaintuning ofteninducesonothertasks(Muelleretal.,2024;Kothaetal.,2024;Lietal.,2024). Concretely,onSWE-Bench,trainingQwen-2.5-7B-InstructwithADPdataachieves10.4%, versus 1.0% with SWE-smith Only; for Qwen-3-8B, ADP reaches 16.6% versus 0.2% with CodeActInstruct + Code-Feedback and 11.0% with SWE-smith Only. On WebArena, ADP trained Qwen-2.5-7B-Instructattains20.1%comparedto16.0%withGo-BrowseOnly. OnAgent- Bench OS, ADP lifts Qwen-3-8B to 25.7% versus 21.5% with AgentInstruct Only. Finally, on GAIA,AgentInstructOnlyresultsin0.6%accuracy,whileADPimprovesitto9.1%.Overall,mixed ADP training yields better in-domain accuracy and stronger cross-task generalization than single- domaintuning. 6.3 ADPEASESADAPTATIONTONEWAGENTHARNESSES Table7: LOCforconvertingdatasetstoADP. Table7demonstratesthelinesofcode(LOC)3 the authors and community contributors used Dataset TotalLOC to convert 13 datasets from distinct sources AgentInstruct ∼1500 to the ADP schema. A single Raw→ADP Code-Feedback 134 converter per dataset performs the same nor- CodeActInstruct 269 malization work (schema mapping, tool/action Go-Browse 335 alignment, conversation formatting) that a tra- Mind2Web 476 NebiusSWE-AgentTrajectories 260 ditional Raw→SFT converter would do for a NNetNav(live+wa) 290 specific agent harness. Therefore, LOC statis- openhands-feedback 879 tics in Table 7 are a reasonable proxy for the OrcaAgentInstruct 155 per-agentharnesseffortwithoutADP. SWE-Gym 221 SWE-smith 228 Without ADP. Using this proxy, the cost of Synatra 145 converting D-many datasets to A-many har- nesses without ADP is Cost (A,D) ≈ Total 4892 no-ADP A·(cid:80)D LOC . Thus the total con- i=0 i,Raw→ADP versioncostacrossthecommunityisquadratic(O(D×A)effort),asdepictedinFigure2. Inour 3AllLOCexcludeprompttext(e.g.,systemprompts);onlyconvertercodeiscounted. 10 --- Page 11 --- arXivSubmission data,(cid:80)D LOC =4892LOCacross13datasets,soforA=100harnessesthetotalcost i=0 i,Raw→ADP isCost ≈100×4892=489,200LOC. no-ADP With ADP. The total cost becomes Cost (A,D) ≈ ADP Table8:LOCforADP→SFTconverters. (cid:80)D LOC + (cid:80)A LOC with AgentHarness TotalLOC i=0 i,Raw→ADP j=0 ADP→SFT,j ADP. Thus, as shown in Figure 2, the total conver- OpenHandsCodeActAgent ∼150 sion cost across the community now becomes linear SWE-Agent ∼50 with ADP (O(D + A) effort). Table 8 demonstrates AgentLab ∼30 thatconvertingADPstandardizeddatatoagentharness Average ∼77 format takes an average of 77 LOC. For A = 100, Cost (A,D) ≈ 4892+77×100 = 12,592across ADP the 13 datasets we used, greatly less than the no-ADP setting. Additionally, adding a new harness only require writing one script converting ADP stan- dardizeddatatoSFT,greatlyeasingadaptationtonewagentharnesses. Hence,ADPsubstantially reducesthecommunity’scollectiveeffortrequiredtodevelopscalable,reproducibleagents. 7 CONCLUSION AND FUTURE WORK ADP provides a practical, lightweight “interlingua” that unifies heterogeneous agent datasets into a single schema consumable by many agent harnesses, turning today’s fragmented data landscape into a scalable training pipeline. Looking ahead, we see three immediate directions. (i) Multi- modality:extendingADPbeyondtexttoimages,screenrecordings,andothermodalitiestocapture richeragent–environmentinteractions. (ii)Standardizedevaluationartifacts: applyingthesame standardized “protocol” idea to evaluation and environment settings so that datasets, agents, and evaluationscomposecleanly. (iii)Communitygrowthanddataquality: continuingopen-source releases,strongerautomatedvalidationorevenautomateddatasetconversion,tosustainscalewhile preservingquality. Webelievethat,byloweringintegrationcostsandenablingsystematicandscal- abletrainingandanalysisacrosssources,ADPcancatalyzethenextwaveofagent-trainingresearch andpractice. REPRODUCIBILITY STATEMENT. Weprovideclearpointerstoenableindependentreproductionofallresults. WedescribetheADP schema and conversion pipeline (§ 3), allowing others to regenerate the training corpus from raw sources. We list the datasets and their characteristics in § 2.1. The exact training and evaluation setup-including base models, agent harnesses, our SFT pipeline, the evaluation benchmarks and protocol-is specified in § 5. Finally, we will release all code and data open source, including the ADPschemas,converters,andscriptsreferencedabove. REFERENCES All Hands AI. Openhands feedback dataset.  all-hands/openhands-feedback,2024. Anthropic Team. The claude 3 model family: Opus, sonnet, haiku. URL  semanticscholar.org/CorpusID:268232499. Eshta Bhardwaj, Harshit Gujral, Siyi Wu, Ciara Zogheib, Tegan Maharaj, and Christoph Becker. Machinelearningdatapracticesthroughadatacurationlens: Anevaluationframework. FAccT ’24, pp.1055–1067, NewYork, NY,USA,2024.AssociationforComputingMachinery. ISBN 9798400704505. doi: 10.1145/3630106.3658955. URL  3630106.3658955. Zehui Chen, Kuikun Liu, Qiuchen Wang, Wenwei Zhang, Jiangning Liu, Dahua Lin, Kai Chen, and Feng Zhao. Agent-FLAN: Designing data and methods of effective agent tuning for large languagemodels. InLun-WeiKu,AndreMartins,andVivekSrikumar(eds.),FindingsoftheAs- sociationforComputationalLinguistics: ACL2024,pp.9354–9366,Bangkok,Thailand,August 2024.AssociationforComputationalLinguistics. doi: 10.18653/v1/2024.findings-acl.557. URL  11 --- Page 12 --- arXivSubmission NeilChowdhury,JamesAung,ChanJunShern,OliverJaffe,DaneSherburn,GiulioStarace,Evan Mays,RachelDias,MarwanAljubeh,MiaGlaese,etal.Introducingswe-benchverified.https: //openai.com/index/introducing-swe-bench-verified,2024. Thibault Le Sellier de Chezelles, Maxime Gasse, Alexandre Lacoste, Massimo Caccia, Alexan- dre Drouin, Le´o Boisvert, Megh Thakkar, Tom Marty, Rim Assouel, Sahar Omidi Shayegan, Lawrence Keunho Jang, Xing Han Lu`, Ori Yoran, Dehan Kong, Frank F. Xu, Siva Reddy, Gra- ham Neubig, Quentin Cappart, Russ Salakhutdinov, and Nicolas Chapados. The browsergym ecosystem for web agent research. Transactions on Machine Learning Research, 2025. ISSN 2835-8856. URL ExpertCertifi- cation. XiangDeng,YuGu,BoyuanZheng,ShijieChen,SamStevens,BoshiWang,HuanSun,andYuSu. Mind2web: Towardsageneralistagentfortheweb. AdvancesinNeuralInformationProcessing Systems,36:28091–28114,2023. Alexandre Drouin, Maxime Gasse, Massimo Caccia, Issam H. Laradji, Manuel Del Verme, Tom Marty, David Vazquez, Nicolas Chapados, and Alexandre Lacoste. WorkArena: How capa- ble are web agents at solving common knowledge work tasks? In Ruslan Salakhutdinov, Zico Kolter, KatherineHeller, AdrianWeller, NuriaOliver, JonathanScarlett, andFelixBerkenkamp (eds.), Proceedings of the 41st International Conference on Machine Learning, volume 235 of Proceedings of Machine Learning Research, pp. 11642–11662. PMLR, 21–27 Jul 2024. URL  ApurvaGandhiandGrahamNeubig. Go-browse: Trainingwebagentswithstructuredexploration. arXivpreprintarXiv:2506.03533,2025. Alexander Golubev, Sergey Polezhaev, Karina Zainullina, Maria Trofimova, Ibragim Badert- dinov, Yury Anapolskiy, Daria Litvintseva, Simon Karasik, Filipp Fisin, Sergey Skvortsov, Maxim Nekrashevich, Anton Shevtsov, Sergey Abramov, and Boris Yangel. Leverag- ing training and search for better software engineering agents. Nebius blog, 2024.  MengkangHu,YuhangZhou,WendongFan,YuzhouNie,BoweiXia,TaoSun,ZiyuYe,Zhaoxuan Jin,YingruLi,QiguangChen,ZeyuZhang,YifengWang,QianshuoYe,BernardGhanem,Ping Luo, and Guohao Li. Owl: Optimized workforce learning for general multi-agent assistance in real-worldtaskautomation,2025. URL CarlosEJimenez,JohnYang,AlexanderWettig,ShunyuYao,KexinPei,OfirPress,andKarthikR Narasimhan. SWE-bench:Canlanguagemodelsresolvereal-worldgithubissues? InTheTwelfth InternationalConferenceonLearningRepresentations,2024. URL net/forum?id=VTF8yNQM66. RaghavKapoor,YashParagButala,MelisaRussak,JingYuKoh,KiranKamble,WaseemAlShikh, andRuslanSalakhutdinov.Omniact:Adatasetandbenchmarkforenablingmultimodalgeneralist autonomousagentsfordesktopandweb. InEuropeanConferenceonComputerVision,pp.161– 178.Springer,2024. SuhasKotha,JacobMitchellSpringer,andAditiRaghunathan. Understandingcatastrophicforget- tinginlanguagemodelsviaimplicitinference.InTheTwelfthInternationalConferenceonLearn- ingRepresentations,2024. URL HongyuLi,LiangDing,MengFang,andDachengTao. Revisitingcatastrophicforgettinginlarge languagemodeltuning.InYaserAl-Onaizan,MohitBansal,andYun-NungChen(eds.),Findings oftheAssociationforComputationalLinguistics:EMNLP2024,pp.4297–4308,Miami,Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024. findings-emnlp.249. URL  249/. ShilongLiu,HaoCheng,HaotianLiu,HaoZhang,FengLi,TianheRen,XueyanZou,JianweiYang, Hang Su, Jun Zhu, et al. Llava-plus: Learning to use tools for creating multimodal agents. In Europeanconferenceoncomputervision,pp.126–142.Springer,2024a. 12 --- Page 13 --- arXivSubmission Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, KaiwenMen, KejuanYang, ShudanZhang, XiangDeng, AohanZeng, ZhengxiaoDu, Chenhui Zhang,ShengShen,TianjunZhang,YuSu,HuanSun,MinlieHuang,YuxiaoDong,andJieTang. Agentbench: EvaluatingLLMsasagents. InTheTwelfthInternationalConferenceonLearning Representations,2024b. URL XingHanLu`,ZdeneˇkKasner,andSivaReddy. Weblinx:Real-worldwebsitenavigationwithmulti- turndialogue. arXivpreprintarXiv:2402.05930,2024. Junyu Luo, Weizhi Zhang, Ye Yuan, Yusheng Zhao, Junwei Yang, Yiyang Gu, Bohan Wu, Binqi Chen,ZiyueQiao,QingqingLong,etal. Largelanguagemodelagent:Asurveyonmethodology, applicationsandchallenges. arXivpreprintarXiv:2503.21460,2025. Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma,QingweiLin,andDaxinJiang. Wizardcoder: Empoweringcodelargelanguagemodelswith evol-instruct. arXivpreprintarXiv:2306.08568,2023. Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. Learningwordvectorsforsentimentanalysis. InProceedingsofthe49thAnnualMeeting oftheAssociationforComputationalLinguistics: HumanLanguageTechnologies,pp.142–150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics. URL http: //www.aclweb.org/anthology/P11-1015. Tula Masterman, Sandi Besen, Mason Sawtell, and Alex Chao. The landscape of emerging ai agent architectures for reasoning, planning, and tool calling: A survey. arXiv preprint arXiv:2404.11584,2024. Gre´goire Mialon, Cle´mentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a benchmark for general ai assistants. In The Twelfth International Conference on Learning Representations,2023. ArindamMitra,LucianoDelCorro,GuoqingZheng,ShwetiMahajan,DanyRouhana,AndresCo- das,YadongLu,Wei-geChen,OlgaVrousgos,CorbyRosset,etal. Agentinstruct: Towardgen- erativeteachingwithagenticflows. arXivpreprintarXiv:2407.03502,2024. MahmoudMohammadi,YipengLi,JaneLo,andWendyYip. Evaluationandbenchmarkingofllm agents:Asurvey. InProceedingsofthe31stACMSIGKDDConferenceonKnowledgeDiscovery andDataMiningV.2,pp.6129–6139,2025. DavidMueller,MarkDredze,andNicholasAndrews.Multi-tasktransfermattersduringinstruction- tuning. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Findings of the Associa- tion for Computational Linguistics: ACL 2024, pp. 14880–14891, Bangkok, Thailand, August 2024.AssociationforComputationalLinguistics. doi: 10.18653/v1/2024.findings-acl.883. URL  Shikhar Murty, Hao Zhu, Dzmitry Bahdanau, and Christopher D Manning. Nnetnav: Unsuper- vised learning of browser agents through environment interaction in the wild. arXiv preprint arXiv:2410.02907,2024. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christo- pherHesse,ShantanuJain,VineetKosaraju,WilliamSaunders,etal. Webgpt: Browser-assisted question-answeringwithhumanfeedback. arXivpreprintarXiv:2112.09332,2021. Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, andCaimingXiong. Codegen: Anopenlargelanguagemodelforcodewithmulti-turnprogram synthesis. ICLR,2023. Liangbo Ning, Ziran Liang, Zhuohang Jiang, Haohao Qu, Yujuan Ding, Wenqi Fan, Xiao-yong Wei, Shanru Lin, Hui Liu, Philip S Yu, et al. A survey of webagents: Towards next-generation ai agents for web automation with large foundation models. In Proceedings of the 31st ACM SIGKDDConferenceonKnowledgeDiscoveryandDataMiningV.2,pp.6140–6150,2025. 13 --- Page 14 --- arXivSubmission Tianyue Ou, Frank F. Xu, Aman Madaan, Jiarui Liu, Robert Lo, Abishek Sridhar, Sudipta Sen- gupta,DanRoth,GrahamNeubig,andShuyanZhou. Synatra: Turningindirectknowledgeinto direct demonstrations for computer agents at scale. In Conference on Neural Information Pro- cessing Systems (NeurIPS), Vancouver, BC, December 2024. URL  abs/2409.15637. JiayiPan,XingyaoWang,GrahamNeubig,NavdeepJaitly,HengJi,AlaneSuhr,andYizheZhang. TrainingsoftwareengineeringagentsandverifierswithSWE-gym. InForty-secondInternational Conference on Machine Learning, 2025. URL  Cq1BNvHx74. AmandalynnePaullada,InioluwaDeborahRaji,EmilyMBender,EmilyDenton,andAlexHanna. Dataandits(dis)contents:Asurveyofdatasetdevelopmentanduseinmachinelearningresearch. Patterns,2(11),2021. I Made Putrama and Pe´ter Martinek. Heterogeneous data integration: Challenges and opportu- nities. Data in Brief, 56:110853, 2024. ISSN 2352-3409. doi:  2024.110853. URL  S2352340924008175. QwenTeam.Qwen2.5:Apartyoffoundationmodels,September2024.URL github.io/blog/qwen2.5/. PranavRajpurkar,JianZhang,KonstantinLopyrev,andPercyLiang. SQuAD:100,000+questions formachinecomprehensionoftext.InProceedingsofthe2016ConferenceonEmpiricalMethods inNaturalLanguageProcessing,pp.2383–2392,Austin,Texas,November2016.Associationfor Computational Linguistics. doi: 10.18653/v1/D16-1264. URL  org/D16-1264. Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva, and Timothy Lillicrap. An- droidinthewild: Alarge-scaledatasetforandroiddevicecontrol. AdvancesinNeuralInformation ProcessingSystems,36:59708–59728,2023. Timo Schick, Jane Dwivedi-Yu, Roberto Dess`ı, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems, 36:68539– 68551,2023. YifanSong,WeiminXiong,XiutianZhao,DaweiZhu,WenhaoWu,KeWang,ChengLi,WeiPeng, and Sujian Li. AgentBank: Towards generalized LLM agents via fine-tuning on 50000+ inter- actiontrajectories. InYaserAl-Onaizan,MohitBansal,andYun-NungChen(eds.),Findingsof the Association for Computational Linguistics: EMNLP 2024, pp. 2124–2141, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024. findings-emnlp.116. URL  116/. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language mod- els. Transactions on Machine Learning Research, 2024a. ISSN 2835-8856. URL https: //openreview.net/forum?id=ehfRiF0R3a. XingyaoWang,YangyiChen,LifanYuan,YizheZhang,YunzhuLi,HaoPeng,andHengJi. Exe- cutablecodeactionselicitbetterllmagents. InForty-firstInternationalConferenceonMachine Learning,2024b. XingyaoWang, BoxuanLi, YufanSong, Frank F.Xu, Xiangru Tang, MingchenZhuge, Jiayi Pan, YueqiSong,BowenLi,JaskiratSingh,HoangH.Tran,FuqiangLi,RenMa,MingzhangZheng, Bill Qian, Yanjun Shao, Niklas Muennighoff, Yizhe Zhang, Binyuan Hui, Junyang Lin, Robert Brennan, Hao Peng, Heng Ji, and Graham Neubig. Openhands: An open platform for AI soft- ware developers as generalist agents. In The Thirteenth International Conference on Learning Representations,2025. URL 14 --- Page 15 --- arXivSubmission Zhiheng Xi, Yiwen Ding, Wenxiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Xin Guo, Dingwen Yang, Chenyang Liao, Wei He, Songyang Gao, Lu Chen, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, and Yu-Gang Jiang. Agent- Gym: Evaluating and training large language model-based agents across diverse environments. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar (eds.), Proceedingsofthe63rdAnnualMeetingoftheAssociationforComputationalLinguistics(Vol- ume 1: Long Papers), pp. 27914–27961, Vienna, Austria, July 2025. Association for Compu- tational Linguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v1/2025.acl-long.1355. URL  Kevin Xu, Yeganeh Kordi, Tanay Nayak, Adi Asija, Yizhong Wang, Kate Sanders, Adam Byerly, JingyuZhang,BenjaminVanDurme,andDanielKhashabi.Tur[k]ingbench:Achallengebench- markforwebagents. arXivpreprintarXiv:2403.11905,2024a. Yiheng Xu, Dunjie Lu, Zhennan Shen, Junli Wang, Zekun Wang, Yuchen Mao, Caiming Xiong, andTaoYu. Agenttrek: Agenttrajectorysynthesisviaguidingreplaywithwebtutorials. arXiv preprintarXiv:2412.09605,2024b. An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388,2025a. JohnYang, CarlosEJimenez, AlexanderWettig, KilianLieret, ShunyuYao, KarthikNarasimhan, and Ofir Press. Swe-agent: Agent-computer interfaces enable automated software engineering. AdvancesinNeuralInformationProcessingSystems,37:50528–50652,2024. John Yang, Kilian Leret, Carlos E Jimenez, Alexander Wettig, Kabir Khandpur, Yanzhe Zhang, BinyuanHui,OfirPress,LudwigSchmidt,andDiyiYang. Swe-smith: Scalingdataforsoftware engineeringagents. arXivpreprintarXiv:2504.21798,2025b. Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. Webshop: Towards scalable real-worldwebinteractionwithgroundedlanguageagents. AdvancesinNeuralInformationPro- cessingSystems,35:20744–20757,2022a. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan Cao. React: Synergizingreasoningandactinginlanguagemodels. InTheeleventhinternational conferenceonlearningrepresentations,2022b. AohanZeng,MingdaoLiu,RuiLu,BowenWang,XiaoLiu,YuxiaoDong,andJieTang. Agenttun- ing: Enablinggeneralizedagentabilitiesforllms. arXivpreprintarXiv:2310.12823,2023. Daochen Zha, Zaid Pervaiz Bhat, Kwei-Herng Lai, Fan Yang, Zhimeng Jiang, Shaochen Zhong, andXiaHu. Data-centricartificialintelligence: Asurvey. ACMComputingSurveys,57(5):1–42, 2025. Jianguo Zhang, Tian Lan, Rithesh Murthy, Zhiwei Liu, Weiran Yao, Ming Zhu, Juntao Tan, Thai Hoang,ZuxinLiu,LiangweiYang,etal. Agentohana: Designunifieddataandtrainingpipeline foreffectiveagentlearning. arXivpreprintarXiv:2402.15506,2024. Jianguo Zhang, Tian Lan, Ming Zhu, Zuxin Liu, Thai Quoc Hoang, Shirley Kokane, Weiran Yao, Juntao Tan, Akshara Prabhakar, Haolin Chen, Zhiwei Liu, Yihao Feng, Tulika Manoj Awal- gaonkar, Rithesh R N, Zeyuan Chen, Ran Xu, Juan Carlos Niebles, Shelby Heinecke, Huan Wang, Silvio Savarese, and Caiming Xiong. xLAM: A family of large action models to em- power AI agent systems. In Luis Chiruzzo, Alan Ritter, and Lu Wang (eds.), Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computa- tionalLinguistics: HumanLanguageTechnologies(Volume1: LongPapers),pp.11583–11597, Albuquerque, NewMexico, April2025.AssociationforComputationalLinguistics. ISBN979- 8-89176-189-6. doi: 10.18653/v1/2025.naacl-long.578. URL  org/2025.naacl-long.578/. 15 --- Page 16 --- arXivSubmission Tianyu Zheng, Ge Zhang, Tianhao Shen, Xueling Liu, Bill Yuchen Lin, Jie Fu, Wenhu Chen, and Xiang Yue. OpenCodeInterpreter: Integrating code generation with execution and refine- ment. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Findings of the Associa- tion for Computational Linguistics: ACL 2024, pp. 12834–12859, Bangkok, Thailand, August 2024a.AssociationforComputationalLinguistics.doi:10.18653/v1/2024.findings-acl.762.URL  Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, Zhangchi Feng, and Yongqiang Ma. Llamafactory: Unified efficient fine-tuning of 100+ language models. In Pro- ceedingsofthe62ndAnnualMeetingoftheAssociationforComputationalLinguistics(Volume 3: SystemDemonstrations),Bangkok,Thailand,2024b.AssociationforComputationalLinguis- tics. URL Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, Uri Alon, and Graham Neubig. Webarena: A real- istic web environment for building autonomous agents. In The Twelfth International Confer- ence on Learning Representations, 2024. URL  oKn9c6ytLx. A USE OF LLMS WeusedLLMstoaidandpolishwritingforstyleandpresentation. Specifically,LLMswereemployedto: • polishwording,tightenparagraphs,andimproveclarity/flow; • improvelatexpresentation(e.g.,table/figurecaptions) B DATA SAMPLING FOR BALANCED TRAINING To balance domains and reduce over-represented sources, we resample each dataset with a per- datasetmultiplierw . Fordatasetdwithn rawtrajectories,wedrawm =⌈w n ⌉examplesper d d d d d epoch; if w < 1 we sample without replacement (downsample), and if w > 1 we sample with d d replacement (upsample). This yields an effective mixture proportional to w across datasets (and d thereforeacrossdomains),whilekeepingtheoverallepochsizestable. Table9: Per-datasetsamplingmultipliersw . w < 1indicatesdownsampling; w > 1indicates d d d upsampling. Dataset w Direction d agenttuning alfworld 2 up agenttuning db 2 up agenttuning kg 2 up agenttuning mind2web 2 up agenttuning os 2 up agenttuning webshop 2 up code feedback 0.1 down codeactinstruct 1 neutral go-browse-wa 1 neutral mind2web 1 neutral nebius SWE-agent-trajectories 1 neutral nnetnav-live 1 neutral nnetnav-wa 1 neutral openhands 1 neutral orca agentinstruct 0.001 down swe-gym openhands sampled trajectories 3 up swe-smith 1 neutral synatra 0.01 down 16 --- Page 17 --- arXivSubmission In practice, we fix a random seed for reproducibility and shuffle the union of sampled examples across datasets each epoch. This scheme targets a more balanced distribution across coding, SWE, tool-use, and web-browsing sources by attenuating very large corpora (e.g., orca agentinstruct at w =0.001) and amplifying under-represented ones (e.g., d swe-gym openhands sampled trajectoriesatw =3). d B.1 DOMAIN-SPECIFICDATAFILTERING Beyondbalancedsampling,weapplydomain-specificfilteringtooptimizetrainingeffectivenessfor eachagentframeworkbasedontheirevaluationfocusandcapabilities. OpenHands and SWE-Agent Training Data. For OpenHands CodeActAgent and SWE-Agent, whichareprimarilyevaluatedoncodingandsoftwareengineeringtasks(SWE-Bench,AgentBench OS,andGAIA),weuseonlythenon-webportionoftheADPtrainingcorpus.Thisincludesdatasets focusedoncodegeneration,softwareengineering,generalagentinstructionfollowing,andAPI/tool usage. Specifically, we exclude web browsing datasets Mind2Web, Go-Browse, NNetNav, and Synatratoavoidpotentialinterferencefromweb-specificinteractionpatternsthatarenotapplicable tocommand-lineandcodingenvironments. AgentLabTrainingData. ForAgentLab,whichisdesignedforwebbrowsingtasksandweevalu- atedexclusivelyitonWebArena,weuseonlythewebportionoftheADPtrainingcorpus. Thisin- cludesdatasetsfocusedonwebnavigation,browser-basedtaskcompletion,andweb-specificagent instruction following (Mind2Web, Go-Browse, NNetNav, and Synatra). We exclude coding and software engineering datasets to ensure the model is optimized for web browsing patterns and UI elementinteractionwithoutdilutionfromlesscompatibledomains. 17