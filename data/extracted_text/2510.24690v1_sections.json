{
  "abstract": "Abstract Wepresentaframeworkforuncoveringandexploitingdependenciesamongtools anddocumentstoenhanceexemplarartifactgeneration. Ourmethodbeginsby constructingatoolknowledgegraphfromtoolschemas\u2014includingdescriptions, arguments, and output payloads\u2014using a DeepResearch-inspired analysis. In parallel,wederiveacomplementaryknowledgegraphfrominternaldocuments andSOPs,whichisthenfusedwiththetoolgraph. Togenerateexemplarplans,we adoptadeep\u2013sparseintegrationstrategythatalignsstructuraltooldependencies withproceduralknowledge. Experimentsdemonstratethatthisunifiedframework effectivelymodelstoolinteractionsandimprovesplangeneration,underscoringthe benefitsoflinkingtoolgraphswithdomainknowledgegraphsfortool-augmented reasoningandplanning.",
  "introduction": "1 Introduction LargeLanguageModels(LLMs)([1,2,3,17,25])haveplayedacentralroleindrivingprogress inartificialintelligence,yieldingmajoradvancesacrossawiderangeofdomains. Akeystrength ofLLMsliesintheirplanningabilitiesandtheircapacityfortooluse([23,24]),whichallowthem notonly toexecute instructionsandcarryout webqueriesbutalsotosignificantly enhancetheir mathematicalreasoningskills. LLMCompiler[9]andsubsequentstudies([5,6])proposemodeling toolinteractionsasdirectedacyclicgraphs(DAGs),enablingtheparallelexecutionofindependent toolsandtherebyimprovingefficiencyintoolcalling. CodeAct[18]andCodePlan[19]advocatefor generatingpseudo-Pythoncodeasameansofstructuringhigh-levelreasoningsteps,whereeachtool invocationisexpressedasafunctioncall. ReWOO[20]introducesamodularapproachthatseparates thereasoningworkflowfromexternalobservationsoftooloutputs,whichreducestokenusageand improvesefficiency. [10]groupstoolsintoclusters,plansatthetoolkitlevel,andperformsreplanning withinthesametoolkitwhenerrorsoccur. [11]presentsPredictive-Decoding,atechniqueinspired by Model Predictive Control, designed to mitigate early-stage errors and encourage non-myopic planning,ultimatelyimprovingaccuracy. ReasonFlux[22]outlinesaframeworkwheretheLLM reasons over template slots, executes tools through these templates, and employs reinforcement learningwithactioncompletionrewardstorefineplanningaccuracy. Intheagenticparadigm,LLMsaretransitioningfrompurelytext-basedreasoningtowarddynamic agents capable of planning, tool usage, and multi-step (including multi-turn) execution. ToolRL [13]providesasystematicstudyofreinforcementlearningrewarddesign\u2014examininggranularity, temporalstructure,andsignaltypes\u2014toenhancegeneralizationinmulti-turn,tool-integratedrea- soning. KimiK2[16]demonstratesthatstabilizinglong-contexttrainingcombinedwithmulti-stage 39thConferenceonNeuralInformationProcessingSystems(NeurIPS2025)Workshop:. 5202 tcO 82 ]IA.sc[ 1v09642.0152:viXra --- Page 2 --- RLenablesstrongperformanceacrossmulti-roundtasksinsoftwareengineering,mathematics,and agenticreasoning. Priorworkontool-usingcapabilitieshaslargelycenteredongeneral-purposetools[14],suchassend emailandmakecalendar,aswellaswebsearchfunctionalitiesexemplifiedbysystemslikeManus. Thesetoolsaretypicallyuni-functional,designedtoperformasingleactionoranswerasinglequery, withdescriptionsandargumentstructuresthatarestraightforwardforLLMssuchasGPT-4o[12]and Claude3.5tointerpret. Incontrast,thetoolsrequiredbyreal-worldbusinessassistants\u2014covering areassuchasinventorytracking, performancemonitoring, andfinancialreporting\u2014arefarmore complexanddomain-specific,posingsignificantchallengesforgeneral-purposeLLMstoparseand utilizeeffectively. Toaddressthisgap,in-contextplanning(ICP)hasemergedasacommonstrategy, whereexemplarAPIexecutionsareprovidedtoLLMstoguideplangeneration. Generatinghigh-qualityin-contextplanningexemplarsisessential,asirrelevantorpoorlychosen examplescanmisguidetheLLMandleadtosuboptimalorerroneousplans[26]. Forabusiness assistantthatmustinitiallyoperateoverhundredsofin-domaintools,obtainingsufficientandhigh- qualityexemplarsiscrucialforovercomingthecold-startprobleminin-contextplanningandensuring reliablefunctionality. Therefore,itishighlyimportanttoautomaticallyconstructatoolknowledge graphthatcapturesthedependenciesamongtoolsandlinksthemtointernaldocumentsorSOPs, whichprovidethecorrespondingusageinstructions. Insummary,thisworkmakesseveralpivotalcontributions: \u2022 We propose a Deep Research approach [21] to explore tool schemas\u2014including descriptions, arguments,andoutputpayloads\u2014inordertouncoverdependenciesamongtoolsandconstructa toolknowledgegraph. \u2022 We further model internal documents and SOPs containing tool usage instructions as a knowl- edgegraphviaGraphRAG[4],andintegratethiswiththetoolgraphthroughknowledgegraph fusion. Basedonthisfusiongraph,weproposeaDense-sparseintegrationframeworkfollowing HippoRAG2forexemplarplangeneration. \u2022 Experimentalresultsvalidatetheeffectivenessofstudyingtooldependencieswithdeepresearch anddemonstratetheusefulnessofconnectingtoolgraphswithdocumentknowledgegraphs. 2",
  "methods": "METHODOLOGY Inthissection,wedescribehowtoadaptDeepResearch\u2014originallydevelopedforwebsearchand reportgeneration\u2014tothetaskofexploringdependenciesamongtoolsusingtheirschemas. Wethen proposeanappropriatedatastructuretorepresentandstorethesedependencies. Next,weexplain howGraphRAGcanbeleveragedtoconstructadomainknowledgegraphfrominternaldocuments, andhowthetwographscanbeintegratedthroughknowledgefusion. 2.1 ToolGraphConstruction We modify the node in Deep Research original pipeline (web-search and then refine with LLM feedback)intodependencyextractionandthenuseLLMasajudge[7]tocheckiftheidentifiedthe dependencyreallymakessenseinthesensewedeletethosewhichshouldnotformthedependency perin-domainspecificrequirements. WhensendpairwisetoolstoLLMandletitcheckthetools description,inputargumentsandalsotheoutputpayload. Theextracteddependencydatastructureis showninFigure2. ThepipelineiswritteninLangGraph. 2.2 FusionofToolGraphandDomainKnowledgeGraph Wefirstconstructthedomainknowledgegraph,alignedwiththecorrespondinginternaldocuments and SOPs, using GraphRAG1 with its default setup. We then enrich this graph by incorporating the tool graph through graph fusion in Neptune2, where the dependency relation is defined as _can_use_this_tool_output. 1 2 2 --- Page 3 --- Dependency_check(tool1_schema, All tools schema tool2_schema, feedback from LLM grading) send \u2026\u2026 \u2026 \u2026 E Son uti rt cy e_ _d te op oe ln =d e \u2026nc ,y s_ oe ux rt cr ea _ct ki eo yn ( = ..., 2.1. stog ce kt __ cst uo rc rek n_ ti _n rd ee tx u( rs nt (o sc tok c_ kn _a im nde e) x) dT eo po el n 1 d ea nn cd y T co ho el c n k dT eo po el n x d ea nn cd y T co ho el c y k T do eo pl e n n- d1 e nan cyd cT ho eo cl k n T Ra er ag se ot n_ t =o o \u2026l = , \u2026., target_key = \u2026, Is_delayed = \u2026,) no no LLM grading LLM grading LLM grading Yes Yes Tool Graph constructing\u2026 Dependency Collection Human in the Loop Knowledge Graph Construction Figure1: ToolGraphConstruction Afterconstructingtheunifiedknowledgegraphthatintegratesthetoolgraph,wedevelopapipeline toderivethefinalexemplarartifactsforIn-ContextPlanning(ICP)fromthisunifiedrepresentation. WeadoptHippoRAG2[8]asthepipelineforgeneratingplanartifacts,astheintegrationofdomain knowledgewiththetoolgraphalignswiththeDense\u2013SparseIntegrationframeworkdescribedin HippoRAG2, where the tool graph serves as the sparse component and the domain knowledge representsthedensecomponent. query Top documents Return the exemplar plans through the detected graph after personalized PageRank Top Triplets Seed nodes for personalized PageRank Figure2: Dense-SparseIntegrationframeworkforexemplarplansgeneration. Reddotsrepresent documentnodes;bluedotsrepresenttoolnodes. Toprepareexemplarartifactsforcold-startICP,webeginbycollectingasetofqueriesfrompro- duction. For each query, we retrieve the top-K tool triplets and relevant knowledge documents usingembeddingsearch. TheselectedtooltripletsarethenusedasseednodestorunPersonalized PageRank,producingasubgraphtailoredtothequery. Leveragingthissubgraph,LLMgeneratesthe exemplarartifacts,whicharesubsequentlystoredinthevectordatabaseforfutureretrieval. 3",
  "experiments": "EXPERIMENTS Similartopriorwork[10],weadoptTOOLBENCH [14]asourbenchmarkdataset. TOOLBENCH includes16,464APIsandprovidesthreelevelsofprompts\u2014G ,G ,andG \u2014forgeneratingqueries 1 2 3 and corresponding plans using depth-first search (DFS) planning. Specifically, G corresponds 1 tosingle-toolinstructions,G tointra-categorymulti-toolinstructions,andG tointra-collection 2 3 multi-toolinstructions. WerepurposetheTOOLBENCHdatabyrandomlyselecting1,000queries fromG ,1000fromG ,and1000fromG \u2014andusetheground-truthprovidedinthedataset. After 1 2 3 filteringoutinvalidcases,weidentified1,500validtooldependenciesderivedfromthequeriesand theircorrespondingground-truthplans.ToevaluatewhetherourDense\u2013SparseIntegrationframework improves exemplar plan generation, we simulate external knowledge by using the Tavily-Search API.ForeachAPIoutputpayloadinourdataset,weretrievedocumentsonlinethatcanutilizethe correspondingoutputpayloadsandaddthedocumnentsinstructionintheground-truthartifacts. 3.1 PerformanceonDependencyChecking Weapplythedependency-checkingpipelinetoallAPIdocumentationinourdatasetandevaluate performance across a range of LLMs. As shown in Table 1, both GPT-4o and Claude-4 achieve 3 --- Page 4 --- strongresults,withprecisionandrecallratesexceeding80%. Notably,despiteitssmallermodel size,Qwen3-8BalsoperformswellandevenattainsslightlyhigherprecisionthanClaude-4. The performanceacrossmostmodelsdemonstratesthevalidityofourframeworkinaccuratelyidentifying dependencies. Table1: PerformanceonDependencyChecking Model PredictedDependencies TrueDependencies Precision Recall GPT-4o 1332 1500 90.7% 80.5% Claude4 1652 1500 79.9% 88.1% Claude3.7 1462 1500 80.9% 78.9% DeepSeekR1 1652 1500 66.4% 73.2% Qwen3-8B 1453 1500 83.2% 80.7% 3.2 Dense-sparseFrameworkforExemplarPlanGeneration Inthissection,weassesstheeffectivenessofourDense\u2013Sparseframeworkunderthesettingwhere the unified knowledge graph correctly integrates tools and domain knowledge. To this end, we beginwiththe3,000queriesintroducedinSection3. Sinceground-truthplansareavailableforeach query,weemployLLM-as-a-judgetoverifywhetherthegeneratedexemplarartifactsalignwiththe ground-truth. WeemployJinaEmbedding(v3)[15]tocomputesemanticsimilarity,whichisthen usedtoretrievethetop-rankeddocumentsandtooltriplets,andweusethesamesetofLLMsasin Table1forgeneratingthefinalplanartifactsafterapplyingPersonalizedPageRank. Therangeof LLM-as-a-judgescorerangesfrom0to2fortheplancoverage. WeuseNovapro3astheLLMjudge. Based on both binary match accuracy and LLM-as-a-judge scores, we observe that performance Table2: PerformanceonExemplarPlanGeneration Model BinaryMatchAccuracy LLM-as-a-judgeScore GPT-4o 77% 1.62 Claude4 69% 1.47 Claude3.7 71% 1.49 DeepSeekR1 64% 1.36 Qwen3-8B 72% 1.58 remains relatively stable across models. Notably, Qwen3-8B achieves strong",
  "results": "results despite its smallersize. Thisconsistencysuggeststhatperformancemaybelargelydeterminedbythequalityof thesubgraphreturnedbyPersonalizedPageRankandembeddingmatch,ratherthansolelybymodel capacity. WealsoconductanablationstudytoevaluatetheeffectivenessofPersonalizedPageRank bycomparingperformancewithandwithoutitsapplication. RemovingPersonalizedPageRankyields Table3: AbalationstudyonPersonalizedPageRankinthepipeline Model BinaryMatchAccuracy LLM-as-a-judgeScore GPT-4owithPersonalizedPageRank 77% 1.62 GPT-4owithoutPersonalizedPageRank 68% 1.56 a 9percentage-pointdropinbinarymatchaccuracy. AdeeperanalysisshowsthatPPRrecoverstool documentsandproceduralinstructionpagesthatembedding-onlyretrievaloftenoverlooks,enriching the subgraph used for plan generation. For example, pure embedding search can miss tools like BacklogCheckwhentheyaredominatedbyotherinventory-relatedtools,whereasPPRpropagates importancethroughdependencylinkstosurfacethem. 4",
  "conclusion": "CONCLUSION Inconclusion,weintroducedaframeworkforuncoveringandleveragingdependenciesbetweentools anddocumentstoimproveexemplarartifactgeneration. Byconstructingatoolknowledgegraph from schemas and fusing it with a domain knowledge graph from internal documents and SOPs, ourdeep\u2013sparseintegrationstrategyalignsstructuraltooldependencieswithproceduralknowledge. Experimentsconfirmthatthisunifiedapproacheffectivelymodelstoolinteractionsandenhancesplan 3 4 --- Page 5 --- generation. Nonetheless,theabsenceofrealbenchmarksfordetectingtooldependenciesremainsa limitation,whichweplantoaddressinfuturework. 5 --- Page 6 ---",
  "references": "References [1] TomB.Brown,BenjaminMann,NickRyder,MelanieSubbiah,JaredKaplan,PrafullaDhariwal, ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,SandhiniAgarwal,Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin,ScottGray,BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,Alec Radford,IlyaSutskever,andDarioAmodei. Languagemodelsarefew-shotlearners,2020. [2] AakankshaChowdhery,SharanNarang,JacobDevlin,MaartenBosma,GauravMishra,Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, TojuDuke,AnselmLevskaya,SanjayGhemawat,SunipaDev,HenrykMichalewski,Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan,HyeontaekLim,BarretZoph,AlexanderSpiridonov,RyanSepassi,DavidDohan,Shivani Agrawal,MarkOmernick,AndrewM.Dai,ThanumalayanSankaranarayanaPillai,MariePellat, AitorLewkowycz,EricaMoreira,RewonChild,OleksandrPolozov,KatherineLee,Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, KathyMeier-Hellstern,DouglasEck,JeffDean,SlavPetrov,andNoahFiedel. Palm: Scaling languagemodelingwithpathways. JournalofMachineLearningResearch,24(240):1\u2013113, 2023. [3] DeepSeek-AI,DayaGuo,DejianYang,HaoweiZhang,JunxiaoSong,RuoyuZhang,Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, Xiaokang Zhang, Xingkai Yu, Yu Wu, Z.F.Wu,ZhibinGou,ZhihongShao,ZhuoshuLi,ZiyiGao,AixinLiu,BingXue,Bingxuan Wang,BochaoWu,BeiFeng,ChengdaLu,ChenggangZhao,ChengqiDeng,ChenyuZhang, ChongRuan,DamaiDai,DeliChen,DongjieJi,ErhangLi,FangyunLin,FucongDai,Fuli Luo,GuangboHao,GuantingChen,GuoweiLi,H.Zhang,HanBao,HanweiXu,Haocheng Wang,HonghuiDing,HuajianXin,HuazuoGao,HuiQu,HuiLi,JianzhongGuo,JiashiLi, JiaweiWang,JingchangChen,JingyangYuan,JunjieQiu,JunlongLi,J.L.Cai,JiaqiNi,Jian Liang, JinChen, KaiDong, KaiHu, KaigeGao, KangGuan, KexinHuang, KuaiYu, Lean Wang,LecongZhang,LiangZhao,LitongWang,LiyueZhang,LeiXu,LeyiXia,Mingchuan Zhang,MinghuaZhang,MinghuiTang,MengLi,MiaojunWang,MingmingLi,NingTian, PanpanHuang,PengZhang,QianchengWang,QinyuChen,QiushiDu,RuiqiGe,Ruisong Zhang,RuizhePan,RunjiWang,R.J.Chen,R.L.Jin,RuyiChen,ShanghaoLu,Shangyan Zhou,ShanhuangChen,ShengfengYe,ShiyuWang,ShuipingYu,ShunfengZhou,Shuting Pan, S. S. Li, Shuang Zhou, Shaoqing Wu, Shengfeng Ye, Tao Yun, Tian Pei, Tianyu Sun, T.Wang,WangdingZeng,WanjiaZhao,WenLiu,WenfengLiang,WenjunGao,WenqinYu, WentaoZhang,W.L.Xiao,WeiAn,XiaodongLiu,XiaohanWang,XiaokangChen,Xiaotao Nie, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xinyu Yang, Xinyuan Li, Xuecheng Su, XuhengLin,X.Q.Li,XiangyueJin,XiaojinShen,XiaoshaChen,XiaowenSun,Xiaoxiang Wang, Xinnan Song, Xinyi Zhou, Xianzu Wang, Xinxia Shan, Y. K. Li, Y. Q. Wang, Y. X. Wei,YangZhang,YanhongXu,YaoLi,YaoZhao,YaofengSun,YaohuiWang,YiYu,Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma,YiyuanLiu,YongqiangGuo,YuanOu,YuduanWang,YueGong,YuhengZou,YujiaHe, YunfanXiong,YuxiangLuo,YuxiangYou,YuxuanLiu,YuyangZhou,Y.X.Zhu,Yanhong Xu,YanpingHuang,YaohuiLi,YiZheng,YuchenZhu,YunxianMa,YingTang,YukunZha, YutingYan,Z.Z.Ren,ZehuiRen,ZhangliSha,ZheFu,ZheanXu,ZhendaXie,Zhengyan Zhang,ZhewenHao,ZhichengMa,ZhigangYan,ZhiyuWu,ZihuiGu,ZijiaZhu,ZijunLiu, ZilinLi,ZiweiXie,ZiyangSong,ZizhengPan,ZhenHuang,ZhipengXu,ZhongyuZhang, andZhenZhang. Deepseek-r1: Incentivizingreasoningcapabilityinllmsviareinforcement learning,2025. [4] DarrenEdge,HaTrinh,NewmanCheng,JoshuaBradley,AlexChao,ApurvaMody,Steven Truitt, Dasha Metropolitansky, Robert Osazuwa Ness, and Jonathan Larson. From local to global: Agraphragapproachtoquery-focusedsummarization,2025. 6 --- Page 7 --- [5] LutfiErenErdogan,NicholasLee,SiddharthJha,SehoonKim,RyanTabrizi,SuhongMoon, Coleman Hooper, Gopala Anumanchipalli, Kurt Keutzer, and Amir Gholami. Tinyagent: Functioncallingattheedge,2024. [6] LutfiErenErdogan,NicholasLee,SehoonKim,SuhongMoon,HirokiFuruta,GopalaAnu- manchipalli,KurtKeutzer,andAmirGholami. Plan-and-act: Improvingplanningofagentsfor long-horizontasks,2025. [7] JiaweiGu,XuhuiJiang,ZhichaoShi,HexiangTan,XuehaoZhai,ChengjinXu,WeiLi,Yinghan Shen, Shengjie Ma, Honghao Liu, Saizhuo Wang, Kun Zhang, Yuanzhuo Wang, Wen Gao, LionelNi,andJianGuo. Asurveyonllm-as-a-judge,2025. [8] Bernal Jim\u00e9nez Guti\u00e9rrez, Yiheng Shu, Weijian Qi, Sizhe Zhou, and Yu Su. From rag to memory: Non-parametriccontinuallearningforlargelanguagemodels,2025. [9] SehoonKim,SuhongMoon,RyanTabrizi,NicholasLee,MichaelW.Mahoney,KurtKeutzer, andAmirGholami. Anllmcompilerforparallelfunctioncalling,2024. [10] YanmingLiu,XinyuePeng,JiannanCao,ShiBo,YuweiZhang,XuhongZhang,ShengCheng, Xun Wang, Jianwei Yin, and Tianyu Du. Tool-planner: Task planning with clusters across multipletools,2025. [11] Chang Ma, Haiteng Zhao, Junlei Zhang, Junxian He, and Lingpeng Kong. Non-myopic generationoflanguagemodelsforreasoningandplanning,2024. [12] OpenAI, :, Aaron Hurst, Adam Lerer, Adam P. Goucher, Adam Perelman, Aditya Ramesh, AidanClark,AJOstrow,AkilaWelihinda,AlanHayes,AlecRadford,AleksanderMa\u02dbdry,Alex Baker-Whitcomb,AlexBeutel,AlexBorzunov,AlexCarney,AlexChow,AlexKirillov,Alex Nichol,AlexPaino,AlexRenzin,AlexTachardPassos,AlexanderKirillov,AlexiChristakis, AlexisConneau,AliKamali,AllanJabri,AllisonMoyer,AllisonTam,AmadouCrookes,Amin Tootoochian,AminTootoonchian,AnanyaKumar,AndreaVallone,AndrejKarpathy,Andrew Braunstein,AndrewCann,AndrewCodispoti,AndrewGalu,AndrewKondrich,AndrewTul- loch,AndreyMishchenko,AngelaBaek,AngelaJiang,AntoinePelisse,AntoniaWoodford, AnujGosalia,ArkaDhar,AshleyPantuliano,AviNayak,AvitalOliver,BarretZoph,Behrooz Ghorbani,BenLeimberger,BenRossen,BenSokolowsky,BenWang,BenjaminZweig,Beth Hoover,BlakeSamic,BobMcGrew,BobbySpero,BogoGiertler,BowenCheng,BradLightcap, BrandonWalkin,BrendanQuinn,BrianGuarraci,BrianHsu,BrightKellogg,BrydonEastman, CamilloLugaresi,CarrollWainwright,CaryBassin,CaryHudson,CaseyChu,ChadNelson, ChakLi,ChanJunShern,ChanningConger,CharlotteBarette,ChelseaVoss,ChenDing,Cheng Lu,ChongZhang,ChrisBeaumont,ChrisHallacy,ChrisKoch,ChristianGibson,Christina Kim,ChristineChoi,ChristineMcLeavey,ChristopherHesse,ClaudiaFischer,ClemensWinter, ColeyCzarnecki,ColinJarvis,ColinWei,ConstantinKoumouzelis,DaneSherburn,Daniel Kappler,DanielLevin,DanielLevy,DavidCarr,DavidFarhi,DavidMely,DavidRobinson, David Sasaki, Denny Jin, Dev Valladares, Dimitris Tsipras, Doug Li, Duc Phong Nguyen, DuncanFindlay,EdedeOiwoh,EdmundWong,EhsanAsdar,ElizabethProehl,ElizabethYang, EricAntonow,EricKramer,EricPeterson,EricSigler,EricWallace,EugeneBrevdo,Evan Mays,FarzadKhorasani,FelipePetroskiSuch,FilippoRaso,FrancisZhang,FredvonLohmann, FreddieSulit,GabrielGoh,GeneOden,GeoffSalmon,GiulioStarace,GregBrockman,Hadi Salman,HaimingBao,HaitangHu,HannahWong,HaoyuWang,HeatherSchmidt,Heather Whitney,HeewooJun,HendrikKirchner,HenriquePondedeOliveiraPinto,HongyuRen,Hui- wenChang,HyungWonChung,IanKivlichan,IanO\u2019Connell,IanO\u2019Connell,IanOsband,Ian Silber,IanSohl,IbrahimOkuyucu,IkaiLan,IlyaKostrikov,IlyaSutskever,IngmarKanitschei- der,IshaanGulrajani,JacobCoxon,JacobMenick,JakubPachocki,JamesAung,JamesBetker, JamesCrooks,JamesLennon,JamieKiros,JanLeike,JanePark,JasonKwon,JasonPhang, JasonTeplitz,JasonWei,JasonWolfe,JayChen,JeffHarris,JeniaVaravva,JessicaGanLee, JessicaShieh,JiLin,JiahuiYu,JiayiWeng,JieTang,JieqiYu,JoanneJang,JoaquinQuinonero Candela,JoeBeutler,JoeLanders,JoelParish,JohannesHeidecke,JohnSchulman,Jonathan Lachman,JonathanMcKay,JonathanUesato,JonathanWard,JongWookKim,JoostHuizinga, JordanSitkin,JosKraaijeveld,JoshGross,JoshKaplan,JoshSnyder,JoshuaAchiam,JoyJiao, JoyceLee,JuntangZhuang,JustynHarriman,KaiFricke,KaiHayashi,KaranSinghal,KatyShi, KavinKarthik,KaylaWood,KendraRimbach,KennyHsu,KennyNguyen,KerenGu-Lemberg, 7 --- Page 8 --- KevinButton,KevinLiu,KielHowe,KrithikaMuthukumar,KyleLuther,LamaAhmad,Larry Kai,LaurenItow,LaurenWorkman,LeherPathak,LeoChen,LiJing,LiaGuy,LiamFedus, LiangZhou,LienMamitsuka,LilianWeng,LindsayMcCallum,LindseyHeld,LongOuyang, LouisFeuvrier,LuZhang,LukasKondraciuk,LukaszKaiser,LukeHewitt,LukeMetz,Lyric Doshi,MadaAflak,MaddieSimens,MadelaineBoyd,MadeleineThompson,MaratDukhan, Mark Chen, Mark Gray, Mark Hudnall, Marvin Zhang, Marwan Aljubeh, Mateusz Litwin, MatthewZeng,MaxJohnson,MayaShetty,MayankGupta,MeghanShah,MehmetYatbaz, MengJiaYang,MengchaoZhong,MiaGlaese,MiannaChen,MichaelJanner,MichaelLampe, MichaelPetrov,MichaelWu,MicheleWang,MichelleFradin,MichellePokrass,MiguelCastro, MiguelOomTemudodeCastro,MikhailPavlov,MilesBrundage,MilesWang,MinalKhan, MiraMurati,MoBavarian,MollyLin,MuratYesildal,NachoSoto,NataliaGimelshein,Natalie Cone,NatalieStaudacher,NatalieSummers,NatanLaFontaine,NeilChowdhury,NickRyder, Nick Stathas, Nick Turley, Nik Tezak, Niko Felix, Nithanth Kudige, Nitish Keskar, Noah Deutsch, NoelBundick, NoraPuckett, OfirNachum, OlaOkelola, OlegBoiko, OlegMurk, OliverJaffe,OliviaWatkins,OlivierGodement,OwenCampbell-Moore,PatrickChao,Paul McMillan,PavelBelov,PengSu,PeterBak,PeterBakkum,PeterDeng,PeterDolan,Peter Hoeschele,PeterWelinder,PhilTillet,PhilipPronin,PhilippeTillet,PrafullaDhariwal,Qiming Yuan,RachelDias,RachelLim,RahulArora,RajanTroll,RandallLin,RaphaGontijoLopes, Raul Puri, Reah Miyara, Reimar Leike, Renaud Gaubert, Reza Zamani, Ricky Wang, Rob Donnelly,RobHonsby,RockySmith,RohanSahai,RohitRamchandani,RomainHuet,Rory Carmichael,RowanZellers,RoyChen,RubyChen,RuslanNigmatullin,RyanCheu,Saachi Jain,SamAltman,SamSchoenholz,SamToizer,SamuelMiserendino,SandhiniAgarwal,Sara Culver,ScottEthersmith,ScottGray,SeanGrove,SeanMetzger,ShamezHermani,Shantanu Jain, Shengjia Zhao, Sherwin Wu, Shino Jomoto, Shirong Wu, Shuaiqi, Xia, Sonia Phene, SpencerPapay,SrinivasNarayanan,SteveCoffey,SteveLee,StewartHall,SuchirBalaji,Tal Broda,TalStramer,TaoXu,TarunGogineni,TayaChristianson,TedSanders,TejalPatwardhan, ThomasCunninghman,ThomasDegry,ThomasDimson,ThomasRaoux,ThomasShadwell, Tianhao Zheng, Todd Underwood, Todor Markov, Toki Sherbakov, Tom Rubin, Tom Stasi, TomerKaftan,TristanHeywood,TroyPeterson,TyceWalters,TynaEloundou,ValerieQi,Veit Moeller, VinnieMonaco, VishalKuo, VladFomenko, WayneChang, WeiyiZheng, Wenda Zhou,WesamManassra,WillSheu,WojciechZaremba,YashPatil,YileiQian,YongjikKim, Youlong Cheng, Yu Zhang, Yuchen He, Yuchen Zhang, Yujia Jin, Yunxing Dai, and Yury Malkov. Gpt-4osystemcard,2024. [13] ChengQian,EmreCanAcikgoz,QiHe,HongruWang,XiusiChen,DilekHakkani-T\u00fcr,Gokhan Tur,andHengJi. Toolrl: Rewardisalltoollearningneeds,2025. [14] YujiaQin,ShihaoLiang,YiningYe,KunlunZhu,LanYan,YaxiLu,YankaiLin,XinCong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, MarkGerstein,DahaiLi,ZhiyuanLiu,andMaosongSun. Toolllm: Facilitatinglargelanguage modelstomaster16000+real-worldapis,2023. [15] SabaSturua,IsabelleMohr,MohammadKalimAkram,MichaelG\u00fcnther,BoWang,Markus Krimmel,FengWang,GeorgiosMastrapas,AndreasKoukounas,AndreasKoukounas,Nan Wang,andHanXiao. jina-embeddings-v3: Multilingualembeddingswithtasklora,2024. [16] KimiTeam,YifanBai,YipingBao,GuanduoChen,JiahaoChen,NingxinChen,RuijueChen, YanruChen,YuankunChen,YutianChen,ZhuofuChen,JialeiCui,HaoDing,MengnanDong, AngangDu,ChenzhuangDu,DikangDu,YulunDu,YuFan,YichenFeng,KelinFu,BofeiGao, HongchengGao,PeizhongGao,TongGao,XinranGu,LongyuGuan,HaiqingGuo,Jianhang Guo,HaoHu,XiaoruHao,TianhongHe,WeiranHe,WenyangHe,ChaoHong,YangyangHu, ZhenxingHu,WeixiaoHuang,ZhiqiHuang,ZihaoHuang,TaoJiang,ZhejunJiang,XinyiJin, YongshengKang,GuokunLai,ChengLi,FangLi,HaoyangLi,MingLi,WentaoLi,Yanhao Li,YiweiLi,ZhaoweiLi,ZhemingLi,HongzhanLin,XiaohanLin,ZongyuLin,Chengyin Liu, Chenyu Liu, Hongzhang Liu, Jingyuan Liu, Junqi Liu, Liang Liu, Shaowei Liu, T. Y. Liu, Tianwei Liu, Weizhou Liu, Yangyang Liu, Yibo Liu, Yiping Liu, Yue Liu, Zhengying Liu,EnzheLu,LijunLu,ShenglingMa,XinyuMa,YingweiMa,ShaoguangMao,JieMei, XinMen,YiboMiao,SiyuanPan,YeboPeng,RuoyuQin,BowenQu,ZeyuShang,Lidong Shi,ShengyuanShi,FeifanSong,JianlinSu,ZhengyuanSu,XinjieSun,FloodSung,Heyi Tang, Jiawen Tao, Qifeng Teng, Chensi Wang, Dinglu Wang, Feng Wang, Haiming Wang, 8 --- Page 9 --- JianzhouWang,JiaxingWang,JinhongWang,ShengjieWang,ShuyiWang,YaoWang,Yejie Wang,YiqinWang,YuxinWang,YuzhiWang,ZhaojiWang,ZhengtaoWang,ZhexuWang, ChuWei,QianqianWei,WenhaoWu,XingzheWu,YuxinWu,ChenjunXiao,XiaotongXie, WeiminXiong,BoyuXu,JingXu,JinjingXu,L.H.Xu,LinXu,SutingXu,WeixinXu,Xinran Xu,YangchuanXu,ZiyaoXu,JunjieYan,YuziYan,XiaofeiYang,YingYang,ZhenYang, ZhilinYang,ZonghanYang,HaotianYao,XingchengYao,WenjieYe,ZhuoruiYe,Bohong Yin,LonghuiYu,EnmingYuan,HongbangYuan,MengjieYuan,HaobingZhan,DehaoZhang, HaoZhang, WanluZhang, XiaobinZhang, YangkunZhang, YizhiZhang, YongtingZhang, Yu Zhang, Yutao Zhang, Yutong Zhang, Zheng Zhang, Haotian Zhao, Yikai Zhao, Huabin Zheng,ShaojieZheng,JianrenZhou,XinyuZhou,ZaidaZhou,ZhenZhu,WeiyuZhuang,and XinxingZu. Kimik2: Openagenticintelligence,2025. [17] HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher,CristianCantonFerrer,MoyaChen,GuillemCucurull,DavidEsiobu,JudeFernandes, JeremyFu,WenyinFu,BrianFuller,CynthiaGao,VedanujGoswami,NamanGoyal,Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,IsabelKloumann,ArtemKorenev,PunitSinghKoura,Marie-AnneLachaux,Thibaut Lavril,JenyaLee,DianaLiskovich,YinghaiLu,YuningMao,XavierMartinet,TodorMihaylov, PushkarMishra,IgorMolybog,YixinNie,AndrewPoulton,JeremyReizenstein,RashiRungta, KalyanSaladi,AlanSchelten,RuanSilva,EricMichaelSmith,RanjanSubramanian,Xiao- qingEllenTan,BinhTang,RossTaylor,AdinaWilliams,JianXiangKuan,PuxinXu,Zheng Yan,IliyanZarov,YuchenZhang,AngelaFan,MelanieKambadur,SharanNarang,Aurelien Rodriguez,RobertStojnic,SergeyEdunov,andThomasScialom. Llama2: Openfoundation andfine-tunedchatmodels,2023. [18] XingyaoWang,YangyiChen,LifanYuan,YizheZhang,YunzhuLi,HaoPeng,andHengJi. Executablecodeactionselicitbetterllmagents,2024. [19] JiaxinWen,JianGuan,HongningWang,WeiWu,andMinlieHuang. Unlockingreasoning potentialinlargelangaugemodelsbyscalingcode-formplanning,2024. [20] BinfengXu,ZhiyuanPeng,BowenLei,SubhabrataMukherjee,YuchenLiu,andDongkuan Xu. Rewoo: Decouplingreasoningfromobservationsforefficientaugmentedlanguagemodels, 2023. [21] RenjunXuandJingwenPeng. Acomprehensivesurveyofdeepresearch: Systems,methodolo- gies,andapplications,2025. [22] LingYang,ZhaochenYu,BinCui,andMengdiWang. Reasonflux: Hierarchicalllmreasoning viascalingthoughttemplates,2025. [23] ShunyuYao,DianYu,JeffreyZhao,IzhakShafran,ThomasL.Griffiths,YuanCao,andKarthik Narasimhan. Treeofthoughts: Deliberateproblemsolvingwithlargelanguagemodels,2023. [24] ShunyuYao,JeffreyZhao,DianYu,NanDu,IzhakShafran,KarthikNarasimhan,andYuan Cao. React: Synergizingreasoningandactinginlanguagemodels,2023. [25] AohanZeng,XiaoLiu,ZhengxiaoDu,ZihanWang,HanyuLai,MingDing,ZhuoyiYang,Yifan Xu,WendiZheng,XiaoXia,WengLamTam,ZixuanMa,YufeiXue,JidongZhai,Wenguang Chen, Peng Zhang, Yuxiao Dong, and Jie Tang. Glm-130b: An open bilingual pre-trained model,2023. [26] XinranZhao,HanieSedghi,BerndBohnet,DaleSchuurmans,andAzadeNova. Improving largelanguagemodelplanningwithactionsequencesimilarity,2025. 9"
}