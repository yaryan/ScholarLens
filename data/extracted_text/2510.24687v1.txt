--- Page 1 --- Fast algorithms enabling optimization and deep learning for photoacoustic tomography in a circular detection geometry Andreas Hauptmann∗, Leonid Kunyansky†, and Jenni Poimala‡ October 29, 2025 Abstract Theinversesourceproblemarisinginphotoacoustictomographyandinseveralothercoupled- physics modalities is frequently solved by iterative algorithms. Such algorithms are based on the minimization of a certain cost functional. In addition, novel deep learning techniques are currently being investigated to further improve such optimization approaches. All such methods require multiple applications of the operator defining the forward problem, and of its adjoint. In thispaper,wepresentnewasymptoticallyfastalgorithmsfornumericalevaluationoftheforward and adjoint operators, applicable in the circular acquisition geometry. For an (n×n) image, our algorithmscomputetheseoperatorsinO(n2logn)floatingpointoperations. Wedemonstratethe performanceofouralgorithmsinnumericalsimulations,wheretheyareusedasanintegralpartof severaliterativeimagereconstructiontechniques: classicvariationalmethods,suchasnon-negative least squares and total variation regularized least squares, as well as deep learning methods, such aslearnedprimaldual. APythonimplementationofouralgorithmsandcomputationalexamples is available to the general public Codes available at  1 Introduction Imagereconstructioninalargenumberofnovelcoupled-physics(orhybrid)imagingmodalitiesinvolves a certain wave operator. For example, two of the most developed hybrid modalities are photoacoustic and thermoacoustic tomography (PAT [31,45] and TAT [32]). In PAT and TAT such a wave operator describes propagation of the acoustic wave generated by an instantaneous thermoelastic expansion of tissues induced by a short pulse of infrared or microwave radiation. The acoustic wave in this case is a solution of the Cauchy problem for the wave equation in Rd: ∂2 p(t,x)=c2∆p(t,x), t≥0, x∈Rd, (1) ∂t2 ∂ p(0,x)=f(x), p(0,x)=0, (2) ∂t where p(t,x) is the excess acoustic pressure, c is the known and constant speed of sound, and function f(x) represents the initial pressure due to thermoelastic expansion. The initial pressure f is assumed to be compactly supported within a region Ω that is a subset of a convex domain Ω with a smooth 0 boundary ∂Ω. The trace g(t,z) of the pressure is measured during the time interval t∈(0,T] by a set of transducers that cover a subset Γ⊂∂Ω of the boundary: g(t,z)=p(t,z), (t,z)∈(0,T]×Γ. This defines the wave operator A: A:f (cid:55)→g. QuestionsabouttheinjectivityandinvertibilityofA[12,13,35,48],aswellasthedesignofinversion algorithms have received a lot of attention over the last two decades [9,10,12,13,18,36,38,41,43,46, ∗Research Unit of Mathematical Sciences, University of Oulu, Oulu, Finland and the Department of Computer Science,UniversityCollegeLondon,London,U.K. †DepartmentofMathematics,UniversityofArizona,Tucson,USA ‡DepartmentofTechnicalPhysics,UniversityofEasternFinland,Kuopio,Finland 1 5202 tcO 82 ]VI.ssee[ 1v78642.0152:viXra --- Page 2 --- MSOT InVision 256-TF 256-element detector array Imaging target Illumination Figure 1: Illustration of photoacoustic system MSOT inVision by iThera Medical with the data ac- quired by a ring of transducers. 50,51]. In the simplest cases (for example, when Γ is a circle or a sphere completely surrounding the supportoff)theoperatorAisstablyinvertible,thereareexplicitformulasforA−1[12,13,38,43,50,51], and efficient computational algorithms have been developed [16,17,21,36,43,50,51] to compute A−1g and, thus, to reconstruct the sought initial condition f. However, in more complex cases involving limited-view geometries or the measurements affected by high level of noise, approximations to f(x) are often computed with variational methods, which seek to reconstruct f(x) as the minimizer of a cost functional by applying suitable optimization algorithms. Computing such solutions usually requires multiple numerical evaluations of the forward operator A and its adjoint A∗ [4,5,20], and the reconstruction times of f(x) are largely governed by the computational effort spent on evaluating these operators. This computational bottleneck is exacerbated when novel model-based deep learning techniques are considered, which often require computations of A and A∗ not only in the forward pass, but also when computing gradients for neural network parameters. The total number of such evaluationsduringtrainingcaneasilybeontheorderoftensofthousandsorevenmillions[1,3,23,26]. Hence, there is a clear need in fast algorithms for computing these operators [24,39]. Inthispaper,weconsiderthepracticallyimportantcaseofatwo-dimensionalmeasurementscheme involving circular acquisition geometry. Such a scheme is used, for example, in the MSOT inVision scanner manufactured by iThera Medical, see Figure 1. For this acquisition geometry, we develop asymptotically fast algorithms for evaluating all three operators A, A∗, and A−1, and we implement them using the Torch Python package that allows parallelized execution on a CPU or a GPU (if present). Assuming that the dimension of the image reconstructiongridis(n×n),thereareO(n)transducerpositionsandthatO(n)samplesarecollected by each transducer, the present algorithms run in O(n2logn) floating point operations (flops). We note that asymptotically fast algorithms for the evaluation of A and A∗ in circular geometry have not previously been presented in the literature. The novel theoretically exact formulas underlying our algorithmsdonotrequireexplicitevaluationoftheHankelfunctions,whicheliminatesapossiblesource ofinstabilities, asexplainedinSection2.1.2. Wetestourmethodsanddemonstratetheirperformance in several numerical simulations, including the use of the inverse operator, solution of a variational problem with and without a total variation regularizer, as well as training and application the learned primal dual method [2]. This paper is organized as follows. The next section contains a precise formulation of the problem in question. Section 3 is devoted to derivation of the fast algorithms we propose and to the outline of their numerical implementation. The results of numerical simulations confirming the efficiency of the proposed methods are presented in Section 4. The next section contains conclusions, followed by an Appendix exhibiting derivations that may be omitted in the first reading. 2 Formulation of the forward and inverse problem The inverse source problem of PAT/TAT consists of reconstructing initial pressure f(x) from the measurements g(t,y). This inverse problem also arises in magnetoacoustoelectric tomography [37], acoustoelectric [34] and ultrasound-modulated optical [33] tomography, and other hybrid modalities. Various explicit inversion formulas and efficient algorithms for solving this problem are known. They yield either theoretically exact or microlocally accurate recovery of f from the ideal data g. However, 2 --- Page 3 --- these techniques do not take into account multiple data deterioration factors affecting the real data. In particular, the speed of sound may be varying across the object and not exactly known; the sound waves are attenuated on its way to transducers; the transducers’ sensitivity is band-limited resulting in missing both high and low frequencies, etc. We distinguish the ideal data gideal ∈ Y produced by applying the wave operator A: X → Y to the initial pressure f ∈X supported in Ω : 0 A:f (cid:55)→gideal, from real data g, where spaces X and Y specific to this paper will be defined later in the text. To make consideration more general, we can incorporate into our equations the simplest model of acoustic attenuation by multiplying the ideal data by the factor e−γt with some γ that should be found experimentally. We will also assume that transducers have a frequently dependent response η(ξ), so that the real data g are related to the ideal data gideal as follows: g(t,y)=[D(cid:0) e−γtgideal(t,y)(cid:1) ](t,y)+χ(t,y), (t,y)∈R+×∂Ω, (3) where χ(t,y) is the realization of a random variable that models measurement noise, and where D is a linear filter in the frequency domain defined through the 1D Fourier transform F in t, and its 1D inverse F−1: 1D [Dh](t)=[F−1(η(ξ)[F h](ξ))](t). 1D 1D Formula (3) (with χ(t,y)≡0) defines an operator B :gideal (cid:55)→g, and the relation between f and g is given by the following composition: g(t,y)=[BAf](t,y)+χ(t,y), (t,y)∈R+×∂Ω. Notethat,dependingonthepropertiesofη(ξ),themutuallocationofΓ,andthesupportoff,one or both operators A and B may be not invertible or not stably invertible, especially in the presence of noise χ(t,y). As a result, in practical applications of TAT/PAT dealing with real data g(t,y), the beauty and computational efficiency of explicit reconstruction techniques is frequently sacrificed in favor of non-linear optimization algorithms and/or deep learning techniques that produce images of superior quality. We note that evaluation of B and B∗ is relatively simple and we will omit these operators from further discussion. Let us now discuss established image reconstruction approaches that are used when the recon- struction problem becomes more ill-posed, i.e., under limited-view and/or high-noise scenarios. First, classical variational methods seek to find an approximation f˜(x) as a minimizer of a suitable cost functional, such as f˜=argmin∥Af −g∥2+αR(f), (4) 2 f≥0 where the first term measures data consistency, R is a regularizing term, and α balances the two terms. There is a wide variety of different choices of R enforcing regularity f˜(x), such as smoothness and sparsity with respect to a suitable transform or closeness to a known prior. Minimization of the functional (4), as a rule, is done using iterative optimization techniques, which usually require the computation of a descent direction in each iteration. The simplest of such methods uses gradient information and necessitates computation of the gradient of the data fidelity given by ∇∥Af −g∥2 =2A∗(Af −g). (5) 2 We note that the splitting techniques and primal-dual methods that are commonly used to minimize (4) also involve the computation of A and A∗ in each iteration. For all such methods, the number of iterations needed to achieve convergence is on the order of hundreds or even thousands. This amounts to a significant computational effort, mainly spent on the evaluation of A and its adjoint A∗. Recently, several successful applications of deep learning techniques to the inverse problem of PAT/TAT have been reported [15,25,52], training neural networks on realistic (or better yet, real) 3 --- Page 4 --- imagesallowsonetopromoterealisticimagepatternsthatarenoteasilyexpressedintermsofsmooth- ness, totalvariation, andsparsity. Amongthesetechniquesareso-calledmodel-basedlearnediterative methods [24,26], which formulate the iteration process in the following form: f(k+1) =Λ (f(k),A∗(Af(k)−g)), θk whereΛ isaconvolutionalneuralnetworkwithasetθ oflearnedparameters,trainedtoimprovethe θk k image generated on iteration number k. This technique was used successfully in [24,26,29] to remove artifactscausedbyaninsufficientfieldofview;italsoshowedpromisetocorrect,additionally,formany other image deterioration factors. The above scheme was trained by greedy training, a computational trickthattrainseachiterateseparatelyanddecouplestheevaluationofAandA∗ fromtrainingofthe network parameters. The whole training took 5 days, where the bulk of the computational effort was spent, again, on numerical evaluation of the operators A and A∗. In the case of linear and planar acquisition geometries, a faster training [24], as well as the end-to- end training of all iterates simultaneously [27] were achieved by using efficient FFT-based algorithms. Thus in commonly used circular and spherical geometries, to apply modern optimization techniques and/or investigate advantages of deep learning-assisted TAT and PAT one needs the fastest possible algorithms for the evaluation of A and A∗. 2.1 Known methods The properties of the three operators of interest, A: X →Y, A∗: Y →X, and A−1: Y →X, depend on the geometry of the measuring scheme. Current commercially available PAT scanners either use a spherical data acquisition surface (such as LOIS 3D by Tomowave) or utilize a ring of detectors moving along the object of interest (MSOTinVision by iThera Medical), as shown in Figure 1. In the present paper, we concentrate on the 2D circular acquisition geometry, leaving the 3D spherical acquisition for future work. We consider the acquisition geometry where f is supported within a disk Ω with boundary S and the pressure is measured on a subset of its boundary Γ ⊂ S. Without loss of generality, one can assume that the circle is of radius 1 and that the speed of sound also equals 1. Under these assumptions, the forward operator A can be expressed as the convolution of f with the fundamental solution of the free-space wave equation G(t,x): ∂ (cid:90) g(t,z)=[Af](t,z)= f(x)G(t,x−z)dx, (t,x)∈Q≡(0,T)×Γ, (6) ∂t Ω0 1 G(t,x)= for t>|x|, and 0 otherwise, (cid:112) 2π t2−|x|2 where Q is the time-space cylinder. Further, by defining the L2 inner products ⟨·,·⟩ and ⟨·,·⟩ on Ω0 Q Ω and Q, respectively, as 0 T (cid:90) (cid:90) (cid:90) ⟨u,v⟩ = u(x)v(x)dx, ⟨h,k⟩ = h(t,z)k(t,z)dzdt, (7) Ω0 Q Ω0 0 Γ one obtains the expression for the adjoint operator A∗: T (cid:90) (cid:90) ∂ [A∗g](x)= g(t,z) G(t,x−z)dzdt, x∈Ω . (8) ∂t 0 0 Γ Theaboveformulaisequivalenttothepreviousdefinitionsoftheadjointoperator(e.g.[4,5,20])ifthe speed of sound is assumed constant. Additionally, the inner products in (7) define the function spaces for the reconstructions f ∈X :=L2(Ω ) as well as for the measurements g ∈Y :=L2(Q). 0 Finally, it is known [19] that the following formula defines a left inverse operator for A: ∞ (cid:90) (cid:90) ∂ f(x)=[A−1g](x)≡2 g(t,z) G(t,x−z)dzdt, (9) ∂n(z) 0 S where n(z) is the exterior normal to S at the point z. 4 --- Page 5 --- 2.1.1 Forward operator Early works on PAT and TAT [6,28] modeled the forward operator by solving the Cauchy problem (1), (2) using second-order finite differences. Such an algorithm requires O(n2) flops per time step, and, assuming that O(n) time steps need to be computed, the total computational cost of the method is O(n3) flops. Such an operation count is too high for the purposes of this paper. In addition, the accuracy of the second-order finite differences is quite low if the function f(x) representing the initial pressure undergoes sharp changes (e.g., see Section 4.3 and Figure 3(d) for the example of artifacts resulting from the use of the finite differences). Frequently, the computation of the forward operator A in PAT and TAT is based on Fourier transform methods, accelerated using the Fast Fourier Transform algorithm (FFT). Let us define the Fourier transform F and its inverse F−1 by the following formulas: 2D 2D 1 (cid:90) 1 (cid:90) hˆ(ξ)=[F h](ξ)≡ h(x)exp(−iξ·x)dx, h(x)=[F−1h](x)≡ hˆ(ξ)exp(iξ·x)dξ, 2D 2π 2D 2π R2 R2 where function h(x) is an element of the Schwartz space on R2 [40] . Then the solution of the forward problem (1), (2) can be written as follows (e.g. Chap. 3 in [47]): (cid:104) (cid:16) (cid:17)(cid:105) p(t,x)= F−1 fˆ(ξ)cos(|ξ|t) (t,x), (t,x)∈(0,∞)×R2, (10) 2D fˆ(ξ)=[F f](ξ), 2D where we assumed that f(x) is extended by 0 to all of R2. This leads to a relatively simple algorithm. First, we precompute fˆ(ξ) and choose discretization for time t. Then for each value of the variable t, the inverse Fourier transform (10) is calculated to produce the values of p(t,x) on a Cartesian grid in x. Finally, the values of g(t,z) at the transducer points discretizing the unit circle are computed by interpolation from p(t,x). Since f(x) is finitely supported, the computation of both fˆ(ξ) and p(t,x) is spectrallyaccurate, andthetotalprecisionofthealgorithmdependsontheorderoftheinterpolation. Thiscanbeviewedasasimplifiedversionofthepopulark-Wave algorithm[49]. (Thelatteralgorithm is more advanced in that it can handle an inhomogeneous speed of sound, but in the case of the constant speed it reduces to what is described here). This approach is frequently used by researchers (e.g. [4,5,20]). The unaccelerated Fourier algorithm based on equation (10) requires O(n2logn) flops to produce p(t,x) at each step in t. Assuming that O(n) time steps need to be computed, the total complexity is O(n3logn) flops. This is slower than the accelerated O(n2logn) flops algorithm we present further in this paper. However, we will use this unaccelerated Fourier algorithm to verify the accuracy of the fast method we propose. 2.1.2 Inverse and adjoint operators KnownPAT/TATimagereconstructionalgorithms,basedonforward/adjointiterations([4,5,20]),use a modification of the k-Wave algorithm [49] discussed above to compute the result of the application of the adjoint operator A∗ to the data supported on the time-space cylinder Q. Without going into details, the operation count for such an approach is O(n3logn) flops. Our goal is to develop methods for evaluating A and A∗ in O(n2logn) flops. Let us start, however, with the inverse operator A−1. Applications of A−1 to data g given on Q have received significant attention from the researchers, because, in the case of complete data g (for example,whenΓcoversthewholecircleS andT isinfinite),computationofA−1g recoversthesought initialpressuref.Wenotethat,infact,theleftinverseoperatorA−1 isnotunique;inthecaseofideal data there exist many non-equivalent operators that recover f from Af (see, e.g. [42]). We will not try to overview the vast literature on the inverses and will only concentrate on known fast algorithms. For the simpler case where the acquisition surface Γ is a line or a plane, Fourier-based algorithms with complexity O(ndlogn) (where d is the dimension of the space) have been developed [22,30]. However, in this paper, we are interested in a circular acquisition geometry. For the latter scheme, a fast image reconstruction algorithm (that can be viewed as a scheme to compute a particular instance of A−1) was developed in [36] and applied to measurement data in [16]. 5 --- Page 6 --- Letusreviewthebasicsofthelattermethod. Byextendingg(t,z)byzerointtoafunctiondefined on R×S one can Fourier transform p in time; we will denote the result by gˆ(λ,z): (cid:90) gˆ(λ,z)≡ g(t,z)eitλdt, z ∈S. (11) R Further, let us switch to polar coordinates in x: x=x(r,θ)=r(cosθ,sinθ),r =|x|, and expand gˆ(t,z(φ)), z =(cosφ,sinφ), and f(rxˆ(θ)) into the Fourier series in φ and θ: ∞ ∞ (cid:88) (cid:88) gˆ(λ,z(φ))= gˆ (λ)eikφ, f(rxˆ(θ))= f (r)eimθ. k m k=−∞ m=−∞ where gˆ (λ) and f (r) are the corresponding Fourier series coefficients, k ∈ Z. Then [36] these k m coefficients are related through the following formula: ∞ π (cid:90) gˆ (λ)= λH(1)(λ) f (r)J (λr)rdr, (12) k 2 |k| |k| |k| 0 where J (·) are H(1)(·) are the Bessel functions and Hankel functions of the first kind, of order k, k k and where the integrals are the Hankel transforms of order |k|. In [36], to reconstruct f from g, one computes gˆ (λ) and finds the values of the integrals in equation (12) by division: k ∞ (cid:90) 2gˆ (λ) f (r)J (λr)rdr = k , k ∈Z, λ∈R\{0}. (13) |k| |k| πλH(1)(λ) 0 |k| The Hankel functions in the denominator of the above formula do not have zeros for real values of λ, so the division is well defined. After the values of Hankel transforms in (13) are computed, f is reconstructed using the well-known connection between the Hankel transforms and the Fourier series of fˆ≡F f considered in polar coordinates, see [36] for details. 2D One may wonder whether a fast algorithm for computing Af can be developed by performing the above steps in reverse. Theoretically, this seems to be possible. Direct computation of Hankel transforms would require O(n3) flops, which is too expensive for our purposes. Instead, one could compute these transforms of f indirectly, through the connection with the Fourier transform fˆof f. However, a problem will arise when formula (12) is used to compute coefficients gˆ (λ). Namely, for a k fixed λ and large order k, Hankel functions exhibit very fast growth (see formula 10.19.2 in [44]) that starts roughly at |k|≥|λ|: (cid:115) 2 (cid:18) 2|k|(cid:19)k |H(1)(λ)|∼ as |k|→∞. |k| π|k| e|λ| Ideally, this growth is compensated for by the rapid decay of the Bessel functions (12) at the limit |k|→∞. However,iftheHankeltransformsarecomputedindirectly,thereisnoreasontoexpectafast decay of absolute error in computed Hankel transforms with |k| → ∞. Therefore, such an algorithm for computing Af would be unstable. Similarly, exploitingequation(12)asastartingpointforanalgorithmforcomputingA∗ alsoleads to multiplication of approximately computed quantities by Hankel functions. Thus, below we find a different strategy for a fast computation of A, A∗ and A−1 (defined by (9)) that does not involve Hankel functions at all. 3 Fast algorithms for computing A, A∗ and A−1 In the present section we derive the algorithms for evaluation of the forward operator A: X →Y and its adjoint A∗: Y →X, and describe their implementation. We also present an implementation of the 6 --- Page 7 --- fast Hankel-free version of the inverse A−1: Y → X, but the derivation of the underlying formulas is relegated to the Appendix. Our codes are made available on Github at  together with computational examples demonstrating the use of the proposed fast algorithms. 3.1 Forward operator Starting with formula (10), for any point zˆ(θ)=(cosθ,sinθ) lying on the unit circle S we obtain: 1 (cid:90) g(t,zˆ(θ))= fˆ(ξ)cos(|ξ|t)exp(iξ·z(θ))dξ. (14) 2π R2 Let us expand this function in the Fouirer series in θ: 2π (cid:88)∞ 1 (cid:90) g(t,zˆ(θ))= g (t)eikθ, g (t)= g(t,zˆ(θ))e−ikθdθ. (15) k k 2π k=−∞ 0 Substitute (14) into (15) and switch to polar coordinates ξ =|λ|ξˆ, ξˆ=(cos(φ,sinφ)): 2π  1 (cid:90) (cid:90) g k(t)= (2π)2  fˆ(ξ)cos(|ξ|t)exp(iξ·zˆ(θ))dξe−ikθdθ 0 R2 2π  1 (cid:90) (cid:90) = fˆ(ξ)cos(|ξ|t) exp(iξ·zˆ(θ))e−ikθdθ dξ (2π)2 R2 0 ∞2π 2π   1 (cid:90) (cid:90) (cid:90) =  fˆ(λξˆ(φ))cos(λt) exp(iλξˆ(φ)·zˆ(θ))e−ikθdθ dφ λdλ. (16) (2π)2 0 0 0 We will need to simplify the inner integral in parentheses in (16): 2π 2π 2π (cid:90) (cid:90) (cid:90) exp(iλξˆ(φ)·zˆ(θ))e−ikθdθ = exp(iλcos(θ−φ))e−ikθdθ =e−ikφ eiλcosθe−ikθdθ. (17) 0 0 0 This can be done by substituting into (17) the Jacobi-Anger expansion (see, e.g. [8]): ∞ ∞ (cid:88) (cid:88) eiλcosθ =J (λ)+2 inJ (λ)cos(nθ)= i|n|J (λ)einθ, (18) 0 n |n| n=1 n=−∞ which results in the following formula: 2π (cid:90) exp(iλξˆ(φ)·zˆ(θ))e−ikθdθ =2πe−ikφi|k|J (λ). |k| 0 Combining the latter formula with (16) we obtain the expression for g (t): k ∞ 2π  (cid:90) 1 (cid:90) g k(t)=i|k|  2π fˆ(λξˆ(φ))e−ikφdφ J |k|(λ)cos(λt)λdλ. 0 0 The expression in brackets defines the Fourier coefficients fˆ(λ)of fˆ(λξˆ(φ)) with respect to φ: k 2π 1 (cid:90) fˆ(λ)= fˆ(λ,ξˆ(φ))e−ikφdφ, (19) k 2π 0 7 --- Page 8 --- so that the Fourier coefficients g of g are expressed through the coefficients fˆ(λ): k k ∞ (cid:90) (cid:104) (cid:105) g (t)=i|k| λfˆ(λ)J (λ) cos(λt)dλ. (20) k k |k| 0 Recall that the cosine Fourier transform [F h](s) of function h(y) is defined as follows: cos (cid:114) 2 (cid:90)∞ [F h](s)= h(y)cos(sy)dy. cos π 0 Thus, equation (20) can be interpreted as the cosine Fourier transform of λfˆ(λ)J (λ): k |k| (cid:114) π (cid:104) (cid:105) g (t)=i|k| F (λfˆ(λ)J (λ)) (t). (21) k 2 cos k |k| We observe that once fˆ(ξ) is computed, Fourier coefficients fˆ(λ) can be computed using (19) and k coefficients g (t) can be obtained by evaluating cosine Fourier transforms (21). The sought function k g(t,z) is then reconstructed by summing the Fourier series (15). Our fast algorithm for computing g =Af results by replacing the Fourier transforms and Fourier series by their discrete counterparts. Computation of the Fourier coefficients and summation of the Fourier series of periodic functions using the FFT is straightforward. On the other hand, replacement of the Fourier transforms by the FFT’s requires some discussion. Replacing in (10) the true Fourier transform F computed over R2, by the FFT sampling the square S ≡ [−L,L]×[−L,L] results in 2D the solution of the wave equation that is periodic in S. This means that so computed approximation to g = Af will become incorrect when the support of the solution, initially contained inside S, will reach the boundaries of S, reflects back and reaches S. Since the speed of sound in our model is equal to 1, this will happen at T = 2(L−1). Therefore, the parameter L of S should be chosen so that refl T >T, or refl T L> +1. 2 (In fact, the above formula yields a very minimal value for L. As explained below, parameter L may require even further increase). Similarly to the 2D FFT’s, replacing the cosine transform F in (21) by its discrete version will cos produce a periodic approximation to all coefficients g (t). Since the wave equation in 2D does not k obey the Huygens principle, the solution will have relatively small tails, slowly decreasing in time. In a periodic approximation, these tails will wrap around, producing a noticeable error. In order to decreasethiseffect,weincreasethemodeltimeT makingT =max(2T,6).Moreover,forthelowest new circularharmonicsg (t)withk =−1,0,1wedonotusethediscretecosineFFTandcomputeintegrals k in (21) using a quadrature rule with discretization points clustering toward λ=0. Finally, interpolation of the values of fˆ(ξ) computed by a 2D FFT on a Cartesian grid in ξ, to the polar grid also requires a discussion. It is well known that the low order interpolation in the Fourier domain results in inaccurate images (see, e.g., Ch. V.2 in [40]). Fortunately, the Fourier transform of a compactly supported function is a band-limited function, implying that higher-order methods should work very well. Perhaps the most accurate interpolation techniques are those based on the nonuniform FFT (NUFFT), (e.g., [14]). However, while formally such a step would be within the desired O(n2logn) flops count, the constant factor hidden in the O(...) notation is quite large for various versions of NUFFTs. A faster method, well-suitable for a single thread computation is bi-cubic interpolation. When experimenting with our code, we obtained sufficient accuracy with the help of the bi-cubic interpolation routines present in the SciPy package in Python. (By sufficient accuracywe understandrelativeL∞ errorsoforderofa half-of-a-percentorless). Unfortunately, such aninterpolation isnotlocal and, as aresult, itis difficulttoparallelize. Forthe numericalsimulations presentedinSection4,wecombinedrefiningthediscretizationoftheCartesianfrequencygrid(obtained by doubling the size of L to the value L≈T +2) with consecutive bi-linear interpolation. On one new hand, this produced an accuracy comparable with that of bi-cubic interpolation. On the other hand, bi-linear interpolation is easily vectorizable and parallelizable. This allowed us to implement the 8 --- Page 9 --- Algorithm 1 Computing g =Af 1: Extend f(x) by zero to a larger square domain S; 2: Using the 2D FFT compute an approximation to fˆ(ξ) on a Cartesian grid in ξ; 3: Use bi-linear interpolation to obtain values of fˆ(λξˆ(φ)) on the polar grid; 4: For each value λ in the polar grid in ξ, compute Fourier coefficients fˆ k(λ) using 1D FFT; 5: Compute Fourier coefficients g k(t) using the discrete Fourier cosine transform, equation (21), for each time step in t; 6: For each time step t, compute g(t,zˆ(θ)) by the FFT in angle θ, see equation (15); 7: Restrict g(t,zˆ(θ)) to Γ . algorithm using the Python Torch package that provides automatic parallelization and execution on a GPU (if present). This results in the Algorithm 1. The most time-consuming steps of the algorithm are the computation of 2D FFT which requires O(n2logn) flops, and O(n) evaluations of 1D FFT’s which has the similar operation count. So, the whole algorithm needs O(n2logn) flops. Since this algorithm is designed mainly for use in iterations, additional time saving is achieved by pre-computing and storing the values of the Bessel functions J (λ) for the values of k from 0 to half |k| the number of discretization points in θ, and for all values of λ = |ξ| in the selected polar grid in ξ. Further details of the implementation can be found in Section 4. 3.2 Adjoint operator The integral in equation (8) describes wave propagation in the whole of R2 excited by a source sup- ported on Q, backwards in time from t=T to 0. We will denote the whole acoustic field at t=0 by u(x), so that the adjoint operator can be written as follows: T (cid:90) (cid:90) [A∗g](x)=[Π u](x), u(x)≡ g(t,z)G′(t,x−z)dzdt, x∈R2, (22) Ω0 t 0 S where Π is a projection operator that restricts a function from R2 to Ω , and where (with abuse of Ω0 0 notation) we extended g(t,z) by zero from Γ to S. For simplicity, we will assume that the distance from Ω to ∂Ω is nonzero. 0 The free-space fundamental solution G(t,x) can be expressed through its Fourier transform [11]: (cid:20) (cid:18) (cid:19)(cid:21) G(t,x)= F−1 sin|ξ|t (t,x), G′(t,x)=(cid:2) F−1(cos|ξ|t)(cid:3) (t,x), for t>0. (23) 2D |ξ| t 2D By substituting the formula for G′(t,x) into equation (22) one obtains: t T 2π   (cid:90) (cid:90) 1 (cid:90) u(x)= g(t,zˆ(θ)) cos(|ξ|t)eiξ·(x−z)dξ dθdt 2π 0 0 R2  T2π   1 (cid:90) (cid:90) (cid:90) =   g(t,zˆ(θ))cos(|ξ|t)e−iξ·zdθ dteiξ·xdξ =[F−1uˆ](x), 2π 2D R2 0 0 where T2π  (cid:90) (cid:90) uˆ(ξ)=  g(t,zˆ(θ))cos(λt)e−iξ·zdθ dt, λ=|ξ|. (24) 0 0 UsingtheFourierseriesforg(t,z(θ))(equation(15)),theinnerintegral(inθ)in(24)canbetransformed 9 --- Page 10 --- as follows: (cid:90)2π (cid:90)2π(cid:34) ∞ (cid:35) (cid:88) g(t,zˆ(θ))cos(λt)e−iξzdθ = g (t)eikθ cos(λt)e−iξzdθ k 0 0 k=−∞ 2π  ∞ (cid:90) (cid:88) = g k(t)cos(λt) e−iξ·zeikθdθ, (25) k=−∞ 0 where ξ = λ(cosφ,sinφ), zˆ(θ) = (cosθ,sinθ). Now, the Jacobi-Anger expansion (18) allows us to further simplify the integral in (25): 2π 2π 2π (cid:90) (cid:90) (cid:90) e−iξ·zeikθdθ = e−iλcos(θ−φ)eikθdθ =eikφ e−iλcosθeikθdθ. 0 0 0 (cid:90)2π(cid:34) ∞ (cid:35) (cid:88) =eikφ i|n|J (−λ)einθ eikθdθ =2πeikφ(−i)|k|J (λ). |n| |k| n=−∞ 0 Thus, for the inner integral in (24) we obtain the following representation: 2π (cid:90) ∞ (cid:88) g(t,zˆ(θ))cos(λt)e−iξ·zdθ =2π eikφ(−i)|k|g (t)J (λ)cos(λt), k |k| 0 k=−∞ so that uˆ(ξ) can be computed by the formulas: ∞ (cid:88) uˆ(ξ(λ,φ))= eikφuˆ (λ), (26) k k=−∞ T (cid:90) uˆ (λ)≡2π(−i)|k|J (λ) g (t)cos(λt)dt. (27) k |k| k 0 Itisevidentfromtheaboveequationthatthefunctionsuˆ (λ)wejustintroducedarethecoefficientsof k expansionofuˆ(ξ)=uˆ(λ(cosφ,sinφ))intheFourierseriesinφ. Thus,wehavereducedthecomputation ofA∗gtoevaluationsofFourierseries,Fouriercosinetransforms,andone2DinverseFouriertransform. As in the case of the forward operator A, in order to facilitate good accuracy of bilinear interpola- tions and accurate representation of non-periodic functions by FFT’s that are naturally periodic, we defineanextendedCartesiangridofthesize[−L,L]×[L,L]withL=1.1+T,andweextendthedata g by zeros to a larger time interval t∈[0,T ] with T =max(2.1,4T). This results in Algorithm large large 2. Algorithm 2 Computing u=A∗g 1: Extend g(t,x) by zero from (0,T)×Γ to (0,T large)×S; 2: Using the 1D FFTs compute coefficients g k(t) (equation (15)) for each grid value of t; 3: Using the 1D cosine FFTs compute coefficients uˆ k(λ) for each grid value of λ, equation (27); 4: Using the 1D FFTs, sum the Fourier series (26) for each grid value of λ, thus obtaining values uˆ(ξ(λ,φ)) on the polar grid; 5: Use the bi-linear interpolation to obtain values uˆ(ξ) on a Cartesian grid from values uˆ(ξ(λ,φ)): 6: Using the 2D FFT reconstruct u(x) from uˆ(ξ); 7: Compute [A∗g](x) as [Π Ω0u](x). Similarly to our Algorithm 1, the most time consuming steps of the present technique are the computation of 2D FFT which requires O(n2logn) flops, and O(n) evaluations of 1D FFT’s, which results in the O(n2logn) flops count for the whole algorithm. Additional time saving is achieved by pre-computing and storing the values of the Bessel functions J (λ) for the values of k from 0 to half k the number of discretization points in θ, and for all values of λ=|ξ| in the selected polar grid in ξ. 10 --- Page 11 --- 3.3 Inverse operator Although the main goal of this paper is the development of fast algorithms for computing A and A∗, theapproachusedforfastevaluationofA∗ canbeeasilymodifiedtoobtainafastHankel-function-free algorithm for approximating the inverse A−1 defined by the universal backprojection formula in 2D, equation (9). Indeed, while formula (8) can be interpreted as a time derivative of the solution of the free space wave equation with a single layer potential supported on S, the backprojection formula equation (9) can be understood as a computation of a double layer potential also supported on S. Formula (9) yields a theoretically exact reconstruction of f from g =Af under the condition that the data g are given on the time interval (0,∞). If the data are given of on the time interval (0,T) with T >2, thereconstructionwillcontainaninfinitelysmootherror. Inmostpracticalcasessuchanerror is dominated by other imperfections of measurements, so that an acceptable approximation to f can be computed as f(x)=[A−1g](x)≈[Π v](x), Ω0 T (cid:90) (cid:90) ∂ v(x)≡2 g(t,z) G(t,x−z)dzdt, x∈R2. (28) ∂n(z) 0 Ω The restriction operator Π appears in the above formula since the function v(x) we compute is Ω0 supported in the square [−L,L]×[−L,L] with L=1+T A computation similar to the one done in the previous section allows one to obtain for the 2D Fourier transform vˆ(ξ) of the function v(x) the following expression: ∞ (cid:88) vˆ(ξ)= eikφvˆ (λ), (29) k k=−∞ T (cid:90) vˆ (λ)≡−4π(−i)|k|J′ (λ) g (t)sin(λt)dt, (30) k |k| k 0 where the Fourier coefficients g (t) are still given by (15) (we relegate the details of this computation k into the Appendix). For the algorithm approximating A−1, we use the same sizes of grids and computational domains asforA∗,sothattheresultingtechniqueisasmallmodificationofthelatteralgorithm. Anadditional step resulting in a significant reduction of the error due to finite-time data we use is an addition of a constant C chosen so that (cid:90) [v(x)+C]dx=0. (31) Ω\Ω0 Hereweare just using the apriori informationthatf(x)issupportedinΩ . ThisresultsinAlgorithm 0 3. Algorithm 3 Computing A−1g 1: Extend g(t,x) by zero from (0,T)×Γ to (0,T large)×S; 2: Using the 1D FFTs, compute coefficients g k(t) (equation (15)) for each grid value of t; 3: Using the 1D sine FFTs, compute coefficients vˆ k(λ) for each grid value of λ, equation (30); 4: Using the 1D FFTs, sum the Fourier series (29) for each grid value of λ, thus obtaining values vˆ(ξ(λ,φ)) on the polar grid; 5: Use the bi-linear interpolation to obtain values vˆ(ξ) on a Cartesian grid from values vˆ(ξ(λ,φ)): 6: Using the 2D FFT reconstruct v(x) from vˆ(ξ); 7: Find constant C to satisfy (31); 8: Compute an approximation to [A−1g](x) as [Π Ω0(v(x)+C)](x). Similarly to our Algorithm 2 for A∗, the present technique requires O(n2logn) flops. 11 --- Page 12 --- 0.6 0.004 0.4 0.002 0.2 0.0 0.000 0.2 0.002 0.4 0.004 0.6 (a) Computedg=Af (b) Errorinthecomputedg Figure 2: Reconstruction error in the fast forward computation 4 Numerical simulations In this section, we test our algorithms in a set of numerical simulations, covering different subsets of circular acquisition geometry. In particular, we investigate: (a) the complete data geometry, where surface Γ coincides with the circle S; (b) the 180 degree acquisition with the support of f lying inside theupperhalfofthecircleS insuchawaythatthewholeobjectis”visible”(see[35]forthediscussion of visible singularities); and (c) the 180 and 120 degrees acquisition with the support of f occupying most of the interior of S, leading to a wide set of ”invisible” singularities. 4.1 Forward problem First, we tested our algorithm for computing the result of application of the forward operator A to a given function f. Here and further in the test (except Section 4.5) we assume that support Ω of 0 f is a disk of radius 0.98 centered at the origin. Our phantoms f are modeled by a rather arbitrary set of smoothed characteristic functions of circles. For the example presented below, function f was discretizedona257×257Cartesiangridcoveringsquare[−1,1]×[−1,1];thecolormaprepresentation of this function is shown in figure 4(a). The solution to the forward problem g = Af was computed using the algorithm described in Section 3.1, on a computational grid with 360 angular positions and 513 uniformly spaced points in time covering interval [0,4]. All of our simulations were run on an Nvidia A2000 GPU. The computation time for one application of the forward operator A took 0.0055 sec (averaged over 100 runs), not counting the time spent precomputing the Bessel functions. The computedgisshowninFigure2(a). WecomparedourresulttoAf calculatedusingasimplifiedversion of the k-Wave algorithm [49] and a finer sampled version of f (on 513×513 grid). The difference (which can be considered the error in our method) is plotted in Figure 2(b), using a much finer color scale. The relative L error was 0.58%, and the relative L∞ error was 0.8%. 2 4.2 Reconstruction methods In the following we will compare different reconstruction methods using the introduced fast FFT models to illustrate their usefulness for solving common reconstruction approaches. The first method will be simply the application of the FFT inverse outlined in Alg. 3. This is expected to provide good reconstructions for full-view data and where the visibility condition is satisfied. However, for limited- view and noisy data the inverse A−1 is not expected to provide satisfactory results and hence we will 12 --- Page 13 --- additionally present results for two iterative methods, non-negative least squares (NNLS) as well as total variation (TV) regularization. Both approaches compute a minimizer by solving the variational problem in (4). Both methods need to be solved iteratively and benefit strongly from the fast FFT forward in Alg. 1 and adjoint in Alg. 2. We will provide a short summary below for each method. The first approach, NNLS, solves only the least squares problem with non-negativity, i.e., argmin∥Af −g∥2. (32) 2 f≥0 This can be efficiently implemented as a projected gradient descent, or proximal gradient descent for the non-negativity constraint, as follows (cid:16) (cid:17) f(k+ 21) =f(k)−λA∗ Af(k)−g , (33) f(k+1) =max(0,f(k+ 21)), k =0,1,2,..., (34) with initialization f(0) =0. The projection step (34) can additionally contain a projection to a region of interest Π , which will be utilized in the case where we only reconstruct in the upper half of the Ω0 unit disk D where the visibility condition is satisfied. In this case the full projection step is given by f(k+1) =Π Ω0max(0,f(k+ 21)). (35) While NNLS can mitigate limited-view artifacts, it is not able to remove noise. Thus, we will additionallyemploythewell-establishedTVregularization,whichaddstheregularizerin(4)penalizing the gradient of f, that is R(f)=∥|∇f|∥ , 1 here the 1-norm enforces sparsity in the gradient and hence promotes piecewise constant reconstruc- tions. Sincetheregularizerisnon-differentiable,wewillsolvetheTVproblemwiththetheprimal-dual hybridgradient(PDHG)method[7], whichallowsforconvexnon-differentiableR. Thealgorithmcan be stated for the problem (4) with TV regularization by q(k+1) = q k+σ(Af(cid:101)(k)−g) , (36) 1+σ (cid:16) (cid:17) f(k+1) =prox f(k)−λA∗q(k+1) , (37) R,αλ f(cid:101)(k+1) =f(k+1)+µ(f(k)−f(k+1)), k =0,1,2,.... (38) where σ,λ > 0, µ ∈ [0,1], regularization parameter α > 0, and initializations f(0) = 0 and q(0) = 0. Theproximaloperatorin(37)enforcestheregularizerbysolvingthecorrespondingdenoisingproblem (cid:26) (cid:27) 1 prox (f)=argmin R(h)+ ∥h−f∥2 . R,αλ 2αλ 2 h Note, that this can also be understood as a projection step to the space of permissible solutions with respect to the regularizer R. Let us point out, that (36) corresponds to the proximal operator in the dual space, i.e., enforcing the least-squares data fidelity term. 4.2.1 Learned primal dual reconstructions Additionally, we will test the capabilities of the forward/adjoint models for training a deep learning model, and in particular an iterative learned image reconstruction method, which makes use of the forward and adjoint operator in the network architecture. Specifically, we will test the learned primal dual (LPD) method [2] which reformulates the PDHG above using neural networks instead of the proximal operators (36) and (37). That is, we introduce two convolutional neural networks Γ and ϕ Λ which operate on the dual (measurement space) and primal (image space), respectively. The LPD ψ algorithm then reformulates the updates in (36) and (37) to a learned version as follows (cid:16) (cid:17) q(k+1) =Γ q(k),Af(k),y (39) ϕ (cid:16) (cid:17) f(k+1) =Λ f(k),A∗q(k+1) , k =0,1,2,.... (40) ψ 13 --- Page 14 --- 0.6 0.6 0.4 0.4 0.2 0.2 0.0 0.0 0.2 0.2 0.4 0.4 1.0 0.5 0.0 0.5 1.0 0.6 1.0 0.5 0.0 0.5 1.0 0.6 (a) Measurementgeometrywith180deg. (b) Measurementgeometrywith120deg. Figure3: Twosamples(a)and(b)fromthetrainingdatawitheachgroundtruthf (left)andcomputed g =Af +δ (right). The dotted white lines indicate the location of the transducers. Given a finite number of iterations K > 0, the above update rules define a learned reconstruction operator A† : y (cid:55)→fK with learnable parameters ψ and ϕ. Note, that this uses weight-sharing, i.e., ϕ,ψ each iterate has the same parameters. Despite the weight-sharing these can be high dimensional, in our case the full reconstruction operator A† has around 3.9·106 learnable parameters. ϕ,ψ This reconstruction operator A† can now be trained given appropriate training data. Here, we ϕ,ψ consider paired supervised training data {f ,g }N , which satisfy the operator equation i i i=1 Af +δ =g, (41) with noise δ. The reconstruction operator is then trained by minimizing the empirical loss to find optimal parameters (ψ∗,ϕ∗) by N (cid:88) (ψ∗,ϕ∗)=argmin ∥A† (g )−f ∥2. (42) ϕ,ψ i i 2 (ψ,ϕ) i=1 Note, that the minimization of (42) requires to first evaluate A† (the forward pass) which involves ϕ,ψ evaluating A and A∗ each K-times. Additionally, computing the gradients with respect to the param- eters(ϕ,ψ)requirestodifferentiatethrough(39)and(40), leadingtwoK-timesadditionalevaluations of forward and adjoint. That is, in total 4K operator evaluations per training iteration. This clearly necessitates efficient implementations. Forthisstudy,wehavechosenthenumberofLPDiterationsK =10andaU-Nettypearchitecture foreachofthenetworksΓ andΛ . Weusedthesamearchitectureforbothprimalanddualnetwork, θ ψ apart from different input dimensions as outlined in (40) and (39). The used U-Net consisted of four scales, i.e. three down and up-sampling layers, with a window size of 2. In each scale, we applied two convolutional layers followed by batch normalization and ReLU. We have chosen the same size of all convolutional kernels as 3 × 3 and the width in the first scale 32, which in each downsampling was doubled, that is in the finest scale we used 256 filters. We trained the LPD networks by using the ADAM optimizer with a cosine decay on the learning rate initialized as 10−4 for a total of 100 000 training iterations. The training data consisted of 10 000 phantoms of randomly generated ellipses withsmoothedboundariesofvaryingdegreeandweused30%Gaussiannoiseintheoperatorequation (41). Examples from the training data are shown in figure 3. Testing was performed on the same phantom as for all other methods. 4.3 Inverse problem with complete data Here we assume that support Ω of f is a disk of radius 0.98 centered at the origin, and that the 0 data g = Af are collected on a time-space cylinder [0,4]×S. As the data g we used the accurate approximationcomputedintheprevioussectionusingtheslowk-Wave algorithmonthegrid513×360, 14 --- Page 15 --- 0.008 1.0 0.006 0.004 0.5 0.002 0.0 0.000 0.002 0.5 0.004 0.006 1.0 0.008 (a) Bothgroundtruthf andA−1g (b) ErrorinA−1g 0.3 1.0 0.2 0.5 0.1 0.0 0.0 0.1 0.5 0.2 1.0 0.3 (c) Finitedifferencereconstruction (d) Errorinfindiffimage Figure 4: 360 deg acquisition, accurate data using finely discretized version of the phantom f shown in figure 4(a). The reconstructed image A−1g obtained by our inverse algorithm is indistinguishable from the ground truth f when plotted as a color map. The error of the reconstruction is shown in figure 4(b) on a much finer color scale. The relative error in L norm is 0.22%, and the relative L∞ error is 0.9%. The reconstruction time (not 2 counting the precomputation of the Bessels functions) was 0.011 sec; it was obtained by averaging one hundred computations of A−1. For comparison, we also computed an approximation to f using the finite difference time reversal method [6,28] mentioned in Section 2.1.1. This technique has the complexity of O(n3) flops, with a small hidden constant due to its simplicity. We implemented this algorithm using the Torch package and ran it on an Nvidia A2000 GPU. The number of time steps had to be doubled for this technique, due to the stability requirement for the explicit finite difference time stepping of this method. The computation time was 0.19 seconds. This is at least an order of magnitude slower than our fast algorithm. More importantly, this method produced reconstruction of a much inferior quality. The reconstructed image is shown in figure 4(c) and the corresponding error is plotted in 4 (d), on a different color scale. The relative reconstruction error was is 11% in L norm 2 30% in L∞ norm. InordertosimulatesignificantmeasurementnoisepresentinrealapplicationofPAT,TATandother hybrid imaging modalities, we added to the data white noise, computed as a sequence of realizations of a normally distributed random variable. The relative intensity of the noise measured in L norm 2 was30%. Theimagereconstructedbyapplicationofourfastinversealgorithmwithoutanyadditional regularization is shown in figure 5(a). As one would expect, the reconstruction is quite noisy. The relative error measured in L norm is 9.9%, while in L∞ norm it is 30%. An improved reconstruction 2 15 --- Page 16 --- 1.0 1.0 0.5 0.5 0.0 0.0 0.5 0.5 1.0 1.0 (a) ReconstructionviaA−1g,30%noiseing (b) IterativeTVreconstruction,30%noiseing Figure 5: 360 deg acquisition, 30% noise in the data was calculated using the iterative algorithm with TV regularization as described in Section 4.2. For this algorithm, and for all other iterative algorithms described below we used the following stopping criterion: theL normofanupdatetothecurrentapproximationissmallerthan0.3%oftheL norm 2 2 of the very first (non-zero) approximation. The method took 53 iterations to converge, with a total computation time of 2.8 seconds (including precomputation of Bessel functions). The resulting image is shown in Figure 5(b). The relative L norm of the error was reduced to 5.5% and the relative L∞ 2 norm was found to be 22%. 4.4 Inverse problem with partial data In this Section, we consider an inverse problem in which data are measured on the upper half of the circle S, and the support of f is the upper-half of the disk D ≡{x∈R2 :|x|<0.98}. This measuring scheme satisfies the ”visibility condition” (see, e.g. [35]), and the problem of reconstructing f in such geometry is well-posed. As a phantom we used the upper half of the phantom used in the previous section, as shown in Figure 6(a). The white dotted line in this figure indicates the location of the transducers. The data g was computed as in section 3.1, with values corresponding to the lower half of the circle reset to 0. The application of our fast inverse operator yields an image with significant artifacts, see Figure 6(b). The relative L error in this reconstruction is 40%, with L∞ norm equal to 2 51%. However, due to the ill-posedness of this problem, a much better image can be obtained by varia- tional techniques as previously discussed in Section 4.2. For solving the NNLS problem (32), we will usetheadditionalprojectionstepin(35),whereΠ istherestrictionofafunctiontotheupperhalfof Ω0 the disk D. This computation converged in 17 iterations that took 2 seconds (with the same stopping criterionasbefore). Thecolormapimageofthereconstructedapproximationtof isindistinguishable fromthegroundtruthshowninFigure6(a). TherelativeL errorinthisreconstructionis0.5%,while 2 the L∞ norm of the error is 2.8%. Theimagesinfigures6(c)and6(d)presentthereconstructionsfromthesamedatabutwithadded 30% white noise (as measured by the relative L norm). The image in 6(c) was obtained by NNLS. 2 Thealgorithmconvergedin26iterationsthattook2.2sec. TherelativeL2 errorinthisimageis11%, the L∞ norm of the error is 37%. The reconstruction depicted in 6(d) was obtained by the iterative algorithm with TV regularization. It took 74 iterations (or 3 seconds) to converge. The relative L 2 error got reduced to 5.2% while the relative L∞ norm of the error was 26%. 4.5 Inverse problem with incomplete data Here, we utilize our fast algorithms to solve inverse problems with incomplete data. Namely, we consider the situation where the detectors occupy either the upper half of the circle S or a 120 degree arch of the circle, while the function f to reconstructed is supported in the disk D. In this situation a 16 --- Page 17 --- 1.0 0.5 0.0 0.5 1.0 (a) Groundtruthf (b) TheinverseA−1g,nonoiseing 1.0 0.5 0.0 0.5 1.0 1.0 0.5 0.0 0.5 1.0 (c) NNLSiterations,30%noise (d) IterativeTV,30%noiseing Figure 6: 180 deg acquisition, with a support satisfying visibility condition, 30% noise. Dotted white line in the part (a) shows the location of the transducers. significantpartofthesingularities(ormaterialinterfaces)ofthefunctionf is”invisible[35], andthey cannot be stably reconstructed. One can only hope to reconstruct a ”visible” part of the image. This kind of a problem calls for the use of advanced nonlinear optimization techniques; there is hope that methods based on deep learning can provide better images. For these simulations, we use the phantom shown in 4(a). The first set of images is obtained for the data g measured on the upper half of S, with added 30% noise. Figure 7(a) presents the image obtained by application of A−1. It is not accurate: the relative L error is 49% and the relative error 2 in the L∞ norm is 76%. The NNLS algorithm converges in 83 iterations taking 3.2 sec. It produces an improved image with L error reduced to 18% and L∞ error equal to 62%, see Figure 7(b). The 2 iterative TV reconstruction produces the image shown in 7(c). It also takes 83 iterations; the error in the relative L norm is 8.2%, and in the relative L∞ norm it measures 50%. Note, however, that all 2 three techniques do not reconstruct the ”invisible” boundaries of the characteristic functions of circles (the boundaries with nearly horizontal normals in the lower part of the images), and they appear blurred, as predicted by general theory. The image reconstructed by the LPD algorithm is presented in Figure 7(d). The image is much closer to the ground truth visually; the error in the relative L 2 norm is 5%, and in the relative L∞ norm it is equal to 38%. Training of the neural network for the LPD technique took about 25 hours on Nvidia A2000 GPU. It involved 2 million of evaluations of operators A and A∗ (each). The benefit of using the proposed fast algorithms for computing these operators is evident in this example. Finally,fortheFigure8weusedthedatarestrictedtothe120archofcircleS locatedsymmetrically on the top of the circle, with 30% noise added. The application of A−1 produces an inaccurate image shown in Figure 8(a). Here the relative L error is 66% and the relative error in L∞ norm 2 is 95%. The forward/adjoint iterative algorithm converges in 231 iterations, taking 6 seconds. The correspondingimageispresentedinFigure8(b);theL erroris26%,andtheL∞is79%. Interestingly, 2 the iterative algorithm with TV regularization takes only 137 iterations to converge, requiring 4.3 seconds of computation time. The L error is reduced to 26% in this case, and L∞ error is 69%. As 2 expected,inalltheseimages”invisible”boundariesareblurred. Figure8(d)showstheimageobtained by the LPD technique. The noise is visibly reduced, and the error in the L and L∞ norms is equal 2 to 11% and 63% respectively. Network training for the LPD method took the same amount of time as 17 --- Page 18 --- 1.0 1.0 0.5 0.5 0.0 0.0 0.5 0.5 1.0 1.0 (a) TheinverseA−1g (b) NNLSiterations 1.0 0.5 0.0 0.5 1.0 (c) Iterativereconstruction,TV (d) Iterativereconstruction,LPD Figure 7: 180 deg acquisition, incomplete data, i.e. support is not satisfying visibility condition, data with 30% noise in the previous example. The results of our numerical simulations are summarized in Table 1. 5 Conclusions We have presented asymptotically fast algorithms for efficient numerical evaluation of operators A, A∗, andA−1 arisingintheinverseproblemofPAT/TATwithacirculardataacquisitionscheme. The efficiency of our techniques has been verified in a series of numerical experiments, in conjunction with various image reconstruction approaches, ranging from a straightforward application of the inverse operator, to TV image regularization and a deep-learning assisted method. A significant speed-up in computations provided by our algorithms is especially valuable in the context of iterative image reconstructionanddeep-learningassistedtomography,wherethenumberofoperatorevaluationsranges from hundreds to millions (for network training purposes). However, the purpose of the present paper wasnottoestablishwhichapproachis”better”,butrathertodemonstratetheefficiencyandversatility of the proposed fast algorithms, and their usefulness for future research of optimization and deep learning in the problems of PAT and TAT. Finally, we have published the codes for the presented methods as open source to promote usage and dissemination. 18 --- Page 19 --- 1.0 1.0 0.5 0.5 0.0 0.0 0.5 0.5 1.0 1.0 (a) TheinverseA−1g (b) NNLSiterations 1.0 0.5 0.0 0.5 1.0 (c) Iterativereconstruction,TV (d) Iterativereconstruction,LPD Figure 8: 120 deg acquisition, incomplete data, i.e. support is not satisfying visibility condition, with 30% noise Appendix Let us find a set of formulas to compute the function v(x) given by the equation (28) that will result in a fast algorithm. Starting with the Fourier transform representation of G(t,x) (equation (23)), one obtains for the normal derivative ∂ G(t,x−z) the following expression: ∂n(z) (cid:20) (cid:18) (cid:19)(cid:21) ∂ sin|ξ|t G(t,x−z)=zˆ(θ)·∇ G(t,x−z)=zˆ(θ)·∇ F−1 (t,x−z) ∂n(z) z z 2D |ξ|   1 (cid:90) sin|ξ|t i (cid:90) sin|ξ|t = 2πzˆ(θ)·∇ z |ξ| eiξ·(x−z)dξ= 2π (zˆ(θ)·ξ) |ξ| eiξ·(x−z)dξ R2 R2 i (cid:90) = cos(θ−φ)sin(|ξ|t)eiξ·(x−z)dξ. 2π R2 19 --- Page 20 --- Acquisition scheme Method Number Full Time Error Error of time per it-n L L 2 ∞ iter-ns (sec.) (sec.) (%) (%) Inverse 1 1.3 (0.011) - 0.22 0.9 360◦, no noise Reversal 1 0.19 - 11 30 Inverse 1 1.3 (0.011) - 9.9 30 360◦, 30% noise TV 53 2.8 0.053 5.5 22 Inverse 1 1.3 (0.011) - 40 51 180◦ (partial), no noise NNLS 17 2. 0.12 0.5 2.8 NNLS 26 2.2 0.085 11 37 180◦ (partial), 30% noise TV 74 3 0.041 5.2 26 Inverse 1 1.3 (0.011) - 49 76 NNLS 83 3.2 0.039 18 62 180◦ (incomplete), 30% noise TV 83 4. 0.048 8.2 50 LPD 10 0.55 0.055 5 38 Inverse 1 1.3 (0.011) - 66 95 NNLS 231 6 0.026 26 79 120◦ (incomplete), 30% noise TV 137 4.3 0.031 20 69 LPD 10 0.55 0.055 11 63 Table 1: Summary of numerical simulations. The numbers in parentheses in the fourth column show computation time not counting pre-computation of Bessel functions. Now expression (28) for v(x) can be transformed as follows: T 2π   (cid:90) (cid:90) i (cid:90) v(x)=2 g(t,zˆ(θ)) cos(θ−φ)sin(|ξ|t)eiξ·(x−z)dξ dθdt 2π 0 0 R2  T2π   = i (cid:90) (cid:90) (cid:90) g(t,zˆ(θ))cos(θ−φ)sin(|ξ|t)e−iξ·zdθ dteiξ·xdξ =(cid:2) F−1vˆ(cid:3) (x), π 2D R2 0 0 where T2π  (cid:90) (cid:90) vˆ(ξ)=2i  g(t,zˆ(θ))cos(θ−φ)sin(λt)e−iξ·zdθ dt 0 0 Use the Fourier series (15) for g to simplify the inner integral in the above equation: (cid:90)2π(cid:34) ∞ (cid:35) ∞ (cid:90)2π (cid:88) (cid:88) g (t)eikθ cos(θ−φ)sin(λt)e−iξ·zdθ = g (t)sin(λt) eikθcos(θ−φ)e−iξ·zdθ k k 0 k=−∞ k=−∞ 0 ∞ (cid:88) = g (t)sin(λt)I (φ,λ), k k k=−∞ where we denote by I (φ,λ) the following integrals: k 2π 2π (cid:90) 1(cid:90) I (φ,λ)≡ eikθcos(θ−φ)e−iξ·zdθ = eikθ(ei(θ−φ)+e−i(θ−φ))e−iλcos(θ−φ)dθ k 2 0 0 2π 2π  1 (cid:90) (cid:90) = eikφ  ei(k+1)θe−iλcosθdθ+ ei(k−1)θe−iλcosθdθ. 2 0 0 20 --- Page 21 --- Using the Jacobi-Anger expansion (18) one obtains: (cid:90)2π (cid:90)2π (cid:32) ∞ (cid:33) (cid:88) ei(k±1)θe−iλcosθdθ = ei(k±1)θ (−i)|n|J (λ)einθ dθ =2π(−i)|k±1|J (λ). |n| |k±1| n=−∞ 0 0 Now I (φ,λ)=πeikφ[(−i)|k+1|J (λ)+(−i)|k−1|J (λ)]. (43) k |k+1| |k−1| By taking into account well-known properies of the Bessel functions, 1 J (λ)=−J′ (λ), (J (λ)−J (λ))=−J′ (λ), m∈Z, 1 0 2 m+1 m−1 m formula (43) simplifies to I (φ,λ)=2πieikφ(−i)|k|J′ (λ). k |k| We now have vˆ(ξ)= (cid:90)T(cid:32) ∞ (cid:33) (cid:90)T(cid:32) ∞ (cid:33) =2i (cid:88) g (t)sin(λt)I (φ,λ) dt=−4π (cid:88) g (t)sin(λt)eikφ(−i)|k|J′ (λ) dt k k k |k| 0 k=−∞ 0 k=−∞  T  ∞ (cid:90) =−4π (cid:88) eikφ(−i)|k|J |′ k|(λ) g k(t)sin(λt)dt k=−∞ 0 or T ∞ (cid:90) (cid:88) vˆ(ξ)= eikφvˆ (λ), vˆ (λ)≡−4π(−i)|k|J′ (λ) g (t)sin(λt)dt, k k |k| k k=−∞ 0 which coincides with equations (29), (30). Acknowledgments We would like to thank Janek Gr¨ohl for providing Figure 1. This work is supported by the Research Council of Finland with the Flagship of Advanced Math- ematics for Sensing Imaging and Modelling Project Nos. 359186, 358944, Centre of Excellence of Inverse Modelling and Imaging Project Nos. 353093, 353086, and the Academy Research Fellow ProjectNo. 338408. TheFinnishMinistryofEducationandCulture’sPilotforDoctoralProgrammes (Pilot project Mathematics of Sensing, Imaging and Modelling). The European Research Council (ERC)undertheEuropeanUnion’sHorizon2020ResearchandInnovationProgramme(GrantAgree- ment No. 101001417—QUANTOM). L.K. is partially supported by the NSF, through the Award No. NSF/DMS-2405348. References [1] J.AdlerandO.O¨ktem,Solvingill-posedinverseproblemsusingiterativedeepneuralnetworks, Inverse Problems, 33 (2017), p. 124007. [2] , Learned primal-dual reconstruction, IEEE transactions on medical imaging, 37 (2018), pp. 1322–1332. 21 --- Page 22 --- [3] S. Arridge, P. Maass, O. O¨ktem, and C.-B. Scho¨nlieb, Solving inverse problems using data-driven models, Acta Numerica, 28 (2019), pp. 1–174. [4] S. R. Arridge, M. M. Betcke, B. T. Cox, F. Lucka, and B. E. Treeby, On the adjoint operator in photoacoustic tomography, Inverse Problems, 32 (2016), p. 115012. [5] Z. Belhachmi, T. Glatz, and O. Scherzer, A direct method for photoacoustic tomography with inhomogeneous sound speed, Inverse Problems, 32 (2016), p. 045005. [6] P. Burgholzer, G. J. Matt, M. Haltmeier, and G. Paltauf, Exact and approximative imaging methods for photoacoustic tomography using an arbitrary detection surface, Phys. Rev. E, 75 (2007), p. 046706. [7] A. Chambolle and T. Pock, A first-order primal-dual algorithm for convex problems with applications to imaging, Journal of mathematical imaging and vision, 40 (2011), pp. 120–145. [8] D. Colton and R. Kress, Inverse Acoustic and Electromagnetic Scattering Theory, Springer, 2nd ed., 1998. [9] N. Do and L. Kunyansky, Theoretically exact photoacoustic reconstruction from spatially and temporally reduced data, Inverse Problems, 34 (2018), p. 094004. [10] M.Eller,P.Hoskins,andL.Kunyansky,Microlocallyaccuratesolutionoftheinversesource problem of thermoacoustic tomography, Inverse Problems, 36 (2020), p. 085012. [11] G. Eskin, Lectures on Linear Partial Differential Equations, American Mathematical Society, 2010. [12] D. Finch, M. Haltmeier, and Rakesh, Inversion of spherical means and the wave equation in even dimensions, SIAM J. Appl. Math., 68 (2007), pp. 392–412. [13] D. Finch, S. K. Patch, and Rakesh, Determining a function from its mean values over a family of spheres, SIAM J. Math. Anal., 35 (2004), pp. 1213–1240. [14] L. Greengard and J.-Y. Lee, Accelerating the nonuniform fast fourier transform, SIAM Re- view., 46 (2004), pp. 443–54. [15] J. Gro¨hl, M. Schellenberg, K. Dreher, and L. Maier-Hein,Deep learning for biomedical photoacoustic imaging: A review, Photoacoustics, 22 (2021), p. 100241. [16] J. Gro¨hl, L. Kunyansky, J. Poimala, T. R. Else, F. Di Cecio, S. E. Bohndiek, B. T. Cox, andA.Hauptmann,Digitaltwinsenablefull-referencequalityassessmentofphotoacoustic imagereconstructions,TheJournaloftheAcousticalSocietyofAmerica,158(2025),pp.590–601. [17] M. Haltmeier, Inversion formula for a cylindrical radon transform, SIAM J. Imaging Sci., 4 (2011), pp. 789–806. [18] , Inversion of circular means and the wave equation on convex planar domains, Comput. Math. Appl., 65 (2013), pp. 1025–1036. [19] ,Universalinversionformulasforrecoveringafunctionfromsphericalmeans,SIAMJournal on Mathematical Analysis, 46 (2014), pp. 214–232. [20] M. Haltmeier and L. Nguyen,Analysis of iterative methods in photoacoustic tomography with variable sound speed, SIAM J. Imaging Sci., 10 (2017), pp. 751–781. [21] M. Haltmeier, O. Scherzer, P. Burgholzer, R. Nuster, and G. Paltauf, Thermoa- coustic tomography and the circular radon transform: Exact inversion formula, Math. Models and Methods in Appl. Sciences, 17 (2007), pp. 635–655. [22] M. Haltmeier, O. Scherzer, and G. Zangerl, A reconstruction algorithm for photoacoustic imaging based on the nonuniform fft, IEEE Trans. Med. Imaging, 28 (2009), pp. 1727–1735. 22 --- Page 23 --- [23] K. Hammernik, T. Klatzer, E. Kobler, M. P. Recht, D. K. Sodickson, T. Pock, and F. Knoll, Learning a variational network for reconstruction of accelerated mri data, Magnetic resonance in medicine, 79 (2018), pp. 3055–3071. [24] A. Hauptmann, B. Cox, F. Lucka, N. Huynh, M. Betcke, P. Beard, and S. Arridge, Approximate k-space models and deep learning for fast photoacoustic reconstruction, in Interna- tionalWorkshoponMachineLearningforMedicalImageReconstruction,Springer,2018,pp.103– 111. [25] A.HauptmannandB.T.Cox,Deeplearninginphotoacoustictomography: Currentapproaches and future directions, Journal of Biomedical Optics, 25 (2020), p. 112903. [26] A. Hauptmann, F. Lucka, M. Betcke, N. Huynh, J. Adler, B. Cox, P. Beard, S. Ourselin, and S. Arridge, Model-based learning for accelerated, limited-view 3-d photoa- coustic tomography, IEEE transactions on medical imaging, 37 (2018), pp. 1382–1393. [27] A. Hauptmann and J. Poimala, Model-corrected learned primal-dual models for fast limited- view photoacoustic tomography, arXiv preprint arXiv:2304.01963, (2023). [28] Y. Hristova, P. Kuchment, and L. Nguyen, Reconstruction and time reversal in thermoa- coustic tomography in acoustically homogeneous and inhomogeneous media, Inverse Problems, 24 (2008), p. 055006. [29] K.-T.Hsu,S.Guan,andP.V.Chitnis,Comparingdeeplearningframeworksforphotoacoustic tomography image reconstruction, Photoacoustics, 23 (2021), p. 100271. [30] K. P. Ko¨stli, M. Frenz, H. Bebie, and H. P. Weber, Temporal backward projection of optoacoustic pressure transients using fourier transform methods, Phys. Med. Biol., 46 (2001), pp. 1863–1872. [31] R. A. Kruger, P. Liu, Y. Fang, and R. Appledorn, Photoacoustic ultrasound (paus) recon- struction tomography, Med. Phys., 22 (1995), pp. 1605–1610. [32] R. A. Kruger, D. R. Reinecke, and G. A. Kruger, Thermoacoustic computed tomography - technical considerations, Med. Phys., 26 (1999), pp. 1832–1837. [33] P. Kuchment and L. Kunyansky, Synthetic focusing in ultrasound modulated tomography, Inverse Problems and Imaging, 4 (2010), pp. 655–673. [34] , 2d and 3d reconstructions in acousto-electric tomography, Inverse Problems, 27 (2011), p. 055013. [35] , Mathematics of photoacoustic and thermoacoustic tomography, in Handbook of Mathemat- ical Methods in Imaging, Springer New York, New York, NY, 2011, pp. 817–865. [36] L. Kunyansky, Fast reconstruction algorithms for the thermoacoustic tomography in certain domains with cylindrical or spherical symmetries, Inverse Probl. Imaging, 6 (2012), pp. 111–131. [37] , A mathematical model and inversion procedure for magneto-acousto-electric tomography (maet), Inverse Problems, 28 (2012), p. 035002. [38] L. A. Kunyansky, Explicit inversion formulae for the spherical mean radon transform, Inverse Problems, 23 (2007), pp. 373–383. [39] S. Lunz, A. Hauptmann, T. Tarvainen, C.-B. Schonlieb, and S. Arridge, On learned operatorcorrectionininverseproblems,SIAMJournalonImagingSciences,14(2021),pp.92–127. [40] F. Natterer, The Mathematics of Computerized Tomography, vol. 32, SIAM, 2nd ed., 2001. [41] L. V. Nguyen, A family of inversion formulas in thermoacoustic tomography, Inverse Problems and Imaging, 3 (2009), pp. 649–675. [42] , A family of inversion formulas in thermoacoustic tomography, Inverse Problems and Imag- ing, 3 (2009), pp. 649–657. 23 --- Page 24 --- [43] S. J. Norton, Reconstruction of a two-dimensional reflecting medium over a circular domain: exact solution, J. Acoust. Soc. Am., 67 (1980), pp. 1266–73. [44] F. W. J. Olver, D. W. Lozier, R. F. Boisvert, and C. W. Clark,eds.,NIST Handbook of Mathematical Functions, U.S. Department of Commerce, NIST and Cambridge University Press, Cambridge, 2010. [45] A. A. Oraevsky, S. L. Jacques, R. O. Esenaliev, and F. K. Tittel, Laser-based optoa- coustic imaging in biological tissues, in Proc. SPIE, vol. 2134A, 1994, pp. 122–128. [46] V. P. Palamodov, A uniform reconstruction formula in integral geometry, InverseProblems, 28 (2012), p. 065014. [47] J. Rauch, Partial Differential Equations, Springer, 2012. [48] P. Stefanov and G. Uhlmann, Thermoacoustic tomography with variable sound speed, Inverse Problems, 25 (2009), p. 075011. [49] B. E. Treeby and B. T. Cox, K-wave: Matlab toolbox for the simulation and reconstruction of photoacoustic wave fields, J. Biomed. Opt., 15 (2010), p. 021314. [50] M. Xu and L. V. Wang, Time-domain reconstruction for thermoacoustic tomography in a spherical geometry, IEEE Transactions on Medical Imaging, 21 (2002), pp. 814–822. [51] , Universal back-projection algorithm for photoacoustic computed tomography, Phys. Rev. E, 71 (2005), p. 016706. [52] C. Yang, H. Lan, F. Gao, and F. Gao, Review of deep learning for photoacoustic imaging, Photoacoustics, 21 (2021), p. 100215. 24