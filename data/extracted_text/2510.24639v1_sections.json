{
  "abstract": "Abstract Predicting causal structure from time series data is crucial for understanding complex phe- nomena in physiology, brain connectivity, climate dynamics, and socio-economic behaviour. Causal discovery in time series is hindered by the combinatorial complexity of identifying true causal relationships, especially as the number of variables and time points grow. A common approach to simplify the task is the so-called ordering-based",
  "methods": "methods in the",
  "results": "Results are averages over 100 repetitions. Error bars and shaded grey areas denote 95% confidence intervals. 31 --- Page 32 --- D Experimental Details D.1 Hyperparameters We summarise the most important hyperparameters used in conjunction with the",
  "introduction": "1 Introduction Understandingcause-effectrelationshipsfromtimeseriesdataisessentialinfieldslikebiology(Marbachetal., 2009), neuroscience (Friston et al., 2003), climate science (Runge et al., 2019), and economics (Pamfil et al., 2020),whereuncoveringhowoneeventinfluencesanothercanleadtovaluableinsightsandbetterpredictions. A key challenge in temporal causal discovery (Granger, 1969; Peters et al., 2013; Nauta et al., 2019; Runge, 2020)isthecombinatorialcomplexity\u2014therearemanypossiblewaysthatvariablescaninfluenceeachother, making it difficult to identify the true causal structure. The goal is to discover a temporal Directed Acyclic Graph (DAG), G, representing these relationships. The core problem is illustrated in Figure 1. \u2217Equalcontribution. 1 5202 tcO 82 ]GL.sc[ 1v93642.0152:viXra --- Page 2 --- Input xT\u00d7d Target G xt xt+1 xt+2 1 1 1 Learnstructure xt xt+1 xt+2 2 2 2 xt xt+1 xt+2 3 3 3 Time(t) Figure 1: Temporal causal discovery estimates, from raw time series data (left), the underlying temporal causal DAG G (right). Causalorderingapproaches(Verma&Pearl,1990;Friedman&Koller,2003;B\u00fchlmannetal.,2014;Rolland et al., 2022; Sanchez et al., 2023) offer a scalable alternative to direct graph estimation by constraining the searchspace,reducingitfromafulladjacencymatrixtoasetoforderedpermutations. Whilethisreduction scalesefficientlywithrespecttothenumberofvariablesandsamples,itcompromisesrepresentationalpower: a single causal ordering can imply extra edges, spurious artifacts, that are absent in the original DAG. In other words, committing to a single arbitrary ordering has an inherent downside: every node is deemed a potential ancestor of all subsequent nodes, creating spurious edges that must be pruned heuristically. To mitigate this, existing",
  "experiments": "experiments. Method Source CAM/SCORE/DAS/NoGAM dodiscover:  PCMCI/PCMCI+ tigramite:  VARLiNGAM lingam:  DYNOTEARS causalnex:  TCDF  DiffAN  TiMINo  32",
  "related_work": "Related work 6.1 Ordering-Based Causal Discovery RepresentingaDAGbyoneofitsvalidtopologicalorderings(Verma&Pearl,1990)reducesstructurelearn- ingtoapermutationsearchfollowedbyedgeselection. Earlyworkframedthisideaasadiscreteoptimisation problem: greedyMCMCoverpermutations(Friedman&Koller,2003),hill-climbingwithdynamicprogram- ming(Teyssier&Koller,2005),arc-reversalsearches(Park&Klabjan,2017),andrestricted-MLEprocedures such as CAM (B\u00fchlmann et al., 2014). More recent combinatorial schemes enforce sparsity via \u2113 -penalised 0 likelihoods, yielding the \u201csparsest permutation\u201d estimators with provable consistency guarantees (Raskutti & Uhler, 2018; Solus et al., 2021; Lam et al., 2022). Reinforcement-learning formulations further cast the permutation search as a sequential decision process, amortising exploration across datasets (Wang et al., 2021). Beyondscoreoptimisation,identifiabilitycanbestrengthenedbyexploitingdistributionaloralgebraicasym- metries. In linear additive models, sequentially peeling off leaf nodes from the precision matrix recovers the causal order under heteroscedastic noise assumptions (Ghoshal & Honorio, 2018; Chen et al., 2019). De- terministicfunctionalconstraintsarehandledbyDeterminism-awareGES(DGES),whichfirstclustersexact relations and then performs exact search within each cluster, using determinism itself as an unambiguous ordering cue (Li et al., 2024). Non-Gaussianity offers an alternative route: LiNGAM identifies a unique ordering via independent-component analysis, a principle extended to functional data in Func-LiNGAM (Shimizu et al., 2006). Scalabilitytohigh-dimensional,nonlinearsettingshasrecentlybeenadvancedthroughcontinuousrelaxations and deep generative models. CaPS estimates Hessian diagonals of the log-likelihood to iteratively detect leaves, unifying linear and nonlinear mechanisms and accelerating pruning with a \u201cparent score\u201d metric (Xu et al., 2024). Recent advances in ordering-based causal discovery further refine and generalise score- basedestimationstrategies. SCORE(Rollandetal.,2022)leveragesscorematchingtechniquestoiteratively identify and remove leaf nodes, specifically utilizing variance estimates of the Hessian diagonal. Building upon similar principles, DAS (Montagna et al., 2023c) enhances scalability by efficiently estimating Hessian diagonals, significantly reducing computational overhead. DiffAN trains a denoising diffusion model to approximate the score-function Jacobian, introducing a deciduous update rule that circumvents network retraining during iterative leaf removal, thus scaling ordering discovery to hundreds of variables (Sanchez et al., 2023). More recently, there have been notable efforts to generalise the score-matching framework. For instance, NoGAM(Montagnaetal.,2023b)generalisesordering-basedapproachesbeyondGaussiannoiseassumptions, employing kernelized score estimates to accommodate a wider range of data distributions. Furthermore, Liu etal.(2024)relaxestheassumptionthatallmodelsmustbeeitherlinearornonlinearandconsidersproblems with mixed models, notably also leveraging parallel processing to improve scalability. 18 --- Page 19 --- Together, these developments illustrate a shift from discrete combinatorics to differentiable optimisation, while preserving the core insight that a well-chosen causal ordering sharply narrows the search for a faithful DAG. None of these works explore combining multiple valid causal orderings to recover the full adjacency matrix. 6.2 Hessian of the Log-likelihood Estimating H(logp(x)) is the most expensive task of the ordering algorithm. Our baseline (Rolland et al., 2022)proposeanextensionofLi&Turner(2018)whichutilisesStein\u2019sidentityoveranRBFkernel(Sch\u00f6lkopf & Smola, 2002). Rolland et al.\u2019s method cannot obtain gradient estimates at positions out of the training samples. Therefore, evaluating the Hessian over a subsample of the training dataset is impossible. Other promising kernel-based approaches rely on spectral decomposition to solve this (Shi et al., 2018) issue and constitute promising future directions. Most importantly, computing the kernel matrix is expensive for memory and computation on n. There are, however,",
  "conclusion": "Conclusion Inthiswork,weintroducedDOTS,adiffusion-basedapproachleveragingmultiplecausalorderingstoaddress thechallengeoftemporalcausaldiscovery. Whileprevioussingle-orderingmethodswereprimarilydeveloped in the context of static causal discovery, our work extends the causal ordering framework explicitly to the temporal setting. This temporal context inherently incorporates the causal temporality principle, where variablescanonlycausallyinfluencefuturevariables,notpastones. Unliketraditionalsingle-orderingmeth- ods, DOTS effectively captures complementary information by aggregating multiple valid causal orderings, therebyreconstructingthetransitiveclosureoftheunderlyingtemporalDAG.Weformalizedthetheoretical benefits of this multi-ordering strategy, demonstrating its capacity to mitigate spurious dependencies and enhance robustness in causal inference. Our empirical",
  "references": "References Dimitris Achlioptas, Frank Mcsherry, and Bernhard Sch\u00f6lkopf. Sampling Techniques for Kernel"
}