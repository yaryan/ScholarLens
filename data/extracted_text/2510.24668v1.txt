--- Page 1 --- INTERACTCOMP: EVALUATING SEARCH AGENTS WITH AMBIGUOUS QUERIES MingyiDeng1∗,LijunHuang2∗,YaniFan2,JiayiZhang2†,†FashenRen2,JinyiBai3, FuzhenYang3,DayiMiao2,ZhaoyangYu1,YifanWu2,YanfeiZhang1,FengweiTeng1, YingjiaWan1,4,SongHu1,YudeLi1,XinJin1,ConghaoHu1,HaoyuLi1,QiruiFu1, TaiZhong5,XinyuWang6,XiangruTang7,NanTang2,ChenglinWu1,YuyuLuo2 1DeepWisdom2TheHongKongUniversityofScienceandTechnology(Guangzhou) 3RenminUniversityofChina4UniversityofCalifornia,LosAngeles 5AgentUniverse6McGillUniversity7YaleUniversity ABSTRACT Languageagentshavedemonstratedremarkablepotentialinwebsearchandinfor- mationretrieval. However,thesesearchagentsassumeuserqueriesarecomplete andunambiguous,anassumptionthatdivergesfromrealitywhereusersbeginwith incomplete queries requiring clarification through interaction. Yet most agents lackinteractivemechanismsduringthesearchprocess, andexistingbenchmarks cannotassessthiscapability. Toaddressthisgap,weintroduceINTERACTCOMP, abenchmarkdesignedtoevaluatewhethersearchagentscanrecognizequeryam- biguityandactivelyinteracttoresolveitduringsearch. Followingtheprincipleof easytoverify,interacttodisambiguate,weconstruct210expert-curatedquestions across 9 domains through a target-distractor methodology that creates genuine ambiguity resolvable only through interaction. Evaluation of 17 models reveals striking failure: the best model achieves only 13.73% accuracy despite 71.50% withcompletecontext,exposingsystematicoverconfidenceratherthanreasoning deficits. Forced interaction produces dramatic gains, demonstrating latent capa- bility current strategies fail to engage. Longitudinal analysis shows interaction capabilitiesstagnatedover15monthswhilesearchperformanceimprovedseven- fold,revealingacriticalblindspot. Thisstagnation,coupledwiththeimmediate feedbackinherenttosearchtasks,makesINTERACTCOMPavaluableresourcefor bothevaluatingandtraininginteractioncapabilitiesinsearchagents. Thecodeis availableat 1 INTRODUCTION Language agents have demonstrated remarkable potential across diverse domains, including code generation (Zhang et al., 2025; Hong et al., 2024b) , data analysis (Hong et al., 2024a; Li et al., 2025b;a), information retrieval (Geng et al., 2025; Song et al., 2025), and decision-making (Liu etal.,2025a;Liangetal.,2025).Anotabletrendistherapiddevelopmentofsearchagents(OpenAI, 2025d;Google,2025b), whichcanhandlecomplexuserqueriesandgatherinformationacrossthe internetbyperformingsearch,browse,andreasoningactions(Mialonetal.,2023;Weietal.,2025). However, these advanced search agents assume user queries are complete and unambiguous. In practice,usersbeginwithincompletequeriesadmittingmultipleplausibleinterpretations,andonly throughinteractioncanthetrueintentbeidentified. Yetmostsearchagentslackinteractivemecha- nismsduringsearch. Commercialagents(OpenAI,2025d)engageinasingleclarification,withno further interaction once search begins. When faced with ambiguity, agents confidently commit to assumedqueries,leadingtoincorrectanswersandwastedcomputationalresources. Existing benchmarks cannot assess this capability. Search benchmarks like GAIA (Mialon et al., 2023)andBrowseComp(Weietal.,2025)provideallnecessaryresourcesupfront,enablingagents ∗Theseauthorscontributedequallytothiswork.  1 5202 tcO 82 ]LC.sc[ 1v86642.0152:viXra --- Page 2 --- Acc(%) (a) BrowseComp Acc(%) (b) InteractComp ChatGPT Agent 70 SOTA (OpenAI) 70 SOTA 60 SOTA (Others) Ultra8x 60 Language Models Language Models Deep Research 50 Ultra 50 40 40 Grok 4 30 30 Claude-4-Opus 20 20 DeepSeek-R1GPT-5 10 OpenAI o1 Sonar pG re om Ai Pn Ii 2.5 Pro 10 GPT-4o Qwen-2.5-72B GPT-4.1 GPT-4o Qwen-2.5-72B 0 0 May Sep Jan May Sep May Sep Jan May Sep Time (May 2024 Sep 2025) Time (May 2024 Sep 2025) Figure 1: Despite rapid progress on complete search queries (BrowseComp: seven-fold over 15 months),agentperformanceonambiguous,interaction-dependentqueries(InteractComp)hasstag- natedaround6-14%. Thisgrowingdisparityrevealsacriticalblindspotinagentdevelopment. toproceedwithoutclarifyingambiguousintent. InteractionbenchmarkslikeIN3(Qianetal.,2024) and Tau-Bench (Yao et al., 2024) focus on general conversation but lack grounding in verifiable search tasks. Neither addresses the question: Can agents recognize query ambiguity and actively interact to gather disambiguating information during search? Without proper assessment of this capability,wecannotdeterminewhetherrecentadvancesinsearchagentstranslatetohandlingreal- worldscenarioswhereuserintentmustbeuncoveredratherthanassumed. Motivated by this gap, we introduce INTERACTCOMP, a benchmark designed to evaluate whether searchagentscanrecognizeambiguityandactivelyinteracttoresolveit. Ourdesignfollowsacore principle: easytoverify,interacttodisambiguate. Questionshaveshort,verifiableanswers(1-2 words) that are answerable with enough context, yet require interaction to obtain specific details neededfordisambiguation. Weachievethisthroughatarget-distractordesign: questionsuseonly shared attributes of a lesser-known target and a popular alternative, creating genuine ambiguity that search alone cannot resolve. Agents must interact with simulated users to uncover distinctive attributes not given in the initial query. INTERACTCOMP contains 210 expert-curated questions across 9 domains in both English and Chinese, validated to ensure interaction is necessary and answersareverifiable. Systematicevaluationof17modelsconfirmsourdesignprincipleandrevealsastrikingfailurepat- tern. When provided complete disambiguating context, models achieve strong performance with the best reaching 71.50% accuracy, validating questions are answerable once information is com- plete. However,eventhebestmodelachievesonly13.73%inthefullinteractionsetting,withmost models in single digits. This 5× performance gap exposes the core problem: models fail not due tosearchandreasoningdeficits,butsystematicoverconfidencethatpreventsthemfromengagingin interactiondespitehavingaccesstoit. Scaling experiments confirm this diagnosis. Simply increasing interaction opportunities from 5 to 20roundsyieldsminimalimprovement(from14%to20%), asmodelsbarelyincreasetheirques- tioningbehavior. Incontrast,forcingmodelstointeractbeforeansweringproducesdramaticgains (from 14% to 40%). Longitudinally, as shown in Figure 1, interaction capabilities have shown al- mostnoimprovementacrossallmodelsover15months,whileBrowseCompperformanceimproved seven-fold during the same period. This stagnation is striking given our forced interaction experi- mentsdemonstratethecapabilityislatentratherthanabsentandreadilyimprovable. Thisfinding, combinedwiththecleanrewardsignalsfromsearchoutcomes,makesINTERACTCOMPwell-suited forRLVRapproachestoimprovemodelinteractionwithhumans. Ourcontributionsarethreefold.(1)WeintroduceINTERACTCOMP,abenchmarkevaluatinginterac- tioncapabilitiesinsearchscenarios,withcleanrewardsignalsenablingfuturetrainingapproaches. (2)Weprovidediagnosticevidenceacross17modelsthatinteractionfailurestemsfromsystematic overconfidenceratherthancapabilitydeficits.(3)Wedemonstratethroughlongitudinalanalysisthat interactionrepresentsacriticalblindspotinagentdevelopment,withINTERACTCOMPprovidinga foundationforaddressingthisneglecteddimension. 2 --- Page 3 --- 2 RELATED WORK Search Benchmarks and Agents. Recent benchmarks evaluate search agents along two dimen- sions. Web-scalesearchbenchmarkslikeBrowseComp(Weietal.,2025)assessinformationgather- ingacrosstheentirewebwithcompletequeries,spawningvariantsforChinese(Zhouetal.,2025a), multimodalcontent(Lietal.,2025d),andenhancedquestions(Chenetal.,2025). Tool-augmented benchmarkslikeGAIA(Mialonetal.,2023)andWebWatcher(Gengetal.,2025)additionallyre- quire agents to handle multimedia and perform computations. These benchmarks have motivated diverseagentdesigns. ReinforcementlearningapproacheslikeR1-Searcher(Songetal.,2025)and Search-R1(Jinetal.,2025)learnintegratedsearch-reasoningpatterns,whiledatasynthesismethods like WebSailor (Li et al., 2025c) and WebExplorer (Liu et al., 2025b) enhance long-horizon capa- bilities. Additionally,bothmanuallydesignedandself-designedsearchagents(Zhangetal.,2025; Zeng et al., 2025; Teng et al., 2025) have achieved strong performance through careful workflow engineering. Interaction Benchmarks and Agents. Complementary to search benchmarks, recent work eval- uates agents’ interaction capabilities. SWEET-RL (Zhou et al., 2025b) proposes ColBench for multi-turncollaborativereasoningwithRL-basedcreditassignmentacrossturns. UserBench(Qian etal.,2025a)andUserRL(Qianetal.,2025b)creategymenvironmentsfortrainingagentsonuser- centrictaskswheregoalsareunderspecifiedandpreferencesemergeincrementally.IN3(Qianetal., 2024) and Tau-Bench (Yao et al., 2024) evaluate implicit intention understanding and tool-agent- user interaction respectively. These benchmarks collectively reveal that current models struggle with proactive clarification and user alignment—for instance, agents uncover fewer than 30% of userpreferencesthroughactivequestioninginUserBench. However,thesebenchmarksprimarilyfocusongeneralconversationalsettingsortool-usescenarios, lacking grounding in search tasks where intent errors lead to objectively wrong retrieval results. INTERACTCOMPdiffersbyevaluatinginteractioncapabilitiesspecificallyinsearchscenarios,where ambiguous queries must be resolved through clarification before effective retrieval can occur, and wheresearchoutcomesprovidenaturalrewardsignalsfortraininginteractionstrategies. 3 THE INTERACTCOMP BENCHMARK Table1: AtaskinstancefromINTERACTCOMP. TasksinINTERACTCOMPcompriseanambiguous query,thesimulateduser’scontext,andaconciseanswer. Question: Whichteam-basedstrikingsportfeatures Context: Struckobjectisaplasticpuck,resembling two sides alternating offense and defense, where in- anicehockeypuck.Strikingmethodusesawhip-like dividualssequentiallyhitahigh-speedprojectileand swing: thehitterlashesthepuckwithalongwooden teammatescoordinatetointerceptitintheair? Out- rod. Defenderswieldwoodenboards,swingingthem comesdependonwhethertheprojectileisintercepted toblockthepuckinmid-air.Fieldisagiantfanshape, orlandswithinthevalidplayingfield. Defenserelies about300meterslongwitha10–12degreeangle.De- on wide positioning and collaboration, all offensive fensiveteamsdeploy18–20playersspreadacrossthe playerstaketurnsstriking,flightspeedsoftenexceed fieldtoformadefensiveline.Scoringisbasedondis- 100 mph, protective gear is required due to impact tance and landing point: offensive points depend on risk, and the sport is governed by long-standing as- how far the puck travels and whether it touches the sociationsorleagues. ground. Distractor:BaseBall Answer:Hornussen The INTERACTCOMP datasetwasconstructedentirelybyhumanannotatorswiththeassistanceof searchtoolsandlanguagemodels. WhileBrowseComp(Weietal.,2025)evaluatescomplexsearch and reasoning with complete initial information, INTERACTCOMP evaluates whether agents can recognize ambiguity and actively gather necessary context through interaction during the search process. Ourcoredesignprinciplefollows“Easytoverify,Interacttodisambiguate”: questions have concise answers that are straightforward to verify once found, yet remain ambiguous with- out interaction to uncover distinguishing details. This section describes the task structure (§3.1), constructionmethodology(§3.2),anddatasetstatistics(§3.3). 3 --- Page 4 --- Algorithm1DataConstructionPipeline Require: targetA,distractorB 1: F A ←attributesofA; F B ←attributesofB 2: BuildambiguousQfromF A∩F B 3: AddcontextC fromF A\Q 4: Validate(Q,C): 5: whilenotfinisheddo 6: ifcandidatesettoolargeorQanswerablethen 7: refineQ 8: elseifanswernotuniquethen 9: refineC 10: elseifcross-validationfailsthen 11: repairQorC 12: returnfinalizedinstance(Q,C,A) 3.1 TASKOVERVIEW As shown in Table 1, each instance comprises an ambiguous question, a context containing dis- tinctiveattributes,thecorrectanswer,andadistractor(apopularalternativesharingattributeswith thetarget). Thecontextishiddenfromagentsbutavailabletoasimulateduserresponder. Agents receive only the ambiguous question and operate with three actions: search to retrieve web in- formation,interacttoproposeclarifyingquestions,andanswertoprovidethefinalresponse. Thesimulatedresponderreplieswith”yes,””no,”or”Idon’tknow”basedsolelyoncontextinfor- mation. Throughthisprocess, agentsmustrecognizeambiguity, gatherdisambiguatingdetailsvia interaction,andidentifythecorrectanswer. Implementationdetailsforbothagentsandresponders areprovidedinAppendixA.1andAppendixA.2. 3.2 DATACONSTRUCTIONANDVERIFICATION Our construction methodology draws inspiration from BrowseComp’s answer-first approach (Wei et al., 2025), but fundamentally shifts focus from search complexity to ambiguity resolution. The central challenge in constructing such a benchmark is creating questions that appear reasonable yet systematically lack information for confident resolution. We observe that user ambiguity is particularlypronouncedwhendealingwithsimilarconceptsthatshareoverlappingattributes,itisin thesescenariosthatadditionalclarificationbecomestrulynecessaryratherthanmerelyhelpful. This observation leads us to design a systematic target-distractor methodology. We deliberately pairantargetentitywithasimilarpopularentity(thedistractor),craftingquestionsusingonlytheir sharedattributeswhilehidingdistinctiveinformationascontext. Thisconstructionensuresthat: (1) questions admit multiple plausible interpretations including the popular distractor, making direct answeringunreliable;(2)thetargetanswerpossessesalldescribedattributes,ensuringverifiability; and(3)distinctiveattributeshiddenincontextprovidecleardisambiguationpathsthroughinterac- tion. Algorithm1formalizesthispipeline, whichwedetailinthefollowingsubsectionsalongside ourtwo-stageverificationprocess. 3.2.1 CONSTRUCTIONPROCESS Annotatorsreceivethefollowinginstruction: “Youneedtofindapairofentitiesthataresimilarbutdifferinpopularity. Usetheirshared attributestoconstructanambiguousquestion,andreservetheremainingdistinctiveattributesto formthecontext.” Followingthisinstruction,theconstructionproceedsinfoursteps: (1)EntitySelection: annotators identify a lesser-known target and a popular distractor sharing overlapping characteristics; (2) At- tributeCategorization: attributesareclassifiedasshared(commontoboth)ordistinctive(unique to target); (3) Question Formulation: only shared attributes are used to create questions admit- ting multiple plausible candidates; (4) Context Formation: distinctive attributes are reserved as 4 --- Page 5 --- context, ensuring question-context pairs uniquely identify the target while questions alone remain ambiguous. 3.2.2 VERIFICATIONPROCESS Weimplementatwo-stageverificationprotocoltoensuredataqualityandinteractionnecessity. Stage1: CompletenessVerification. Independentannotatorsvalidatethreerequirements: (1)the targetanswermustpossessallattributesdescribedinboththequestionandcontext,(2)thequestion- context combination must admit only one valid answer with no plausible alternatives, and (3) in- stanceswhereannotatorsidentifyvalidalternativeanswersarediscardedandreconstructed. Stage 2: Interaction Necessity Validation. We verify that questions truly require interaction through two complementary checks. First, we manually confirm questions cannot be confidently resolvedthroughdirectwebsearch,checkingthefirstfiveGoogleresultpages. Second,weconduct automatedtestingwiththreecapablemodels(GPT-5,GPT-5-mini,Claude-Sonnet-4)across5-round trials where models have access to search but no interaction. Questions successfully answered by twoormoremodelswithoutinteractionareflaggedasinsufficientlyambiguousandundergorevision tostrengthentheirambiguity. 3.3 DATASTATISTICS Figure2: Topicdistributionandquestion/contextlengthstatisticsinINTERACTCOMP. Inthissection,wepresentstatisticsonthetopicdistribution,questionandcontextlengthdistribution ofourcuratedINTERACTCOMPdataset. Topic distribution. Figure 2 presents the distribution of samples across 9 topic domains in the INTERACTCOMPdataset. ThemostrepresentedcategoriesincludeScience&Engineering(21.3%), Humanities(18.0%),andEntertainment(16.6%). ThedatasetalsofeaturesBusiness&Economics (11.8%), Law & Politics (8.5%), and Sports (7.1%). Conversely, domains like Medicine & Life Science(5.7%),Academic&Research(4.7%),andGeneralKnowledge&Misc. (6.2%)havefewer samples. Question and Context Length distribution. Figure 2 illustrates the distribution of question and context lengths in the INTERACTCOMP dataset. Question length predominantly ranges between 40 to 80 words, with the majority falling within this interval. Context length shows a broader distribution,typicallyspanningfrom40toover200words,withpeakfrequencyinthe60-100word range. These distributions demonstrate that questions are concise yet informative, while contexts providecomprehensivedisambiguationinformation. 5 --- Page 6 --- Languagedistribution. The INTERACTCOMP datasetcomprisesbilingualinstanceswithEnglish accountingfor139samples(66.19%)andChinesecontributing71samples(33.81%),enablingeval- uationofinteractioncapabilitiesacrossdifferentlinguisticcontexts. 4 EXPERIMENTS 4.1 EXPERIMENTALSETUP To systematically evaluate agent capabilities across different interaction paradigms, we design a controlledexperimentalframeworkthatisolatesandmeasurestheincrementalcontributionofcore agentcapabilities: knowledgerecall,informationretrieval,andinteractiveclarification. Agent Architecture: We employ the ReAct framework (Yao et al., 2023) as our base architec- ture, implementingthreecomplementaryconfigurations: (1)Answer-only: directresponsegenera- tion testing pure knowledge recall, (2) Answer+Search: incorporating web search for information retrieval, and (3) Answer+Search+Interact: adding interactive clarification through interact with responder. This design enables measurement of capability increments while maintaining architec- tural consistency. To further investigate interaction behavior, we implement a forced-interaction variantforablationstudiesthatrequiresminimuminteractionthresholdsbeforeanswergeneration. ImplementationdetailsareprovidedinAppendixA.1. Models: We evaluate across diverse model families including proprietary models (GPT-4o-mini, GPT-4o, GPT-4.1, GPT-5, OpenAI o3, Grok-4, Doubao-1.6, Claude-Sonnet-4, Claude-Opus-4, Claude-3.5-Sonnet) and open-weight models (GLM-4.5, Kimi-K2, Deepseek-V3.1, Deepseek-R1, Qwen3-235B-A22B,Qwen2.5). Followingestablishedbenchmarkingpractices,westandardizepa- rameters where supported: temperature=0.6, top p=0.95.We employ GPT-4o (temperature=0.0) as ourgrader,providinggroundtruth,agentresponse,andquestioncontextforbinarycorrectnessjudg- ments.WeimplementrespondersimulationusingGPT-4o(temperature=1.0)thatprovidesstructured feedbackwhenagentsemploytheinteractaction. Metrics: We evaluate agents across five key dimensions: (1) Interaction Metrics: Round (aver- age number of conversation turns) and percentage of rounds where interact actions are used (IR) measuring behavioral patterns and action utilization; (2) Performance Metrics: Accuracy (Acc.) measuring the percentage of correctly answered queries, and Calibration Error (C.E.) measuring confidencecalibrationusing5confidencebins;and(3)Cost: measuredinUSDreflectingcomputa- tionalresourcesusageforpracticaldeploymentconsiderations. 4.2 MAINRESULTS Table2presentscomprehensiveresultsacross17models,revealingstrikingpatternsinhowdifferent architectureshandleambiguousqueries. Theresultsexposefundamentallimitationseveninstate- of-the-art systems, with the highest-performing model (GPT-5) achieving only 13.73% accuracy, demonstratingthebenchmark’schallengingnature. Diverse Interaction Patterns Across Models. Models exhibit dramatically different interaction strategies,creatingdistinctbehavioralprofiles. GPT-4o-ministandsoutasanextremecase: itasks questionsin73.95%ofavailablerounds,byfarthehighestinteractionrate,yetachievesonly7.14% accuracy—closetoGLM-4.5whichbarelyinteracts(0.25%IR).Thissuggeststhatexcessiveques- tioning without clear purpose can be counterproductive. Conversely, DeepSeek-R1 demonstrates morebalancedbehaviorwith44.72%IRyielding13.08%accuracy,thehighestamongopen-weight models,indicatingthatwillingnesstointeractcantranslatetobetterperformancewhenusedeffec- tively. Calibration Quality Correlates with Interaction Patterns. A remarkable finding is that models withhigherinteractionratesoftenexhibitsuperiorcalibration. GPT-4o-mini’saggressivequestion- ing strategy, while not improving accuracy, results in dramatically better calibration (37.44 CE) comparedtolow-interactionmodelslikeDoubao-1.6(84.35CE).Thispatternsuggeststhatinterac- tion,evenwhennotoptimallytargeted,helpsmodelsdevelopmorerealisticconfidenceassessments abouttheirknowledgelimitations. 6 --- Page 7 --- Table 2: Performance comparison of 17 large language models on the INTERACTCOMP dataset. Thetablereportsbothinteractionbehaviorslikeaveragenumberofconversationturns(Round)and percentage of rounds where interact actions (IR) are used; final performance like accuracy (Acc. withstdinparentheses)andcalibrationerror(C.E.),alongwiththeestimatedtotalcost. Modelsare groupedintoopen-weight andclosed-weight categoriesforclarity. Bestaccuracyishighlightedin bold. Interaction Performance Model Cost($) Round IR Acc. C.E. OpenWeightsModels GLM-4.5(ZhipuAI,2025) 6.91 0.25 7.14(±0.48) 80.64 2.16 Kimi-K2(MoonshotAI,2025) 4.95 5.98 6.51(±1.53) 87.10 0.75 Deepseek-V3.1(DeepSeek,2025a) 7.26 11.60 11.74(±2.71) 74.79 8.84 Deepseek-R1(DeepSeek,2025b) 6.58 44.72 13.08(±0.29) 77.00 60.43 Qwen2.5-72B-Instruct(Yangetal.,2024) 7.45 31.88 8.08(±0.73) 77.57 0.15 Qwen3-235B-A22B(QwenTeam,2025) 5.64 27.75 8.89(±0.72) 82.63 7.47 ProprietaryModels GPT-4o-mini(OpenAI,2024b) 4.16 73.95 7.13(±0.42) 37.44 0.35 GPT-4o(OpenAI,2024a) 5.65 9.26 7.62(±0.79) 79.50 8.65 GPT-4.1(OpenAI,2025a) 5.49 34.02 10.79(±1.22) 82.11 5.58 OpenAIo3(OpenAI,2025c) 2.96 15.03 10.00(±1.44) 41.96 5.04 GPT-5(OpenAI,2025b) 4.33 30.87 13.73(±2.55) 68.67 16.85 Grok-4(xAI,2025) 4.92 4.55 8.40(±1.24) 69.00 77.55 Gemini-2.5-Pro(Google,2025a) 4.65 11.09 10.28(±0.37) 86.52 15.04 Doubao-1.6(ByteDance,2025) 3.08 10.60 6.73(±0.97) 84.35 1.40 Claude-3.5-Sonnet(Anthropic,2024) 5.63 27.57 8.10(±1.91) 80.04 13.09 Claude-Sonnet-4(Anthropic,2025b) 6.90 10.76 7.46(±1.37) 79.62 19.47 Claude-Opus-4(Anthropic,2025a) 8.55 10.86 8.10(±0.96) 78.42 115.47 Open-Weightvs. ProprietaryModelDivide. Theperformancegapbetweenopen-weightandpro- prietarymodelsisstarkandconsistent.Allopen-weightmodelsstrugglewithinteractionratesbelow 45%,withmostfallingunder32%. GLM-4.5,Kimi-K2,andQwen3-235B-A22Bshowparticularly conservativeinteractionbehavior(0.25%, 5.98%, and27.75%respectively), suggestingthatopen- weightmodelsmayhavebeentrainedtominimizeuncertainresponsesratherthanseekclarification. In contrast, proprietary models like GPT-4.1 and GPT-5 show more balanced interaction patterns (34.02%and30.87%),thougheventheyfallshortofoptimalinformation-gatheringbehavior. These findings collectively demonstrate that current language models, regardless of scale or so- phistication, struggle fundamentally with effective information gathering, often exhibiting either excessiveconservatismorineffectiveover-questioningwhenfacedwithgenuineambiguity. 4.3 ABLATIONANALYSIS Tovalidatethatourbenchmarkspecificallytestsinteractionabilitiesratherthangeneralreasoning, weconductablationstudiesacrossthreeevaluationmodesusing8representativemodels. Table 3 reveals dramatic performance gaps confirming interaction as the critical missing compo- nent. Threekeyfindingsemerge: (1)Answer-onlymodeexposesfundamentallimitations,OpenAI o3 achieves only 5.18%, GPT-5 reaches 7.62%, with catastrophic overconfidence (60.94-93.17% calibrationerrors). (2)Searchaugmentationprovidesminimalbenefits,o3increasestojust8.81% andGPT-5to9.52%, demonstratingthatinformationretrievalalonecannotresolveambiguity. (3) Complete contextual information reveals the performance ceiling, o3 soars to 71.50% (13.8× in- crease), GPT-5 reaches 67.88%, and calibration errors plummet to 7.44%, confirming underlying reasoningcapabilitiesexistbutareinaccessiblewithoutpropercontext. Themassivegapbetweensearch-only(6.74-9.52%)andwith-context(40.93-71.50%)performance validatesourbenchmarkdesign:interactiontoacquiredisambiguatinginformationisthetruebottle- 7 --- Page 8 --- neck,notreasoningability.Modelspossesstheknowledgetoanswercorrectlybutfailatrecognizing whenandhowtoseeknecessaryclarification. Table 3: Ablation study comparing model performance under three evaluation settings: answer- only(modelsrespondwithoutadditionalevidence),search-only(responsesbasedsolelyonretrieved information),andwith-context(responsessupportedbycompletedisambiguatingcontext). Results arereportedintermsofaccuracy(Acc.)andcalibrationerror(C.E.).Thebestscoresineachcolumn arehighlightedinbold. answer-only search-only with-context Model Acc. C.E. Acc. C.E. Acc. C.E. GPT-4o 2.38 88.76 7.77 80.52 40.93 47.33 GPT-5 7.62 76.26 9.52 79.14 67.88 21.36 OpenAIo3 5.18 60.94 8.81 52.62 71.50 7.44 GLM-4.5 2.38 84.40 6.74 82.41 64.77 22.37 Kimi-K2 1.43 90.36 7.53 86.87 53.37 40.62 Gemini-2.5-Pro 2.38 93.17 7.25 90.65 69.95 28.60 DeepSeek-V3.1 3.11 85.60 8.29 79.24 65.28 24.17 Claude-Sonnet-4 2.85 87.12 7.25 81.70 59.07 26.31 Table4: Scalinganalysisofmodelperformanceacrossdifferentinteractionrounds(5,10,and20) ona50-questionsubsample. Wereporttheaveragenumberofinteractrounds(IRound), accuracy (Acc.), and calibration error (C.E.) for four representative models: GPT-4o-mini, GPT-5, Claude- Sonnet-4,andDeepseek-V3.1. GPT-4o-mini GPT-5 Claude-Sonnet-4 Deepseek-V3.1 Rounds IRound Acc. C.E. IRound Acc. C.E. IRound Acc. C.E. IRound Acc. C.E. 5 2.00 4.00 49.50 1.14 14.00 71.50 0.16 6.00 79.90 0.38 10.00 77.00 10 3.62 8.00 47.60 1.76 16.00 71.54 0.70 4.00 80.24 0.74 8.00 80.30 20 2.76 8.00 33.20 1.90 20.00 70.06 0.78 8.00 81.84 1.54 10.00 75.20 4.4 SCALINGANALYSIS Theablationstudiesrevealedthatmodelspossessthecapabilitiestohandleambiguousquerieswhen givencompletecontext,butfailtogathernecessaryinformationthroughinteraction. Weinvestigate whether providing more interaction opportunities (5, 10, and 20 rounds) encourages information gathering. Figure3(a)andTable4presenttheresults. Resultsshowthatmodelsfailtoscaleinteractionusagewithavailableopportunities. Despitequa- drupling round limits from 5 to 20, GPT-5 increases interactions from just 1.14 to 1.90, while Claude-Sonnet-4 barely reaches 0.78 interactions per instance. However, models that do interact more achieve better performance—GPT-5 improves from 14.00% to 20.00% accuracy as interac- tions increase. This reveals systematic overconfidence as the primary bottleneck: models prema- turely conclude they have sufficient information despite evidence that continued questioning im- provesperformance. 4.5 FORCEDINTERACTIONANALYSIS To test whether interaction underutilization stems from voluntary choice rather than capability deficits,weimplementforcedinteractionprotocolsthatrequireagentstoaskaminimumnumberof clarifyingquestions(rangingfrom2to10)beforeprovidinganswers,asshowninFigure3(b). Resultsrevealdramaticmodel-specificdifferences. GPT-5doublesitsaccuracyfrom20%to40% when compelled to ask 8 questions, confirming strong reasoning capabilities hindered by volun- tary underuse of interaction. However, not all models benefit—Claude-Sonnet-4 shows modest 8 --- Page 9 --- 50 40 30 20 10 0 5 10 20 Max Rounds Limit )%( ycaruccA (a) Scaling analysis (b) Interaction Analysis 50 gpt-5 gpt-5 deepseek-v3.1 deepseek-v3.1 40 claude-sonnet claude-sonnet gpt-4o-mini gpt-4o-mini 30 20 10 0 0 3 6 9 12 15 Interaction Rounds Figure3: Modelperformanceunderdifferentroundsconstraints. gains while GPT-4o-mini’s performance actually degrades under forced interaction. This demon- strates that effective information acquisition is a distinct capability varying significantly across architectures, suggesting limitations extend beyond overconfidence to fundamental differences in information-seekingstrategies. 4.6 LONGITUDINALSTUDY Tracking 15 months of model development reveals a concerning divergence: while BrowseComp performanceimprovedseven-fold(10%to70%),INTERACTCOMPperformanceremainedstagnant. RecentmodelslikeGPT-5,DeepSeek-R1,andGPT-4.1clusteraround6-14%accuracywithminimal variation over time. This exposes a fundamental blind spot in AI development: rapid progress on search-focused tasks has not translated to progress in interaction-based problem solving. Without explicitfocusoninteractioncapabilities,modelsadvanceinreasoningandretrievalwhileremaining primitive at recognizing ambiguity and gathering clarification—a critical limitation for practical deployment. Figure1illustratesthisstarkcontrast,showingBrowseComp’ssteepupwardtrajectory alongsideINTERACTCOMP’sflatperformanceacrossallevaluatedmodels. 5 CONCLUSION This paper presents INTERACTCOMP, a benchmark designed to evaluate a critical yet overlooked capabilityofsearchagents:recognizingandresolvingambiguousqueriesthroughactiveinteraction. Whileexistingsearchbenchmarkshavedrivenremarkableprogressinretrievalandreasoning,they uniformly assume users provide complete queries from the outset—an assumption that diverges from real-world behavior where users begin with incomplete information needs. By constructing questionsthatareeasytoverifyoncesufficientcontextisgatheredyetimpossibletodisambiguate withoutinteraction,INTERACTCOMPsystematicallyevaluateswhetheragentscanrecognizeambi- guityandactivelyseekclarificationduringsearch. Our evaluation of 17 models reveals systematic overconfidence as the primary bottleneck rather thancapabilitydeficits. Modelsachieve68-72%accuracywhenprovidedcompletecontextbutonly 13.73%withinteractionavailable,severelyunderutilizingclarifyingquestionsdespitetheiraccess. Forcedinteractionexperimentsconfirmthisisastrategicfailure—whencompelledtointeract, ac- curacy doubles, demonstrating latent capabilities current strategies fail to engage. Longitudinal analysis reinforces this diagnosis: while BrowseComp performance improved seven-fold over 15 months, INTERACTCOMP scores remained stagnant, exposing a critical blind spot where progress in retrieval has not translated to progress in interaction. Beyond diagnosis, the grounded nature ofsearchprovidescleanrewardsignalsfortraining,makingINTERACTCOMPwell-suitedforrein- forcement learning approaches to develop uncertainty-aware, actively interactive agents. We hope this benchmark provides the foundation for systematic progress on this neglected but essential di- mensionofagentdevelopment. 9 --- Page 10 --- REFERENCES Anthropic. Claude 3.5 sonnet.  claude-3-5-sonnet,2024. Anthropic. Claudeopus4.  Anthropic. Claudesonnet4.  ByteDance. Doubao1.6.  Zijian Chen, Xueguang Ma, Shengyao Zhuang, Ping Nie, Kai Zou, Andrew Liu, Joshua Green, Kshama Patel, Ruoxi Meng, Mingyi Su, et al. Browsecomp-plus: A more fair and transparent evaluationbenchmarkofdeep-researchagent. arXivpreprintarXiv:2508.06600,2025. DeepSeek. Deepseek-chat.  1,2025a. DeepSeek. DeepSeek-R1.  2025b. Xinyu Geng, Peng Xia, Zhen Zhang, Xinyu Wang, Qiuchen Wang, Ruixue Ding, Chenxi Wang, JialongWu,YidaZhao,KuanLi,etal. Webwatcher: Breakingnewfrontiersofvision-language deepresearchagent. arXivpreprintarXiv:2508.05748,2025. Google. Gemini2.5: Ourmostintelligentaimodel.  google-deepmind/gemini-model-thinking-updates-march-2025/,2025a. Google. Gemini deep research.  deep-research/,2025b. Sirui Hong, Yizhang Lin, Bang Liu, Bangbang Liu, Binhao Wu, Ceyao Zhang, Chenxing Wei, DanyangLi,JiaqiChen,JiayiZhang,etal. Datainterpreter: Anllmagentfordatascience. arXiv preprintarXiv:2402.18679,2024a. Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang,ZiliWang,StevenKaShingYau,ZijuanLin,LiyangZhou,ChenyuRan,LingfengXiao, ChenglinWu,andJu¨rgenSchmidhuber. MetaGPT:Metaprogrammingforamulti-agentcollabo- rativeframework. InTheTwelfthInternationalConferenceonLearningRepresentations,2024b. URL BowenJin,HansiZeng,ZhenruiYue,JinsungYoon,SercanArik,DongWang,HamedZamani,and JiaweiHan. Search-r1: Trainingllmstoreasonandleveragesearchengineswithreinforcement learning. arXivpreprintarXiv:2503.09516,2025. Boyan Li, Chong Chen, Zhujun Xue, Yinan Mei, and Yuyu Luo. Deepeye-sql: A software- engineering-inspiredtext-to-sqlframework. arXivpreprintarXiv:2510.17586,2025a. Boyan Li, Jiayi Zhang, Ju Fan, Yanwei Xu, Chong Chen, Nan Tang, and Yuyu Luo. Alpha-sql: Zero-shottext-to-sqlusingmontecarlotreesearch. arXivpreprintarXiv:2502.17248,2025b. KuanLi,ZhongwangZhang,HuifengYin,LiwenZhang,LituOu,JialongWu,WenbiaoYin,Baix- uanLi,ZhengweiTao,XinyuWang,etal.Websailor:Navigatingsuper-humanreasoningforweb agent. arXivpreprintarXiv:2507.02592,2025c. Shilong Li, Xingyuan Bu, Wenjie Wang, Jiaheng Liu, Jun Dong, Haoyang He, Hao Lu, Haozhe Zhang,ChenchenJing,ZhenLi,etal. Mm-browsecomp: Acomprehensivebenchmarkformul- timodalbrowsingagents. arXivpreprintarXiv:2508.13186,2025d. Xinbin Liang, Jinyu Xiang, Zhaoyang Yu, Jiayi Zhang, Sirui Hong, Sheng Fan, and Xiao Tang. Openmanus: Anopen-sourceframeworkforbuildinggeneralaiagents,2025. BangLiu,XinfengLi,JiayiZhang,JinlinWang,TanjinHe,SiruiHong,HongzhangLiu,Shaokun Zhang, Kaitao Song, Kunlun Zhu, et al. Advances and challenges in foundation agents: From brain-inspired intelligence to evolutionary, collaborative, and safe systems. arXiv preprint arXiv:2504.01990,2025a. 10 --- Page 11 --- JuntengLiu,YunjiLi,ChiZhang,JingyangLi,AiliChen,KeJi,WeiyuCheng,ZijiaWu,Chengyu Du,QidiXu,etal. Webexplorer: Exploreandevolvefortraininglong-horizonwebagents. arXiv preprintarXiv:2509.06501,2025b. Gre´goire Mialon, Cle´mentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a benchmark for general ai assistants. In The Twelfth International Conference on Learning Representations,2023. MoonshotAI. KimiK2.  OpenAI. HelloGPT-4o.  OpenAI.GPT-4omini:Advancingcost-efficientintelligence. gpt-4o-mini-advancing-cost-efficient-intelligence/,2024b. OpenAI. IntroducingGPT-4.1.  OpenAI. Introducing GPT-5.  2025b. OpenAI. Introducing openai o3 and o4-mini.  introducing-o3-and-o4-mini/,2025c. OpenAI. Introducing deep research.  introducing-deep-research/,2025d. ChengQian,BingxiangHe,ZhongZhuang,JiaDeng,YujiaQin,XinCong,ZhongZhang,JieZhou, YankaiLin, ZhiyuanLiu, etal. Tellmemore! towardsimplicituserintentionunderstandingof languagemodeldrivenagents. arXivpreprintarXiv:2402.09205,2024. Cheng Qian, Zuxin Liu, Akshara Prabhakar, Zhiwei Liu, Jianguo Zhang, Haolin Chen, Heng Ji, WeiranYao,ShelbyHeinecke,SilvioSavarese,etal.Userbench:Aninteractivegymenvironment foruser-centricagents. arXivpreprintarXiv:2507.22034,2025a. ChengQian,ZuxinLiu,AksharaPrabhakar,JielinQiu,ZhiweiLiu,HaolinChen,ShirleyKokane, HengJi,WeiranYao,ShelbyHeinecke,etal. Userrl: Traininginteractiveuser-centricagentvia reinforcementlearning. arXivpreprintarXiv:2509.19736,2025b. QwenTeam. Qwen3-235B-A22B.  HuatongSong, JinhaoJiang, YingqianMin, JieChen, ZhipengChen, WayneXinZhao, LeiFang, and Ji-Rong Wen. R1-searcher: Incentivizing the search capability in llms via reinforcement learning. arXivpreprintarXiv:2503.05592,2025. FengweiTeng,ZhaoyangYu,QuanShi,JiayiZhang,ChenglinWu,andYuyuLuo.Atomofthoughts formarkovllmtest-timescaling. arXivpreprintarXiv:2502.12018,2025. Jason Wei, Zhiqing Sun, Spencer Papay, Scott McKinney, Jeffrey Han, Isa Fulford, Hyung Won Chung, Alex Tachard Passos, William Fedus, and Amelia Glaese. Browsecomp: A simple yet challengingbenchmarkforbrowsingagents. arXivpreprintarXiv:2504.12516,2025. xAI. Grok4.  An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, et al. Qwen2.5 technical report. arXiv preprint arXiv:2412.15115,2024. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In International Conference on LearningRepresentations(ICLR),2023. Shunyu Yao, Noah Shinn, Pedram Razavi, and Karthik Narasimhan. τ-bench: A benchmark for tool-agent-user interaction in real-world domains, 2024. URL  2406.12045. 11 --- Page 12 --- WeihaoZeng,KeqingHe,ChuqiaoKuang,XiaoguangLi,andJunxianHe.Pushingtest-timescaling limitsofdeepsearchwithasymmetricverification. arXivpreprintarXiv:2510.06135,2025. Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xiong-Hui Chen, Jiaqi Chen, Mingchen Zhuge,XinCheng,SiruiHong,JinlinWang,BingnanZheng,BangLiu,YuyuLuo,andChenglin Wu. AFlow: Automatingagenticworkflowgeneration. InTheThirteenthInternationalConfer- ence on Learning Representations, 2025. URL  z5uVAKwmjf. ZhipuAI. Glm-4.5.  PeilinZhou,BruceLeon,XiangYing,CanZhang,YifanShao,QichenYe,DadingChong,Zhiling Jin, Chenxuan Xie, Meng Cao, et al. Browsecomp-zh: Benchmarking web browsing ability of largelanguagemodelsinchinese. arXivpreprintarXiv:2504.19314,2025a. YifeiZhou,SongJiang,YuandongTian,JasonWeston,SergeyLevine,SainbayarSukhbaatar,and XianLi.Sweet-rl:Trainingmulti-turnllmagentsoncollaborativereasoningtasks.arXivpreprint arXiv:2503.15478,2025b. 12 --- Page 13 --- A APPENDIX A.1 AGENTIMPLEMENTATION Our agent implementation is built upon the ReAct framework (Yao et al., 2023), which combines reasoningandactinginaunifiedarchitecture. Weimplementthreedistinctagentconfigurationsto systematicallyevaluatedifferentcapabilitycombinations: Configuration1: Answer-only: Theagentdirectlygeneratesresponsesusingitsinternalknowledge without external information gathering. This configuration serves as a baseline to measure pure knowledgerecallcapabilitiesonambiguousqueries. Configuration 2: Answer+Search: The agent can perform web search actions to retrieve external informationbeforegeneratinganswers. Availableactionsinclude: • search(query): Performswebsearchwiththespecifiedquery • answer(response, confidence): Providesfinalanswerwithconfidencescore Configuration3: Answer+Search+Ask: Thefullinteraction-enabledagentthatcanadditionallyre- questclarificationfromusers. Thisconfigurationadds: • ask(question): Posesyes/noquestionstogathermissinginformation Action Space Design - Each agent operates with a maximum of 10 rounds, where each round allowsexactlyoneaction. Theagentmaintainsaninternalmemoryofpreviousactionsandobserva- tions. Forforcedinteractionexperiments,weimplementaconstraintrequiringminimuminteraction thresholdsbeforeanswergenerationispermitted. Thecompletesystempromptsandinteractionprotocolsaredetailedbelow. Prompt SYSTEM_PROMPT = """ ## Goal You are an intelligent agent, designed to answer user's question. In each round, you can execute one action, and you can get the action's result as (cid:44)→ observation. You should think step by step, and output the action you want to execute. ### Evidence first Before answering, you MUST: 1. Identify ALL missing information dimensions (time, scope, context, conditions etc.) 2. Systematically gather evidence for each dimension 3. Verify key assumptions through multiple sources/questions 4. Only answer when you can confidently justify each part of your response **Critical**: Most questions have hidden complexities. Your initial understanding is (cid:44)→ likely incomplete. ### Using ask When the ask action is available, you may pose closed-ended questions to fill gaps such (cid:44)→ as time, scope, conditions, relationships, or quantities. - Do **not** ask the user to confirm a complete candidate answer or entity name. (cid:44)→ request neutral attributes or other missing evidence instead. **Important: When you choose the ask action, you can only ask closed-ended, yes/no (cid:44)→ questions. The user will only respond with "yes", "no", or "I don't know".** ## Available actions: {actions} ## Output Format When you output the action, you should output the action name and parameters in the json format, and only one (cid:44)→ action. Such as, ```json {{ "action": "", "params": {{ "<param_name>": "<param_value>" 13 --- Page 14 --- }} }} ``` Before output, you should think step by step. ## Question {question} """ ACT_PROMPT = """ ## Memory {memory} ## Observation Last action: {last_action} Observation: {last_observation} ## Question {question} ## Action You should output the action you want to execute. Output your next action in JSON format, e.g. ```json {{ "action": "", "params": {{ "<param_name>": "<param_value>" }} }} ``` ## ROUNDS Current round: {round_info} You have only one opportunity to provide your final answer. Use your remaining rounds wisely to collect evidence and test your theories before (cid:44)→ committing to an answer. The above shows your remaining action rounds. """ FINAL_ROUND_ACT_PROMPT = """ Given the question and information you have gathered, output the final answer. ## Round {round_info} ## Memory {memory} ## Question {question} ## Action You should output the answer action, you can think step by step before you output the (cid:44)→ answer. Return the final answer action in JSON, for example: ```json {{ "action": "answer", "params": {{ "answer": "<param_value>", "confidence": "<param_value>" }} }} ``` """ A.2 RESPONDERSIMULATION We implement a controlled responder simulation using GPT-4o (temperature=1.0) that provides structuredfeedbackwhenagentsemploytheaskaction.Uponreceivingagentqueries,theresponder evaluates questions against available context and responds with one of three standardized options: ”yes”,”no”,or”Idon’tknow”. Theresponderstates consistsofthegivencontextandinteraction r history, with transitions T : (s ,q ) → o ∈ {yes,no,unknown} conditioned on context- r r agent r 14 --- Page 15 --- questionalignment. WhilemaintainingresponsediversitythroughLLMgeneration,theconstrained outputformatensuresevaluationconsistency. Thecompleteresponderpromptsaredetailedbelow. Prompt RESPONDER_PROMPT = """ You are a specialized Q&A agent. Think step by step before you output the answer. Rules: - Reply with exactly one of: yes, no, or i don't know. - Treat the context as the entire truth. - Use only the provided CONTEXT to judge the yes/no question. - Answer **yes** only if the context clearly states the proposition is correct. - Answer **no** if the context contradicts the proposition (for example it states an (cid:44)→ incompatible attribute). - If the context neither confirms nor denies it, answer **i don't know**. - Do not rely on outside knowledge, analogies, or multi-hop guesses. Compare the (cid:44)→ relevant words directly. CONTEXT {context} QUESTION {question} Output: yes | no | i don't know """ A.3 EVALUATIONPROTOCOL Wevalidatesimulationreliabilitythroughrepeatedsamplingacrossidenticalcontext–questionpairs acrossk =3trials,indicatingstablebehaviordespitethestochasticgenerationprocess. Weemploy GPT-4O (temperature = 0.0) as our grader, providing ground truth, agent response, and ques- tioncontextforbinarycorrectnessjudgments. Graderreliabilityisvalidatedthroughspot-checking againsthumanevaluation. Thecompleteresponderpromptsaredetailedbelow. Prompt GRADING_PROMPT = """ \nYou are an impartial grader. Question: {question} Predicted Answer: {predicted_answer} Correct Answer: {correct_answer} CRITICAL GRADING INSTRUCTIONS: 1. The predicted answer must match the CORRECT ANSWER 2. Look for EXACT name matches or clear references to the same entity 3. Consider different languages, translations, or alternative names as potential (cid:44)→ matches 4. Be strict: partial matches or vague similarities should be 'no' IMPORTANT: Give ONLY one score: - 'yes': The predicted answer correctly identifies the same entity as the correct (cid:44)→ answer - 'no': The predicted answer is wrong, matches the popular answer, or refers to a (cid:44)→ different entity Respond with ONLY 'yes' or 'no', nothing else.""" 15 --- Page 16 --- A.4 DATACONSTRUCTIONPIPELINE TableA1: DataConstructionPipeline: Step-by-StepExample Step Component ExampleContent TargetEntityA Hornussen(Swissteamstrikingsport) Step1 DistractorB Baseball(globallypopularteambat-and-ballsport) SharedAttributes Team-basedstrikinggame;offense/defensealternation;play- Step2 ers take turns hitting; projectiles reach very high speeds (>100 mph); protective gear required; governed by formal associationsorleagues. Distinctive Hornussen: strikesaplasticpuck(“Nouss”)withwhip-like Attributes swing using a long wooden rod; defenders intercept with wooden boards; fan-shaped field ∼300m; 18–20 defenders spreadinwideformation;scoringdependsondistance/land- ingpoint. Step3 Ambiguous “Whichteam-basedstrikingsportfeaturestwosidesalternat- QuestionQ ingoffenseanddefense,whereindividualssequentiallyhita high-speedprojectileandteammatescoordinatetointercept it in the air? Outcomes depend on whether the projectile is intercepted or lands within the valid playing field. Defense relies on wide positioning and collaboration, all offensive players take turns striking, flight speeds often exceed 100 mph, protective gear is required due to impact risk, and the sportisgovernedbylong-standingassociationsorleagues.” Step4 Contextual – Struck object is a plastic puck, resembling an ice hockey Information puck. –Strikingmethodusesawhip-likeswingwithalongwooden rod. –Defendersusewoodenboardstoblockthepuckinmid-air. –Field: fanshape,∼300mlong,10–12°angle. –Defensiveline: 18–20players. –Scoring: distance/landing-based. Step5 ReasoningPath Q gives a plausible candidate set (e.g., Baseball vs Hor- nussen). AddingcontextclarifiesuniqueHornussenfeatures (puck,whipswing,fan-shapedfield,defensiveboards),lead- ingtotheuniqueanswer=Hornussen. 16 --- Page 17 --- A.5 ROUNDSCONSTRAINTSRESULTS Table A2: Performance comparison of models under varying average interaction levels. Metrics includeaccuracy(%),expectedcalibrationerror(ECE,%),andaverageroundsofinteraction(Inter- action). Interaction Accuracy(%) ECE(%) Setting GPT-5 1.14 14.0 71.50 SCALING 1.76 16.0 71.54 SCALING 1.90 20.0 70.06 SCALING 4.40 24.0 63.34 FORCED 6.10 20.0 69.02 FORCED 8.32 32.0 54.68 FORCED 9.40 40.0 48.20 FORCED 11.56 40.0 46.86 FORCED DeepSeek-Chat 0.38 10.0 77.00 SCALING 0.74 8.0 80.30 SCALING 1.54 10.0 75.20 SCALING 5.40 20.0 62.30 FORCED 6.68 22.0 52.60 FORCED 9.26 22.0 61.30 FORCED 10.82 16.0 66.40 FORCED 12.62 24.0 61.20 FORCED Claude-Sonnet-4 0.16 6.0 79.90 SCALING 0.70 4.0 80.24 SCALING 0.78 8.0 81.84 SCALING 3.12 12.0 75.80 FORCED 4.26 12.0 76.90 FORCED 6.10 10.0 76.00 FORCED 8.02 16.0 69.10 FORCED 10.46 18.0 68.40 FORCED GPT-4o-mini 2.00 4.0 49.50 SCALING 3.62 8.0 47.60 SCALING 2.76 8.0 33.20 SCALING 14.50 4.0 65.50 FORCED 16.50 4.0 69.70 FORCED 14.88 2.0 62.60 FORCED 11.18 6.0 56.10 FORCED 14.92 2.0 66.70 FORCED 17